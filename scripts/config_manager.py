#!/usr/bin/env python
"""
é…ç½®æ–‡ä»¶ç®¡ç†è„šæœ¬
ç”¨äºåˆ›å»ºã€ç®¡ç†å’Œç»„ç»‡ä¸åŒçš„å®éªŒé…ç½®æ–‡ä»¶
"""

import os
import sys
import yaml
import argparse
from datetime import datetime
from pathlib import Path
from typing import Dict, Any

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

class ConfigManager:
    """é…ç½®æ–‡ä»¶ç®¡ç†å™¨"""
    
    def __init__(self, config_dir: str = "configs"):
        self.config_dir = Path(config_dir)
        self.config_dir.mkdir(parents=True, exist_ok=True)
        
        # é…ç½®æ¨¡æ¿
        self.templates = {
            "baseline": self._get_baseline_template(),
            "high_performance": self._get_high_performance_template(),
            "experimental": self._get_experimental_template()
        }
    
    def create_config(self, 
                     dataset: str, 
                     template: str = "baseline", 
                     description: str = "",
                     custom_params: Dict[str, Any] = None) -> str:
        """åˆ›å»ºæ–°çš„é…ç½®æ–‡ä»¶"""
        
        # ç”Ÿæˆæ—¶é—´æˆ³
        timestamp = datetime.now().strftime("%Y%m%d_%H%M")
        
        # ç”Ÿæˆæ–‡ä»¶å
        filename = f"{timestamp}_{dataset}_{template}.yaml"
        filepath = self.config_dir / filename
        
        # è·å–é…ç½®æ¨¡æ¿
        if template not in self.templates:
            raise ValueError(f"æœªçŸ¥æ¨¡æ¿: {template}. å¯ç”¨æ¨¡æ¿: {list(self.templates.keys())}")
        
        config = self.templates[template].copy()
        
        # æ›´æ–°æ•°æ®é›†è·¯å¾„
        config['data']['corpus_path'] = f"data/processed/{dataset}_corpus.jsonl"
        config['data']['queries_path'] = f"data/processed/{dataset}_queries.jsonl"
        config['data']['qrels_path'] = f"data/processed/{dataset}_qrels.tsv"
        
        # æ›´æ–°ç´¢å¼•è·¯å¾„
        for retriever in config['retrievers']:
            if 'index_path' in config['retrievers'][retriever]:
                old_path = config['retrievers'][retriever]['index_path']
                # åœ¨æ–‡ä»¶åä¸­æ’å…¥æ—¶é—´æˆ³å’Œæ•°æ®é›†
                path_parts = Path(old_path)
                new_name = f"{timestamp}_{dataset}_{path_parts.name}"
                config['retrievers'][retriever]['index_path'] = str(path_parts.parent / new_name)
        
        # æ›´æ–°æ—¥å¿—è·¯å¾„
        config['system']['log_path'] = f"checkpoints/logs/{timestamp}_{dataset}_{template}_system.log"
        config['evaluation']['output_path'] = f"checkpoints/logs/{timestamp}_{dataset}_{template}_eval_results.json"
        
        # åº”ç”¨è‡ªå®šä¹‰å‚æ•°
        if custom_params:
            config = self._merge_config(config, custom_params)
        
        # æ·»åŠ å…ƒæ•°æ®
        config['metadata'] = {
            'created_at': datetime.now().isoformat(),
            'dataset': dataset,
            'template': template,
            'description': description,
            'filename': filename
        }
        
        # ä¿å­˜é…ç½®æ–‡ä»¶
        with open(filepath, 'w', encoding='utf-8') as f:
            yaml.dump(config, f, default_flow_style=False, allow_unicode=True, indent=2)
        
        print(f"âœ… é…ç½®æ–‡ä»¶å·²åˆ›å»º: {filepath}")
        return str(filepath)
    
    def list_configs(self) -> None:
        """åˆ—å‡ºæ‰€æœ‰é…ç½®æ–‡ä»¶"""
        configs = list(self.config_dir.glob("*.yaml"))
        configs.sort()
        
        print("ğŸ“‹ ç°æœ‰é…ç½®æ–‡ä»¶:")
        print("-" * 80)
        print(f"{'æ–‡ä»¶å':<40} {'æ•°æ®é›†':<15} {'æ¨¡æ¿':<15} {'åˆ›å»ºæ—¶é—´':<20}")
        print("-" * 80)
        
        for config_file in configs:
            try:
                with open(config_file, 'r', encoding='utf-8') as f:
                    config = yaml.safe_load(f)
                
                metadata = config.get('metadata', {})
                dataset = metadata.get('dataset', 'unknown')
                template = metadata.get('template', 'unknown')
                created_at = metadata.get('created_at', 'unknown')
                
                if created_at != 'unknown':
                    created_at = created_at[:19]  # åªæ˜¾ç¤ºæ—¥æœŸå’Œæ—¶é—´
                
                print(f"{config_file.name:<40} {dataset:<15} {template:<15} {created_at:<20}")
                
            except Exception as e:
                print(f"{config_file.name:<40} {'error':<15} {'error':<15} {'error':<20}")
    
    def compare_configs(self, config1: str, config2: str) -> None:
        """æ¯”è¾ƒä¸¤ä¸ªé…ç½®æ–‡ä»¶"""
        path1 = self.config_dir / config1
        path2 = self.config_dir / config2
        
        if not path1.exists() or not path2.exists():
            print("âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨")
            return
        
        with open(path1, 'r') as f:
            cfg1 = yaml.safe_load(f)
        with open(path2, 'r') as f:
            cfg2 = yaml.safe_load(f)
        
        print(f"ğŸ” æ¯”è¾ƒé…ç½®æ–‡ä»¶:")
        print(f"  æ–‡ä»¶1: {config1}")
        print(f"  æ–‡ä»¶2: {config2}")
        print("-" * 60)
        
        self._compare_dict(cfg1, cfg2, "")
    
    def _compare_dict(self, dict1: Dict, dict2: Dict, prefix: str) -> None:
        """é€’å½’æ¯”è¾ƒå­—å…¸"""
        all_keys = set(dict1.keys()) | set(dict2.keys())
        
        for key in sorted(all_keys):
            full_key = f"{prefix}.{key}" if prefix else key
            
            if key not in dict1:
                print(f"  + {full_key}: {dict2[key]} (ä»…åœ¨æ–‡ä»¶2ä¸­)")
            elif key not in dict2:
                print(f"  - {full_key}: {dict1[key]} (ä»…åœ¨æ–‡ä»¶1ä¸­)")
            elif dict1[key] != dict2[key]:
                if isinstance(dict1[key], dict) and isinstance(dict2[key], dict):
                    self._compare_dict(dict1[key], dict2[key], full_key)
                else:
                    print(f"  ~ {full_key}: {dict1[key]} â†’ {dict2[key]}")
    
    def _merge_config(self, base_config: Dict, custom_params: Dict) -> Dict:
        """åˆå¹¶é…ç½®å‚æ•°"""
        import copy
        result = copy.deepcopy(base_config)
        
        def merge_recursive(base, custom):
            for key, value in custom.items():
                if key in base and isinstance(base[key], dict) and isinstance(value, dict):
                    merge_recursive(base[key], value)
                else:
                    base[key] = value
        
        merge_recursive(result, custom_params)
        return result
    
    def _get_baseline_template(self) -> Dict[str, Any]:
        """åŸºçº¿é…ç½®æ¨¡æ¿"""
        return {
            "data": {
                "corpus_path": "data/processed/nfcorpus_corpus.jsonl",
                "queries_path": "data/processed/nfcorpus_queries.jsonl",
                "qrels_path": "data/processed/nfcorpus_qrels.tsv",
                "output_dir": "data/processed/"
            },
            "retrievers": {
                "bm25": {
                    "enabled": True,
                    "index_path": "checkpoints/retriever/bm25_index.pkl",
                    "k1": 1.2,
                    "b": 0.75,
                    "top_k": 100
                },
                "dense": {
                    "enabled": True,
                    "model_name": "sentence-transformers/all-MiniLM-L6-v2",
                    "index_path": "checkpoints/retriever/dense_index.faiss",
                    "embedding_dim": 384,
                    "top_k": 100
                },
                "graph": {
                    "enabled": False,
                    "index_path": "checkpoints/retriever/graph_index.pkl",
                    "neo4j_uri": "bolt://localhost:7687",
                    "neo4j_user": "neo4j",
                    "neo4j_password": "fusionrag123",
                    "database": "neo4j",
                    "max_walk_length": 3,
                    "entity_threshold": 2,
                    "top_k": 50
                }
            },
            "classifier": {
                "enabled": False,
                "threshold": 0.5,
                "classes": ["factual", "analytical", "procedural"],
                "adaptation_enabled": False
            },
            "fusion": {
                "method": "weighted",
                "weights": {
                    "bm25": 0.6,
                    "dense": 0.4,
                    "graph": 0.0
                },
                "top_k": 20
            },
            "evaluation": {
                "metrics": ["recall@5", "recall@10", "ndcg@10", "map"],
                "output_path": "checkpoints/logs/eval_results.json"
            },
            "system": {
                "device": "cpu",
                "batch_size": 32,
                "num_threads": 4,
                "log_level": "INFO",
                "log_path": "checkpoints/logs/system.log"
            }
        }
    
    def _get_high_performance_template(self) -> Dict[str, Any]:
        """é«˜æ€§èƒ½é…ç½®æ¨¡æ¿"""
        config = self._get_baseline_template()
        
        # é«˜æ€§èƒ½è®¾ç½®
        config['retrievers']['bm25']['top_k'] = 300
        config['retrievers']['dense']['enabled'] = True
        config['retrievers']['dense']['model_name'] = "sentence-transformers/all-mpnet-base-v2"
        config['retrievers']['dense']['embedding_dim'] = 768
        config['retrievers']['dense']['top_k'] = 300
        config['retrievers']['dense']['batch_size'] = 32
        config['retrievers']['graph']['enabled'] = True
        config['retrievers']['graph']['top_k'] = 100
        
        config['classifier']['enabled'] = True
        config['classifier']['adaptation_enabled'] = True
        
        config['fusion']['method'] = "weighted"
        config['fusion']['weights'] = {"bm25": 0.5, "dense": 0.4, "graph": 0.1}
        config['fusion']['top_k'] = 100
        
        config['evaluation']['metrics'] = ["recall@5", "recall@10", "recall@20", "recall@50", "ndcg@10", "ndcg@20", "map", "mrr"]
        config['system']['batch_size'] = 16
        config['system']['num_threads'] = 8
        
        return config
    
    def _get_experimental_template(self) -> Dict[str, Any]:
        """å®éªŒé…ç½®æ¨¡æ¿"""
        config = self._get_high_performance_template()
        
        # å®éªŒæ€§è®¾ç½®
        config['fusion']['method'] = "rrf"
        config['fusion']['rrf_k'] = 60
        config['retrievers']['dense']['model_name'] = "sentence-transformers/all-mpnet-base-v2"
        
        return config

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="FusionRAGé…ç½®æ–‡ä»¶ç®¡ç†å™¨")
    
    subparsers = parser.add_subparsers(dest='command', help='å¯ç”¨å‘½ä»¤')
    
    # åˆ›å»ºé…ç½®
    create_parser = subparsers.add_parser('create', help='åˆ›å»ºæ–°é…ç½®æ–‡ä»¶')
    create_parser.add_argument('dataset', help='æ•°æ®é›†åç§°')
    create_parser.add_argument('--template', choices=['baseline', 'high_performance', 'experimental'], 
                              default='baseline', help='é…ç½®æ¨¡æ¿')
    create_parser.add_argument('--description', default='', help='é…ç½®æè¿°')
    
    # åˆ—å‡ºé…ç½®
    subparsers.add_parser('list', help='åˆ—å‡ºæ‰€æœ‰é…ç½®æ–‡ä»¶')
    
    # æ¯”è¾ƒé…ç½®
    compare_parser = subparsers.add_parser('compare', help='æ¯”è¾ƒä¸¤ä¸ªé…ç½®æ–‡ä»¶')
    compare_parser.add_argument('config1', help='é…ç½®æ–‡ä»¶1')
    compare_parser.add_argument('config2', help='é…ç½®æ–‡ä»¶2')
    
    args = parser.parse_args()
    
    manager = ConfigManager()
    
    if args.command == 'create':
        manager.create_config(args.dataset, args.template, args.description)
    elif args.command == 'list':
        manager.list_configs()
    elif args.command == 'compare':
        manager.compare_configs(args.config1, args.config2)
    else:
        parser.print_help()

if __name__ == "__main__":
    main()
