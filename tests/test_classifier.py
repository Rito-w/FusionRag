#!/usr/bin/env python
"""
æŸ¥è¯¢åˆ†ç±»å™¨æµ‹è¯•è„šæœ¬
æµ‹è¯•æ™ºèƒ½æŸ¥è¯¢åˆ†ç±»å’Œè·¯ç”±åŠŸèƒ½
"""

import sys
import os
sys.path.append('.')

from modules.classifier.query_classifier import QueryClassifier, AdaptiveQueryRouter
from modules.utils.interfaces import Query

def test_query_classifier():
    """æµ‹è¯•æŸ¥è¯¢åˆ†ç±»å™¨"""
    print("ğŸ§ª æŸ¥è¯¢åˆ†ç±»å™¨æµ‹è¯•")
    print("=" * 50)
    
    classifier = QueryClassifier()
    
    # æµ‹è¯•æŸ¥è¯¢
    test_queries = [
        # äº‹å®æ€§æŸ¥è¯¢
        Query("1", "What is breast cancer?"),
        Query("2", "Define diabetes mellitus"),
        Query("3", "ä»€ä¹ˆæ˜¯é«˜è¡€å‹ï¼Ÿ"),
        Query("4", "Who discovered insulin?"),
        
        # åˆ†ææ€§æŸ¥è¯¢
        Query("5", "Why do statins cause muscle pain?"),
        Query("6", "How does chemotherapy work?"),
        Query("7", "Compare different diabetes treatments"),
        Query("8", "ä¸ºä»€ä¹ˆä¼šå¾—ç³–å°¿ç—…ï¼Ÿ"),
        
        # ç¨‹åºæ€§æŸ¥è¯¢
        Query("9", "Step by step procedure for blood pressure measurement"),
        Query("10", "Treatment protocol for acute myocardial infarction"),
        Query("11", "å¦‚ä½•æ²»ç–—é«˜è¡€å‹ï¼Ÿ"),
        Query("12", "Cancer diagnosis process"),
    ]
    
    print("å•ä¸ªæŸ¥è¯¢åˆ†ç±»æµ‹è¯•:")
    print("-" * 40)
    
    for query in test_queries:
        result = classifier.classify_query(query)
        
        print(f"æŸ¥è¯¢: {query.text}")
        print(f"  é¢„æµ‹ç±»åˆ«: {result['predicted_class']}")
        print(f"  ç½®ä¿¡åº¦: {result['confidence']:.3f}")
        print(f"  æ¨èæ£€ç´¢å™¨: {result['recommended_retrievers']}")
        print(f"  ç±»åˆ«å¾—åˆ†: {result['class_scores']}")
        print()
    
    # æ‰¹é‡åˆ†ç±»æµ‹è¯•
    print("\næ‰¹é‡åˆ†ç±»æµ‹è¯•:")
    print("-" * 40)
    
    batch_results = classifier.batch_classify(test_queries)
    stats = classifier.get_retriever_stats(batch_results)
    
    print(f"ç±»åˆ«åˆ†å¸ƒ: {stats['class_distribution']}")
    print(f"æ£€ç´¢å™¨ä½¿ç”¨: {stats['retriever_usage']}")
    print(f"æ€»æŸ¥è¯¢æ•°: {stats['total_queries']}")

def test_adaptive_router():
    """æµ‹è¯•è‡ªé€‚åº”è·¯ç”±å™¨"""
    print("\nğŸ”€ è‡ªé€‚åº”è·¯ç”±å™¨æµ‹è¯•")
    print("=" * 50)
    
    classifier = QueryClassifier()
    router = AdaptiveQueryRouter(classifier)
    
    # å¯ç”¨æ£€ç´¢å™¨
    available_retrievers = ['bm25', 'dense', 'graph']
    
    # æµ‹è¯•æŸ¥è¯¢
    test_queries = [
        Query("r1", "What causes diabetes?"),
        Query("r2", "How to treat hypertension?"),
        Query("r3", "Define cardiovascular disease"),
        Query("r4", "Compare cancer therapies"),
    ]
    
    print("è·¯ç”±å†³ç­–æµ‹è¯•:")
    print("-" * 40)
    
    routing_results = []
    
    for query in test_queries:
        route_result = router.route_query(query, available_retrievers)
        routing_results.append(route_result)
        
        print(f"æŸ¥è¯¢: {query.text}")
        print(f"  åˆ†ç±»: {route_result['classification']['predicted_class']}")
        print(f"  è·¯ç”±åˆ°: {route_result['retrievers']}")
        print(f"  è·¯ç”±ç½®ä¿¡åº¦: {route_result['route_confidence']:.3f}")
        print(f"  è‡ªé€‚åº”è°ƒæ•´: {route_result['adaptation_applied']}")
        print()
    
    # æ¨¡æ‹Ÿæ€§èƒ½åé¦ˆ
    print("æ¨¡æ‹Ÿæ€§èƒ½æ›´æ–°:")
    print("-" * 40)
    
    import random
    for i, (query, route_result) in enumerate(zip(test_queries, routing_results)):
        # æ¨¡æ‹Ÿæ€§èƒ½å¾—åˆ†
        performance_score = random.uniform(0.1, 0.9)
        router.update_performance(query, route_result['retrievers'], performance_score)
        print(f"æŸ¥è¯¢ {i+1}: æ€§èƒ½å¾—åˆ† {performance_score:.3f}")
    
    # è·å–è·¯ç”±ç»Ÿè®¡
    routing_stats = router.get_routing_stats()
    print(f"\nè·¯ç”±ç»Ÿè®¡:")
    print(f"  è·¯ç”±ä½¿ç”¨: {routing_stats['route_usage']}")
    print(f"  æ€§èƒ½å†å²: {routing_stats['performance_history']}")

def test_classifier_persistence():
    """æµ‹è¯•åˆ†ç±»å™¨æŒä¹…åŒ–"""
    print("\nğŸ’¾ åˆ†ç±»å™¨æŒä¹…åŒ–æµ‹è¯•")
    print("=" * 50)
    
    # åˆ›å»ºå¹¶é…ç½®åˆ†ç±»å™¨
    original_classifier = QueryClassifier({
        'threshold': 0.6,
        'classes': ['factual', 'analytical', 'procedural', 'custom']
    })
    
    # æ·»åŠ è‡ªå®šä¹‰ç‰¹å¾
    original_classifier.feature_patterns['custom'] = {
        'keywords': ['custom', 'special'],
        'patterns': [r'\bcustom\b', r'\bspecial\b']
    }
    
    # ä¿å­˜æ¨¡å‹
    model_path = "temp_classifier_model.pkl"
    original_classifier.save_model(model_path)
    
    # åˆ›å»ºæ–°åˆ†ç±»å™¨å¹¶åŠ è½½æ¨¡å‹
    new_classifier = QueryClassifier()
    new_classifier.load_model(model_path)
    
    # æµ‹è¯•åŠ è½½çš„æ¨¡å‹
    test_query = Query("test", "This is a custom special query")
    
    original_result = original_classifier.classify_query(test_query)
    loaded_result = new_classifier.classify_query(test_query)
    
    print(f"åŸå§‹åˆ†ç±»å™¨ç»“æœ: {original_result['predicted_class']}")
    print(f"åŠ è½½ååˆ†ç±»å™¨ç»“æœ: {loaded_result['predicted_class']}")
    print(f"ç»“æœä¸€è‡´: {original_result['predicted_class'] == loaded_result['predicted_class']}")
    
    # æ¸…ç†
    os.remove(model_path)
    print("âœ… æ¨¡å‹ä¿å­˜å’ŒåŠ è½½æµ‹è¯•æˆåŠŸ")

def test_real_queries():
    """æµ‹è¯•çœŸå®æŸ¥è¯¢æ•°æ®"""
    print("\nğŸ”¬ çœŸå®æŸ¥è¯¢æµ‹è¯•")
    print("=" * 50)
    
    try:
        from modules.utils.common import JSONDataLoader
        
        # åŠ è½½çœŸå®æŸ¥è¯¢
        loader = JSONDataLoader()
        queries = loader.load_queries("data/processed/nfcorpus_queries.jsonl")[:10]
        
        classifier = QueryClassifier()
        
        print("çœŸå®æŸ¥è¯¢åˆ†ç±»ç»“æœ:")
        print("-" * 40)
        
        for query in queries:
            result = classifier.classify_query(query)
            print(f"æŸ¥è¯¢: {query.text[:60]}...")
            print(f"  ç±»åˆ«: {result['predicted_class']} (ç½®ä¿¡åº¦: {result['confidence']:.3f})")
            print(f"  æ¨è: {result['recommended_retrievers']}")
            print()
        
        # ç»Ÿè®¡åˆ†æ
        batch_results = classifier.batch_classify(queries)
        stats = classifier.get_retriever_stats(batch_results)
        
        print(f"çœŸå®æ•°æ®ç»Ÿè®¡:")
        print(f"  ç±»åˆ«åˆ†å¸ƒ: {stats['class_distribution']}")
        print(f"  æ£€ç´¢å™¨æ¨è: {stats['retriever_usage']}")
        
    except Exception as e:
        print(f"âŒ çœŸå®æŸ¥è¯¢æµ‹è¯•å¤±è´¥: {e}")

def test_integration_with_pipeline():
    """æµ‹è¯•ä¸Pipelineé›†æˆ"""
    print("\nğŸ”— Pipelineé›†æˆæµ‹è¯•")
    print("=" * 50)
    
    try:
        # åˆ›å»ºåŒ…å«åˆ†ç±»å™¨çš„é…ç½®
        config_content = """
data:
  corpus_path: "data/processed/nfcorpus_corpus.jsonl"
  queries_path: "data/processed/nfcorpus_queries.jsonl"
  qrels_path: "data/processed/nfcorpus_qrels.tsv"

retrievers:
  bm25:
    enabled: true
    index_path: "checkpoints/retriever/test_bm25_index.pkl"
    k1: 1.2
    b: 0.75
    top_k: 50
  dense:
    enabled: true
    model_name: "sentence-transformers/all-MiniLM-L6-v2"
    index_path: "checkpoints/retriever/test_dense_index.faiss"
    embedding_dim: 384
    top_k: 50

classifier:
  enabled: true
  threshold: 0.5
  classes: ["factual", "analytical", "procedural"]
  adaptation_enabled: true

fusion:
  method: "weighted"
  weights:
    bm25: 0.5
    dense: 0.5
  top_k: 10

system:
  log_level: "ERROR"
"""
        
        temp_config = "temp_classifier_config.yaml"
        with open(temp_config, 'w') as f:
            f.write(config_content)
        
        # è¿™é‡Œåªæ˜¯æ¼”ç¤ºé…ç½®ï¼Œå®é™…é›†æˆéœ€è¦åœ¨Pipelineä¸­å®ç°
        print("âœ… åˆ†ç±»å™¨é…ç½®å·²å‡†å¤‡å¥½é›†æˆåˆ°Pipeline")
        print("é…ç½®åŒ…å«:")
        print("  - æŸ¥è¯¢åˆ†ç±»åŠŸèƒ½")
        print("  - æ™ºèƒ½æ£€ç´¢å™¨è·¯ç”±")
        print("  - è‡ªé€‚åº”æ€§èƒ½ä¼˜åŒ–")
        
        # æ¸…ç†
        os.remove(temp_config)
        
    except Exception as e:
        print(f"âŒ Pipelineé›†æˆæµ‹è¯•å¤±è´¥: {e}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ æŸ¥è¯¢åˆ†ç±»å™¨å…¨é¢æµ‹è¯•")
    print("=" * 60)
    
    try:
        # 1. åŸºæœ¬åˆ†ç±»æµ‹è¯•
        test_query_classifier()
        
        # 2. è‡ªé€‚åº”è·¯ç”±æµ‹è¯•
        test_adaptive_router()
        
        # 3. æŒä¹…åŒ–æµ‹è¯•
        test_classifier_persistence()
        
        # 4. çœŸå®æŸ¥è¯¢æµ‹è¯•
        test_real_queries()
        
        # 5. Pipelineé›†æˆæµ‹è¯•
        test_integration_with_pipeline()
        
        print("\nâœ… æ‰€æœ‰æµ‹è¯•å®Œæˆ!")
        print("\nğŸ“ åŠŸèƒ½ç‰¹ç‚¹:")
        print("1. åŸºäºè§„åˆ™çš„æŸ¥è¯¢åˆ†ç±»ï¼ˆäº‹å®æ€§ã€åˆ†ææ€§ã€ç¨‹åºæ€§ï¼‰")
        print("2. æ™ºèƒ½æ£€ç´¢å™¨è·¯ç”±æ¨è")
        print("3. è‡ªé€‚åº”æ€§èƒ½ä¼˜åŒ–")
        print("4. æ”¯æŒä¸­è‹±æ–‡æŸ¥è¯¢")
        print("5. æ¨¡å‹æŒä¹…åŒ–åŠŸèƒ½")
        
    except KeyboardInterrupt:
        print("\nâ¹ï¸ ç”¨æˆ·ä¸­æ–­æµ‹è¯•")
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()