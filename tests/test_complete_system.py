#!/usr/bin/env python
"""
å®Œæ•´FusionRAGç³»ç»Ÿæµ‹è¯•
æµ‹è¯•åŒ…å«æ‰€æœ‰æ¨¡å—çš„å®Œæ•´ç³»ç»ŸåŠŸèƒ½
"""

import sys
import os
sys.path.append('.')

from pipeline import FusionRAGPipeline
from modules.utils.interfaces import Query

def test_complete_system():
    """æµ‹è¯•å®Œæ•´ç³»ç»ŸåŠŸèƒ½"""
    print("ğŸš€ å®Œæ•´FusionRAGç³»ç»Ÿæµ‹è¯•")
    print("=" * 60)
    
    # åˆ›å»ºåŒ…å«æ‰€æœ‰ç»„ä»¶çš„é…ç½®
    config_content = """
data:
  corpus_path: "data/processed/nfcorpus_corpus.jsonl"
  queries_path: "data/processed/nfcorpus_queries.jsonl"
  qrels_path: "data/processed/nfcorpus_qrels.tsv"

retrievers:
  bm25:
    enabled: true
    index_path: "checkpoints/retriever/complete_test_bm25_index.pkl"
    k1: 1.2
    b: 0.75
    top_k: 50
    
  dense:
    enabled: true
    model_name: "sentence-transformers/all-MiniLM-L6-v2"
    index_path: "checkpoints/retriever/complete_test_dense_index.faiss"
    embedding_dim: 384
    top_k: 50
    
  graph:
    enabled: true
    index_path: "checkpoints/retriever/complete_test_graph_index.pkl"
    neo4j_uri: "bolt://localhost:7687"
    neo4j_user: "neo4j"
    neo4j_password: "password"
    database: "neo4j"
    max_walk_length: 2
    entity_threshold: 2
    top_k: 30

classifier:
  enabled: true
  threshold: 0.5
  classes: ["factual", "analytical", "procedural"]
  adaptation_enabled: true
  min_samples: 5
  performance_threshold: 0.1

fusion:
  method: "weighted"
  weights:
    bm25: 0.4
    dense: 0.4
    graph: 0.2
  top_k: 20

evaluation:
  metrics: ["recall@5", "recall@10", "ndcg@10", "map"]

system:
  log_level: "INFO"
  log_path: "checkpoints/logs/complete_test.log"
"""
    
    temp_config = "temp_complete_test_config.yaml"
    with open(temp_config, 'w') as f:
        f.write(config_content)
    
    try:
        # åˆå§‹åŒ–Pipeline
        print("ğŸ“ åˆå§‹åŒ–å®Œæ•´ç³»ç»Ÿ...")
        pipeline = FusionRAGPipeline(temp_config)
        
        # åŠ è½½æ•°æ®
        print("\nğŸ“ åŠ è½½æ•°æ®...")
        pipeline.load_data()
        
        print(f"æ•°æ®æ¦‚å†µ:")
        print(f"  æ–‡æ¡£æ•°: {len(pipeline.documents):,}")
        print(f"  æŸ¥è¯¢æ•°: {len(pipeline.queries):,}")
        print(f"  æ ‡æ³¨æ•°: {len(pipeline.qrels):,}")
        
        # ä½¿ç”¨å°æ•°æ®é›†è¿›è¡Œæµ‹è¯•
        print("\nğŸ”¨ æ„å»ºç´¢å¼•...")
        test_docs = pipeline.documents[:100]  # ä½¿ç”¨100ä¸ªæ–‡æ¡£æµ‹è¯•
        
        for name, retriever in pipeline.retrievers.items():
            print(f"  æ„å»º {name} ç´¢å¼•...")
            retriever.build_index(test_docs)
        
        # æµ‹è¯•æ™ºèƒ½æ£€ç´¢
        print("\nğŸ” æµ‹è¯•æ™ºèƒ½æ£€ç´¢...")
        
        # ä¸åŒç±»å‹çš„æµ‹è¯•æŸ¥è¯¢
        test_queries = [
            # äº‹å®æ€§æŸ¥è¯¢
            Query("fact_1", "What is diabetes?"),
            Query("fact_2", "Define breast cancer"),
            
            # åˆ†ææ€§æŸ¥è¯¢  
            Query("anal_1", "Why do statins cause side effects?"),
            Query("anal_2", "How does obesity affect cardiovascular health?"),
            
            # ç¨‹åºæ€§æŸ¥è¯¢
            Query("proc_1", "Treatment procedure for hypertension"),
            Query("proc_2", "Step by step cancer diagnosis process"),
        ]
        
        all_results = {}
        routing_stats = []
        
        for i, query in enumerate(test_queries):
            print(f"\næŸ¥è¯¢ {i+1}: {query.text}")
            print("-" * 50)
            
            # æ‰§è¡Œæ£€ç´¢
            results = pipeline.search(query, top_k=10)
            all_results[query.query_id] = results
            
            # æ˜¾ç¤ºåˆ†ç±»å’Œè·¯ç”±ä¿¡æ¯
            if pipeline.classifier:
                classification = pipeline.classifier.classify_query(query)
                print(f"  åˆ†ç±»: {classification['predicted_class']} (ç½®ä¿¡åº¦: {classification['confidence']:.3f})")
                print(f"  æ¨èæ£€ç´¢å™¨: {classification['recommended_retrievers']}")
            
            # æ˜¾ç¤ºæ£€ç´¢ç»“æœ
            print(f"  æ£€ç´¢ç»“æœæ•°: {len(results)}")
            for j, result in enumerate(results[:3]):
                print(f"    {j+1}. [{result.final_score:.4f}] {result.document.title[:50]}...")
                print(f"       å„æ£€ç´¢å™¨åˆ†æ•°: {result.individual_scores}")
        
        # è·å–è·¯ç”±ç»Ÿè®¡
        if pipeline.router:
            routing_stats = pipeline.router.get_routing_stats()
            print(f"\nğŸ“Š è·¯ç”±ç»Ÿè®¡:")
            print(f"  è·¯ç”±ä½¿ç”¨: {routing_stats['route_usage']}")
            print(f"  æ€§èƒ½å†å²: {routing_stats['performance_history']}")
        
        # è¯„æµ‹ç³»ç»Ÿæ€§èƒ½
        print(f"\nğŸ“ˆ ç³»ç»Ÿæ€§èƒ½è¯„æµ‹...")
        
        # é€‰æ‹©æœ‰æ ‡æ³¨çš„æŸ¥è¯¢è¿›è¡Œè¯„æµ‹
        eval_queries = [q for q in pipeline.queries if q.query_id in pipeline.qrels][:10]
        eval_results = {}
        
        for query in eval_queries:
            results = pipeline.search(query, top_k=20)
            eval_results[query.query_id] = [r.doc_id for r in results]
        
        # æ„å»ºground truth
        eval_qrels = {qid: pipeline.qrels[qid] for qid in eval_results.keys()}
        
        # æ‰§è¡Œè¯„æµ‹
        metrics = pipeline.evaluator.evaluate_retrieval(eval_results, eval_qrels)
        
        print(f"è¯„æµ‹ç»“æœ ({len(eval_queries)} ä¸ªæŸ¥è¯¢):")
        for metric, score in metrics.items():
            if metric not in ['num_queries', 'timestamp']:
                print(f"  {metric}: {score:.4f}")
        
        # ç»„ä»¶ç»Ÿè®¡
        print(f"\nğŸ”§ ç³»ç»Ÿç»„ä»¶ç»Ÿè®¡:")
        print(f"  å¯ç”¨çš„æ£€ç´¢å™¨: {list(pipeline.retrievers.keys())}")
        print(f"  åˆ†ç±»å™¨çŠ¶æ€: {'å¯ç”¨' if pipeline.classifier else 'ç¦ç”¨'}")
        print(f"  æ™ºèƒ½è·¯ç”±: {'å¯ç”¨' if pipeline.router else 'ç¦ç”¨'}")
        print(f"  èåˆç­–ç•¥: {pipeline.fusion.method if pipeline.fusion else 'None'}")
        
        # å›¾æ£€ç´¢å™¨ç»Ÿè®¡ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if 'graph' in pipeline.retrievers:
            graph_stats = pipeline.retrievers['graph'].get_statistics()
            print(f"  å›¾æ£€ç´¢å™¨ç»Ÿè®¡: {graph_stats}")
        
        print(f"\nâœ… å®Œæ•´ç³»ç»Ÿæµ‹è¯•æˆåŠŸ!")
        
    except Exception as e:
        print(f"\nâŒ ç³»ç»Ÿæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
    
    finally:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        if os.path.exists(temp_config):
            os.remove(temp_config)

def test_component_interaction():
    """æµ‹è¯•ç»„ä»¶é—´äº¤äº’"""
    print("\nğŸ”— ç»„ä»¶äº¤äº’æµ‹è¯•")
    print("=" * 60)
    
    try:
        # æµ‹è¯•å„ç»„ä»¶çš„ååŒå·¥ä½œ
        from modules.classifier.query_classifier import QueryClassifier
        from modules.retriever.bm25_retriever import BM25Retriever
        from modules.retriever.dense_retriever import DenseRetriever
        from modules.fusion.fusion import MultiFusion
        from modules.utils.common import JSONDataLoader
        
        # åŠ è½½æ•°æ®
        loader = JSONDataLoader()
        documents = loader.load_documents("data/processed/nfcorpus_corpus.jsonl")[:50]
        
        # åˆå§‹åŒ–ç»„ä»¶
        classifier = QueryClassifier()
        bm25_retriever = BM25Retriever()
        dense_retriever = DenseRetriever(config={'model_name': 'sentence-transformers/all-MiniLM-L6-v2'})
        fusion = MultiFusion({'method': 'weighted', 'weights': {'bm25': 0.6, 'dense': 0.4}})
        
        # æ„å»ºç´¢å¼•
        bm25_retriever.build_index(documents)
        dense_retriever.build_index(documents)
        
        # æµ‹è¯•æŸ¥è¯¢
        test_query = Query("test", "What causes diabetes mellitus?")
        
        # åˆ†ç±»æŸ¥è¯¢
        classification = classifier.classify_query(test_query)
        print(f"æŸ¥è¯¢åˆ†ç±»ç»“æœ: {classification}")
        
        # åŸºäºåˆ†ç±»ç»“æœé€‰æ‹©æ£€ç´¢å™¨
        recommended = classification['recommended_retrievers']
        print(f"æ¨èæ£€ç´¢å™¨: {recommended}")
        
        # æ‰§è¡Œæ£€ç´¢
        retrieval_results = {}
        
        if 'bm25' in recommended:
            bm25_results = bm25_retriever.retrieve(test_query, top_k=20)
            retrieval_results['bm25'] = bm25_results
            print(f"BM25æ£€ç´¢ç»“æœ: {len(bm25_results)} ä¸ª")
        
        if 'dense' in recommended:
            dense_results = dense_retriever.retrieve(test_query, top_k=20)
            retrieval_results['dense'] = dense_results
            print(f"Denseæ£€ç´¢ç»“æœ: {len(dense_results)} ä¸ª")
        
        # èåˆç»“æœ
        if len(retrieval_results) > 1:
            fused_results = fusion.fuse(retrieval_results, test_query)
            print(f"èåˆåç»“æœ: {len(fused_results)} ä¸ª")
            
            # æ˜¾ç¤ºèåˆç»Ÿè®¡
            fusion_stats = fusion.get_fusion_statistics(fused_results)
            print(f"èåˆç»Ÿè®¡: {fusion_stats}")
        
        print("âœ… ç»„ä»¶äº¤äº’æµ‹è¯•æˆåŠŸ!")
        
    except Exception as e:
        print(f"âŒ ç»„ä»¶äº¤äº’æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ FusionRAGå®Œæ•´ç³»ç»ŸéªŒè¯")
    print("=" * 70)
    
    try:
        # 1. å®Œæ•´ç³»ç»Ÿæµ‹è¯•
        test_complete_system()
        
        # 2. ç»„ä»¶äº¤äº’æµ‹è¯•
        test_component_interaction()
        
        print(f"\nğŸ‰ FusionRAGç³»ç»ŸéªŒè¯å®Œæˆ!")
        print(f"\nğŸ“‹ ç³»ç»Ÿç‰¹æ€§æ€»ç»“:")
        print("âœ… å¤šæ£€ç´¢å™¨èåˆ (BM25 + Dense + Graph)")
        print("âœ… æ™ºèƒ½æŸ¥è¯¢åˆ†ç±»å’Œè·¯ç”±")
        print("âœ… è‡ªé€‚åº”æ€§èƒ½ä¼˜åŒ–")  
        print("âœ… Neo4jå›¾æ•°æ®åº“æ”¯æŒï¼ˆå¯å›é€€åˆ°å†…å­˜æ¨¡å¼ï¼‰")
        print("âœ… æ ‡å‡†åŒ–è¯„æµ‹æŒ‡æ ‡")
        print("âœ… æ¨¡å—åŒ–å¯æ‰©å±•æ¶æ„")
        print("âœ… ä¸­è‹±æ–‡æ”¯æŒ")
        
    except KeyboardInterrupt:
        print(f"\nâ¹ï¸ ç”¨æˆ·ä¸­æ–­æµ‹è¯•")
    except Exception as e:
        print(f"\nâŒ ç³»ç»ŸéªŒè¯å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()