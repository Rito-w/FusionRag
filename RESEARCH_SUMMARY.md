# Multi-Retriever Fusion Strategy Research Summary

## ğŸ¯ Research Overview

This repository contains a comprehensive study on multi-retriever fusion strategies for information retrieval, conducted across 6 BEIR datasets. The research systematically evaluates 8 different fusion strategies and provides empirical evidence that simple linear weighting outperforms complex RRF (Reciprocal Rank Fusion) methods.

## ğŸ“Š Key Experimental Results

### Performance Improvements
- **Quora**: +7% MRR improvement over baseline
- **SciDocs**: +11% MRR improvement over baseline  
- **FiQA**: +8% MRR improvement over baseline

### Main Findings
1. **Simple Linear Weighting > RRF**: Linear weighting consistently outperforms RRF across multiple datasets
2. **Dataset-Specific Strategies**: Different datasets require different fusion approaches
3. **Computational Efficiency**: Simple methods offer better performance-cost trade-offs

## ğŸ”¬ Experimental Framework

### Datasets
- 6 BEIR datasets: fiqa, quora, scidocs, nfcorpus, scifact, arguana
- 50-100 queries per dataset for statistical significance

### Retrievers
- BM25 (sparse retrieval)
- E5-large-v2 (dense vector retrieval)

### Evaluation Metrics
- MRR (Mean Reciprocal Rank)
- NDCG@10
- Precision@10
- Recall@10

## ğŸ“ Repository Structure

```
â”œâ”€â”€ examples/                    # Experiment scripts
â”‚   â”œâ”€â”€ run_smart_baseline.py
â”‚   â”œâ”€â”€ run_fusion_strategy_comparison.py
â”‚   â”œâ”€â”€ run_ablation_experiments.py
â”‚   â””â”€â”€ run_adaptive_fusion.py
â”œâ”€â”€ reports/                     # Experimental results
â”‚   â”œâ”€â”€ smart_baseline_results_*.json
â”‚   â”œâ”€â”€ fusion_strategy_comparison_*.json
â”‚   â””â”€â”€ ablation_results_*.json
â”œâ”€â”€ modules/                     # Core implementation
â”‚   â”œâ”€â”€ adaptive/               # Adaptive fusion strategies
â”‚   â”œâ”€â”€ retriever/             # Retrieval components
â”‚   â””â”€â”€ evaluation/            # Evaluation framework
â”œâ”€â”€ configs/                    # Experiment configurations
â””â”€â”€ data/                      # BEIR datasets
```

## ğŸš€ Quick Start

1. **Install Dependencies**:
   ```bash
   pip install -r requirements.txt
   ```

2. **Download Data**:
   ```bash
   python scripts/download_data.py
   ```

3. **Run Experiments**:
   ```bash
   python examples/run_fusion_strategy_comparison.py
   ```

## ğŸ“ˆ Research Impact

### Technical Contributions
- First systematic comparison of 8 fusion strategies
- Counter-intuitive finding: simple methods outperform complex ones
- Dataset-specific strategy selection principles

### Practical Value
- Engineering guidance for real-world systems
- Computational efficiency advantages
- Cross-domain validation

## ğŸ“ Publication Status

This research is being prepared for submission to AAAI 2025. See `EXPERIMENT_RESULTS_SUMMARY.md` for detailed results and `.kiro/specs/paper-publication-plan/` for publication planning.

## ğŸ”— Related Work

Our approach builds upon recent advances in:
- Multi-retriever fusion (RRF, linear weighting)
- Dense-sparse hybrid retrieval
- Adaptive information retrieval systems

---
*Last Updated: July 20, 2025*
*Research conducted with 24GB RTX 4090 + E5-large-v2 model*