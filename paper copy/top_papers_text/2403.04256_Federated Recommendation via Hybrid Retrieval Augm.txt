Federated Recommendation via Hybrid Retrieval Augmented Generation
Huimin Zeng Zhenrui Yue Qian Jiang Dong Wang
Unversity of Illinois at Urbana-Champaign
{huiminz3, zhenrui3, qianj3, dwang24}@illinois.edu
Abstract
Federated Recommendation (FR) emerges as a
novel paradigm that enables privacy-preserving
recommendations. However, traditional FR sys-
tems usually represent users/items with discrete
identities (IDs), suffering from performance
degradation due to the data sparsity and het-
erogeneity in FR. On the other hand, Large
Language Models (LLMs) as recommenders
have proven effective across various recom-
mendation scenarios. Yet, LLM-based rec-
ommenders encounter challenges such as low
inference efficiency and potential hallucina-
tion, compromising their performance in real-
world scenarios. To this end, we propose GPT-
FedRec , a federated recommendation frame-
work leveraging ChatGPT and a novel hybrid
Retrieval Augmented Generation (RAG) mech-
anism. GPT-FedRec is a two-stage solution.
The first stage is a hybrid retrieval process,
mining ID-based user patterns and text-based
item features. Next, the retrieved results are
converted into text prompts and fed into GPT
for re-ranking. Our proposed hybrid retrieval
mechanism and LLM-based re-rank aims to ex-
tract generalized features from data and exploit
pretrained knowledge within LLM, overcoming
data sparsity and heterogeneity in FR. In addi-
tion, the RAG approach also prevents LLM hal-
lucination, improving the recommendation per-
formance for real-world users. Experimental
results on diverse benchmark datasets demon-
strate the superior performance of GPT-FedRec
against state-of-the-art baseline methods.
1 Introduction
Recommendation systems play a vital role in aiding
users to discover pertinent content of their interests,
such as online commerce (Ying et al., 2018), social
media (Fan et al., 2019). The prevailing strategy in
developing recommendation systems involves ex-
tracting usersâ€™ personalized preferences from their
historical data. However, the concerns on data pri-
vacy have prompted strict regulations on data gov-
Client 1 
Server 
Q: Iâ€™ve watched these 
movies, any 
recommendations? 
A:            11   
Poor generalization on 
cold-start users.  Federated RecSys 
Client 2 User: query with unseen 
movie IDs? 
Data:
Data:
ðŸ˜”
Figure 1: Under data heterogeneity and data sparsity,
traditional ID-based recommenders fail to recommend
correct items to the cold-start users.
ernance (e.g., GDPR1). Such regulations limit the
development of modern recommendation systems.
To address this issue, federated recommenda-
tion (FR) emerges as a new paradigm facilitating
privacy-preserving recommendations (Ammad-Ud-
Din et al., 2019; Zhang et al., 2024). In FR, a cen-
tral server stores a global recommendation model,
while a set of clients contain local private data.
These clients collaboratively train the global model
without sharing their private data. Note that the
concept "client" does not necessarily refer to a sin-
gle human user, but can also represent a local data
server with a small dataset. For clarity, we con-
sistently use "client" to represent a federated
client, and use "user" to denote a human user
of a recommender system.
However, traditional FR systems usually rep-
resent users/items with discrete identities (Zhang
et al., 2024). As such, they may suffer from de-
graded performance, due to the data sparsity and
heterogeneity in the federated setting (Wu et al.,
2022; Zhang et al., 2024). In FR, the clients might
only contain the data of a few or even a single user
(data sparsity). Training an ID-based recommender
on such sparse data is prone to overfitting (Zhang
1General Data Protection Regulation:https://gdpr-info.eu/arXiv:2403.04256v1  [cs.IR]  7 Mar 2024
et al., 2024). Moreover, data sparsity may also trig-
ger data heterogeneity. That is, the item scopes of
local datasets are only subsets of the entire item
scope, and different local clients may have different
item scopes (non-i.i.d. data). As shown in Figure 1,
a test userâ€™s data contains novel items never seen
in the local clients (i.e., a cold-start user). Conse-
quently, the FR system could not make meaningful
recommendations. Since the locally trained models
may never see certain items during training, aggre-
gating such sparsely-trained models results in poor
generalization (Zhang et al., 2024).
On the other hand, large language models
(LLMs) exhibit strong generalization abilities in
diverse tasks, thanks to the extensive knowledge
learned from the massive-scale real-world data. Re-
cently, LLMs as recommenders also demonstrate
impressive performance in different recommenda-
tion tasks (Harte et al., 2023; Li et al., 2023c; Bao
et al., 2023; Zhang et al., 2023; Yue et al., 2023a).
Therefore, employing LLMs for FR has the poten-
tial to address data sparsity and data heterogene-
ity. Yet, existing LLM-based recommenders suf-
fer from issues like incomplete recommendations,
low inference efficiency and potential hallucination
(Yue et al., 2023a; Li et al., 2023b), impairing their
applicability in real-world scenarios. Besides, in
FR, it is neither affordable nor feasible for local
clients to finetune LLMs with limited computa-
tional resources and data. In addition, the next-
word-generating nature of LLMs might generate
irrelevant words in terms of recommendation, lead-
ing to incomplete recommendations and low infer-
ence efficiency (Yue et al., 2023a). Finally, as a
consequence of hallucination, LLM-based recom-
menders may recommend non-existing or make-up
items, compromising user experience in real-world
applications.
To this end, in this work, we propose GPT-
FedRec, a novel and effective two-stage frame-
work for federated recommendation. Leveraging
both the generalized features within training data
and pretrained knowledge within LLMs (e.g., Chat-
GPT), GPT-FedRec not only provides a complete
solution in a data sparse and heterogeneous FR set-
ting, but also outperforms existing methods with
improved recommendation performance.
As shown in Figure 2, GPT-FedRec operates in
two stages. The first stage employs a novel hybrid
retrieval mechanism to generate recommendation
candidates using generalized data features. We pro-
pose to adopt small-scale ID-based retrievers tocapture the ID-based user patterns, and dense text-
based retrievers to extract robust and generalized
semantic features from item descriptions. The ra-
tionale behind this design is: while the ID-based
user history is informative in terms of representing
user-item dynamics, the textual item descriptions
(e.g., titles, categories) contain more generalized
semantic features. Leveraging such generalized
features improves generalization of the recommen-
dation, especially in data-sparse and heterogeneous
FR settings (Zhang et al., 2024). Consider the
movie recommendation in Figure 1. The descrip-
tions of these movies provide more information for
the recommender: the movies watched by the new
user could be depicted in texts like "war, action
movies", which is semantically closer to the "sci-fi,
action movies" on client 2, compared to the "love,
romantic movies" on client 1. In the second stage,
the retrieved candidates are fed into an LLM for
re-ranking. This process leverages the pretrained
generalized knowledge of LLM, thereby further
improving the generalization of the recommenda-
tion. Moreover, conditioning LLM re-rank on the
first-stage results effectively prevents hallucination.
This enhances recommendation performance for
real-world users. Finally, due to space limit, we
narrow down the scope of this work to the sequen-
tial recommendation, for its superior performance
over traditional recommendater systems (e.g., ma-
trix factorization). We summarize the contributions
of our paper as follows2:
1.To the best of our knowledge, GPT-FedRec is
the first FR framework that uses hybrid RAG
and LLMs. More importantly, GPT-FedRec
withstands the critical challenge of data spar-
sity and data heterogeneity in FR, achieving
promising performance.
2.Technically, GPT-FedRec employs arbitrary
ID-based retriever and arbitrary text-based re-
triever to perform the hybrid retrieval. More-
over, as a RAG method, GPT-FedRec does
not require the finefuning of the LLMs.
3.We evaluate GPT-FedRec in the FR setting.
On different benchmark datasets, experimen-
tal results suggest that GPT-FedRec achieves
considerable improvements in recommenda-
tion performance, while outperforming state-
of-the-art baselines.
2We adopt publicly available datasets and release the code
athttps://github.com/huiminzeng/GPT-FedRec.git .
Text Description  
(e.g. movie titles, genres) ID-based 
Retriever 
Text-based 
Retriever  Hybrid Retrieval 
ID 1ID 2ID 3
    Prompt 
### Iâ€™ve watched the 
following movies in the past 
in order: {history} . 
### There is also candidate 
pool: { candidates }. 
### { task instruction }
RAG-based Re-ranking 
Parse outputs 
Re-ranked 
Candidates Figure 2: GPT-FedRec. The first stage involves a hybrid retrieval with an ID-based retriever and a text-based
retriever. The second stage performs re-ranking via the retrieved results and RAG of the prompted GPT.
2 Related Work
Federated Recommendation. Existing feder-
ated recommendation (FR) systems are usually
ID-based models: users/items are represented
with unique identities (IDs). For instance, FCF
(Ammad-Ud-Din et al., 2019), FedRec (Lin et al.,
2020), FedMF (Chai et al., 2020) extend classic
ID-based matrix factorization into federated mode.
In comparison, Wu et al. (2022) train ID-based
sequential recommenders to domain-disentangled
features in a federated fashion, achieving better per-
formance. Luo et al. (2022) aggregates ID-based
model with a client utility-aware protocol for better
federated recommendation. However, in heteroge-
neous settings, these ID-based FR methods could
not generalize well to cold-start users, because the
items in the cold-start user data might never be
seen during training (Zhang et al., 2024). Target-
ing at this issue, Zhang et al. (2024) proposed a
text-based FR solution, namely TransFR. Trained
using textual features, TransFR demonstrates bet-
ter generalization on heterogeneous FR settings.
However, TransFR suffers from data sparsity and is
not capable of handling long user-item sequences.
Compared to existing FR methods, the hybrid re-
trieval mechanism in GPT-FedRec is designed to
address the data sparsity and heterogeneity in FR.
Unlike TransFR, GPT-FedRec is capable of model-
ing long sequences.
Natural Language for Recommendation. The
inherent generality of textual features empowered
the generalizability and transferability of recom-
menders. For instance, to achieve better transfer-
ability, Hou et al. (2023a, 2022) train sequential rec-
ommenders using language-model-encoded item
texts. Similary, in (Li et al., 2023a; Geng et al.,
2022), pretrained language models are finetuned
using item descriptions and then used as recom-
menders. These text-based recommender systemsdemonstrate state-of-the-art generalizability in dif-
ferent recommendation scenarios. However, they
usually require rich textual data to enable fine-
funing and could not handle long user histories.
On the other hand, LLMs as recommenders have
gained increased attention for LLMsâ€™ impressive
generalization ability. The mainstream LLM-based
recommenders exploits the pretrained knowledge
within LLMs to perform next-item recommenda-
tion (Hou et al., 2023b; Sileo et al., 2022; Sun
et al., 2023; He et al., 2023). For example, He
et al. (2023) employees LLMs as conversational
agents to understand user preferences and improve
recommendation. Another stream of LLM-based
recommendation designs tuning strategies tailored
for specific subtasks (e.g., rating prediction) to im-
prove recommendation performance (Chen, 2023;
Kang et al., 2023; Yue et al., 2023a). However, ex-
isting LLM-based recommenders mainly generate
recommendation candidates in an autoregressive
fashion. As such, the generated content might be
irrelevant to the items of interests or even are hallu-
cinated, leading to undesired performance in real-
world applications. As such, we design a retrieval
augmented recommendation framework, where the
RAG approach effectively reduces hallucination
and improves recommendation performance.
3 Preliminaries
Data. We adopt the sequential recommendation
setting to illustrate the data format. In sequential
recommendation, a data point is the historical data
of a user: a sequence of interacted items x(sorted
by timestamps) within her history. A sequence xis
a list of items [x1, x2, ..., x l]of length l. Each ele-
ment in xbelongs to the item scope Ithat contains
all items: xiâˆˆ I. The goal of a recommender is
to predict the next user-item interaction xl+1âˆˆ I
based on the user history x. In our experiments,
xl+1is used as ground truth y(i.e.,y=xl+1).
Model. An ID-based recommender directly takes
item sequences as input, and maps them into new
items as recommendations. Given an input se-
quence x, an ID-based recommender computes a
score vector over the item scope I, and recom-
mends items with highest probabilities. In compar-
ison, a text-based recommender usually transforms
discrete item IDs into descriptions: transforming a
sequence of items ( x) into a sequence of descrip-
tions. After trained on such text sequences, the
text-based recommender generates textual IDs (i.e.,
IDs in text format) or item titles as the final recom-
mendation.
Federated Recommendation. In FR, a central
server stores a global recommender, while a set of
local clients store their respective datasets. The
goal of FR is to collaboratively train the global rec-
ommender without clients sharing their private data.
Assume there are Kclients in an FR application.
Each client contains a local dataset Dkwith|Dk|
item sequences. In FR, the item scopes covered
by local datasets may be smaller than the entire
item scope: IkâŠ† I andâˆªkIkâŠ† I (data spar-
sity). In addition, some local clients may contain
unique items only present in their datasets (data het-
erogeneity). The test user can also introduce new,
unseen items (i.e., cold-start users). As in Figure 1,
the clients contain disjoint movies, and the test user
data involves new, unseen movies. Therefore, the
challenges of data sparsity, data heterogeneity and
non-generalizabilty on cold-start users drive the
development of GPT-FedRec. For simplicity, un-
less specified, notations without client index k
represent the data of an arbitrary client.
4 Algorithm
The overview of GPT-FedRec is in Figure 2. To
address the aforementioned challenges, we firstly
develop a hybrid retrieval mechanism using a small-
scale ID-based retriever and a dense text-based
retriever to retrieve generalized candidates (Sec-
tion 4.1). Then, based on the retrieved results, we
establish a retrieval augmented recommendation
pipeline using LLMs (Section 4.2).
4.1 Hybrid Retrieval
ID-based Retriever. Given existing ID-based
recommenders, any of them could be used by GPT-
FedRec to retrieve potential candidates. In our
implementation, we choose LRURec (Yue et al.,
2023b) as the ID-based retriever for its state-of-the-art performance and light-weight design, avoiding
extra communication costs in FR settings.
Formally, we define the ID-based retriever as fI,
parameterized by Î¸I. As shown in Figure 2, for
a piece of user data, fItakes its interacted item
sequence xas input, i.e., fI(x).fIreturns a vec-
tor of similarity scores over the item scope I. To
train LRURec on each local client, we optimize the
cross-entropy loss over the local dataset:
Lce=E(x,y)âˆ¼Dk[L(fI(x), y)]. (1)
During federated training, the weights of fIare
sent to the global server for aggregation. However,
it is foreseeable that in a data sparse and data het-
erogeneous setting, the predicted scores returned
by a local fIare skewed towards the items present
in its local dataset. That is, a locally trained fIis
prone to retrieve the items present its local datasets,
rendering its unsatisfactory performance on test
data with unseen new items.
Text-based Retriever. In the data sparse and
data heterogeneous FR setting, the inadequacy of
ID-based retriever motivates us to employ an ad-
ditional dense, more generalizable text-based re-
triever to build GPT-FedRec. To illustrate the ne-
cessity of using text-based retriever, consider the
example in Figure 1. In this example, client 1,
client 2 and the test user have mutually exclusive
item scopes. This is a typical data heterogeneous
case. In the discrete ID space, a movie with a spe-
cific ID can only appear in one party. An ID-based
retriever would fail to capture the correlation be-
tween some movie IDs cross parties, leading to
degraded performance. In a sharp contrast, in the
text space, the movies across these parties may still
share common, generalized features (e.g., "war,
action movies" of the new user and "sci-fi, war
movies" on client 2), despite the different movie
IDs. As such, text-based retriever could capture
such generalized features, overcoming data hetero-
geneity that defects ID-based retrievers.
To this end, we propose to use E5 (Wang
et al., 2022) as the text-based retriever. E5 is a
transformer-based language model, pretrained for
text-retrieval tasks. Formally, we define the text-
based retriever as fT, parameterized by Î¸T.
To adapt E5 into our FR application, we finetune
it using text descriptions of items and the InfoNCE
loss (Oord et al., 2018) on each local client. In par-
ticular, for each training sample x= [x1, x2, ..., x l]
and its ground-truth item y, we firstly transform
Text Description  
(e.g. movie titles, genres) ID-based 
Retriever 
Txt-R.
Client 1  Client 2  Client 3 
Text-based 
Retriever  Client Training 
ID-R. 
ID 1ID 2ID 3
CE
InfoNCE Global Aggregation Figure 3: The training and aggregation process of GPT-FedRec. On clients, the ID-based retriever and the text-based
retriever are trained using local data.
them into input texts tand ground-truth text ty
using the item meta data (e.g., titles, categories,
genres of the items) using the E5 template.
t= [t1, t2, ..., t l],where ti=Template 1(xi),
ty=Template 2(y).
(2)
In Equation 2, Template 1is the E5 template with
"query" as prefix, Template 2is the E5 template
with "passage" as prefix. (More details about E5
templates in Appendix B.) Then, with prepared text
templates, fTis finetuned with the InfoICE loss:
Linfo=
âˆ’1
|D||D|X
mloges(q(m),p(m))
es(q(m),p(m))+P
nes(q(m),Â¯p(n)),
where
q=fT(t), p=fT(ty),Â¯p=fT(Â¯y),Â¯yâˆˆ I \ y
(3)
In Equation 3, we use superscript (m)to index dif-
ferent users (not client). As for s(q, p), it refers to
a scoring function between the encoded query q
and an encoded positive passage por negative pas-
sage Â¯p. In our implementation, the score function
is cosine similarity scaled by a temperature Ï„:
s(p, q) = cos( p, q)/Ï„. (4)
By finetuning E5 using Equation 3, the text-based
retriever learns to assign high similarity between
user sequences and their ground-truth items in the
text space. More importantly, since E5 is pre-
trained, it has already encoded prior knowledge
of language patterns. Therefore, the text-based re-
triever is capable of extracting generalized textual
features from item descriptions, despite the data
sparsity and data heterogeneity across clients.
Finally, after training the ID-based retriever ( fk
I)
and the text-based retriever ( fk
T) on each localclient, we adopt FedAvg (McMahan et al., 2017)
to perform global model aggregation, obtaining the
global ID-based retriever and text-based retriever:
Î¸âˆ—
(Â·)=1P
k|Dk|KX
k=1|Dk| Â·Î¸k
(Â·)
s.t. Î¸k
I= arg min Lce(Dk, fI),
Î¸k
T= arg min Linfo(Dk, fT),
kâˆˆ {1, ..., K}.(5)
Hybrid Retrieval. To generate the retrieval re-
sults for any user sequence x, we compute a
weighted sum of the normalized prediction scores
returned by the aggregated ID-based retriever and
text-based retriever through the Tikhonov principle
(Tikhonov, 1963):
Ë†Phybrid =Î»Â·Ïƒ(fI(x)) + (1 âˆ’Î»)Â·Ïƒ(fT(t)),
(6)
where Ïƒis the softmax opernation. Then, the items
of top-N scores within Ë†Phybrid are retrieved as can-
didates. These candidates form a candidate set Ë†I.
Ë†Iis the result of the first stage of GPT-FedRec.
We highlight that the candidate set Ë†Iis retrieved
based on the hybrid scores Ë†Phybrid . Compared to
traditional ID-based FR models, the hybrid scores
incorporate both domain-generalized features from
the text-based retriever and the representative ID-
based user patterns. As such, GPT-FedRec is
equipped with generalization ability by design, and
can overcome the data sparsity and data hetero-
geneity issue in FR applications, achieving better
recommendation performance.
4.2 Hybrid Retrieval Augmented Generation
RAG-based Recommendation. After the hybrid
retrieval stage, GPT-FedRec further employs an
LLM to perform re-ranking among the retrieved
candidates within Ë†I. This design is to exploit the
pretrained knowledge encoded in LLMs, so that
the generalization of recommendations is further
enhanced. Moreover, the re-ranking process of the
LLM is conditioned on the retrieved results, hallu-
cination could be effectively avoided: the LLM is
explicitly instructed to only re-rank the candidates
within Ë†I, and they are retrieved from real-world
data during the first stage. Finally, for efficiency,
we intend to prompt an LLM for recommendation
without finetuning it, and treat the LLM-based re-
ranking process as retrieval augmented generation
(De Cao et al., 2020; Tay et al., 2022).
LLM. In this work, we adopt GPT-3.5-Turbo
(OpenAI) from OpenAI to build GPT-FedRec.
GPT-3.5-Turbo is a closed-source LLM with abil-
ities of solving many complex tasks (OpenAI).
Since in a data sparse FR setting, it is infeasible to
finetune LLM using such limited data, we select
GPT-3.5-Turbo for its powerful zero-shot general-
ization ability.
To construct a text prompt for GPT-3.5-Turbo,
inspired by (Hou et al., 2023b), we start it with a
description of both user history and candidate item
using their titles and categories/genres. Then, an in-
struction to the task is appended to the description.
In addition to the text prompts, we also feed sys-
tem prompts to GPT, so that its mindset is adjusted
to the concrete recommendation application (e.g.,
recommending movies or cosmetics). A simplifed
prompt template looks like:
### system: You are a helpful { role },
{role description }.
### user: Iâ€™ve browsed the fol-
lowing items in the past in order:
{history }. There is also candidate pool:
{candidates }. {task instruction }.
In the above template, role and role
description are replaced with a concrete real-
world job (e.g., shopping assistant) and its job de-
scription (e.g., recommending products for cus-
tomers). history is instantiated as item texts
containing item titles, possibly with item cat-
egories/genres. As for candidates , it is re-
placed with the hybrid retrieval results. task
instruction shall be replaced with a direct re-
rank instruction. We also add additional formatting
instructions in the template for post-processing pur-
poses. The detailed, complete prompt template is
summarized in Appendix B.Post-processing. As mentioned, we do not ac-
cess the model weights or output logits of LLMs.
The re-rank results are generated in free texts (e.g.,
item titles) despite the formatting instructions in
the prompts. Therefore, we apply fuzzy matching
to transform the generated textual recommenda-
tions (e.g., item titles) into a ranked list of item IDs:
Ë†IRAG to perform evaluation.
5 Experiments
5.1 Experimental Setup
Datasets. We select 5 benchmark datasets from
different domains to evaluate GPT-FedRec. They
are Beauty, Games, Toys, Auto (He and McAuley,
2016; McAuley et al., 2015) and ML-100K (Harper
and Konstan, 2015). The first four datasets are
Amazon review datasets consisting of user feed-
back on different categories of products. ML-100K
is a benchmark movie recommendation dataset.
Following (Chen, 2023; Yue et al., 2022), we pre-
process the raw data with 5-core, and construct
training sequences in chronological order. The de-
tailed dataset statistics are in Table 3 (Appendix A).
Baselines. We adopt three groups of baseline
methods for comparison. (1) Group 1: ID-based FR
models, namely FedSAS, FedLRU and CF-FedSR.
FedSAS and FedLRU are federated version of SAS-
Rec (Kang and McAuley, 2018) and LRURec (Yue
et al., 2023b) with FedAvg (McMahan et al., 2017)
as the aggregation protocol. CF-FedSR (Luo et al.,
2022) uses a client utility-aware aggregation proto-
col for better FR. (2) Group 2: Text-based models,
i.e., TransFR (Zhang et al., 2024), P5 (Geng et al.,
2022) and RecFmr (Li et al., 2023a) and UniSR T
(Hou et al., 2022). TransFR trains a BERT-like
retriever. UniSR Ttrains SASRec using BERT-
encoded item texts. P5 and RecFmr finetune pre-
trained T5 or LongFormer with item texts and use
the model as recommender. (3) Group 3: The hy-
brid UniSR IT(Hou et al., 2022), an ID-augmented
version of UniSR T. Note that P5, RecFmr, UniSR T
and UniSR ITare not originally designed for FR.
We use FedAvg as the aggregation protocol to ex-
tend them into our FR setting. We did not include
LLM-based recommenders as baselines, because
existing LLM-based recommenders solely focus on
the ranking stage, and could not provide a complete
solution for FR: they can only rank ground-truth
items along with other sampled negative items. The
can not generate candidates from the entire item
scope from scratch, which is required by FR.
Dataset MetricID-Based Text-Based Hybrid
FedSAS FedLRU CF-FedSR TransFR P5 RecFmr. UniSR TUniSR IT GPT-FedRec
BeautyR@5â†‘ 0.0153 0.0218 0.0204 0.0059 0.0013 0.0313 0.0231 0.0247 0.0348
N@5â†‘ 0.0101 0.0145 0.0138 0.0037 0.0007 0.0167 0.0159 0.0166 0.0233
R@10 â†‘ 0.0241 0.0336 0.0306 0.0088 0.0024 0.0533 0.0347 0.0349 0.0563
N@10 â†‘ 0.0129 0.0183 0.0170 0.0047 0.0011 0.0238 0.0196 0.0199 0.0302
GamesR@5â†‘ 0.0289 0.0391 0.0366 0.0059 0.0019 0.0399 0.0327 0.0412 0.0471
N@5â†‘ 0.0195 0.0257 0.0235 0.0037 0.0010 0.0227 0.0218 0.0274 0.0331
R@10 â†‘ 0.0419 0.0613 0.0560 0.0096 0.0042 0.0706 0.0522 0.0621 0.0764
N@10 â†‘ 0.0237 0.0329 0.0298 0.0049 0.0017 0.0326 0.0281 0.0342 0.0406
ToysR@5â†‘ 0.0094 0.0182 0.0162 0.0067 0.0156 0.0476 0.0323 0.0183 0.0419
N@5â†‘ 0.0070 0.0133 0.0125 0.0043 0.0080 0.0250 0.0225 0.0125 0.0268
R@10 â†‘ 0.0124 0.0243 0.0211 0.0106 0.0240 0.0739 0.0495 0.0271 0.0720
N@10 â†‘ 0.0080 0.0153 0.0141 0.0055 0.0107 0.0355 0.0280 0.0155 0.0364
AutoR@5â†‘ 0.0214 0.0607 0.0464 0.0107 0.0060 0.0536 0.0500 0.0464 0.0643
N@5â†‘ 0.0138 0.0341 0.0294 0.0072 0.0027 0.0264 0.0324 0.0372 0.0390
R@10 â†‘ 0.0357 0.0786 0.0679 0.0143 0.0083 0.0750 0.0679 0.0821 0.0964
N@10 â†‘ 0.0187 0.0398 0.0361 0.0085 0.0035 0.0332 0.0384 0.0488 0.0492
ML-100KR@5â†‘ 0.0183 0.0459 0.0550 0.0092 0.0002 0.0001 0.0183 0.0183 0.0642
N@5â†‘ 0.0085 0.0327 0.0402 0.0035 0.0001 0.0001 0.0150 0.0075 0.0362
R@10 â†‘ 0.0367 0.1101 0.1009 0.0092 0.0002 0.0091 0.0183 0.0459 0.1468
N@10 â†‘ 0.0145 0.0538 0.0550 0.0035 0.0001 0.0031 0.0150 0.0166 0.0621
AverageR@5â†‘ 0.0187 0.0371 0.0350 0.0077 0.0050 0.0345 0.0313 0.0298 0.0505
N@5â†‘ 0.0118 0.0241 0.0239 0.0045 0.0025 0.0182 0.0215 0.0202 0.0313
R@10 â†‘ 0.0302 0.0616 0.0553 0.0105 0.0070 0.0546 0.0445 0.0504 0.0896
N@10 â†‘ 0.0156 0.0320 0.0304 0.0054 0.0034 0.0256 0.0258 0.0270 0.0437
Table 1: Main results on recommendation performance under different FR schemes. The best results are highlighted
in bold and the second best results are highlighted with underline.
FR Setup. Since the training of some baseline
methods could not converge under a large num-
ber of clients, we compare all methods under a
setting of 5 clients. Moreover, to simulate data
sparsity and data heterogeneity, the local datasets
are sparsely sampled from the original datasets and
are guaranteed to be mutually exclusive in terms
of users. The remaining users are used as cold-
start test users. The detailed local datasets statistics
are summarized in Table 4 (Appendix A). Note
that the test users in our FR setting are cold-start
users, whose historical data are not used for model
training. This is fundamentally different from the
common centralized sequential recommendation
setting, where the historical data of all users are
used to train the model with the last item used for
testing. Our cold-start setting is more realistic in
the FR setting, and also more appropriate to test
the generalization of the trained FR model.
Implementation. To implement GPT-FedRec,
we train LRURec from scratch, and finetune the
pretrained E5 ( e5-base-v2 ) using the training data.
When training LRURec, the learning rate is initial-
ized as 1e-3, and the number of local/global epochsis 80/5 (for Beauty, Games, Toys) and 60/5 (for
Auto and ML-100k). As for E5, the learning rate is
initialized as 1e-6, and the number of local/global
epochs is 2/2. We use AdamW as the optimizer
for both LRURec and E5. When generating the
candidate set Ë†Iin the first stage, we pick the top-20
items from the hybrid score Ë†Phybrid . To evaluate
the recommendation performance, we select the
commonly used normalized discounted cumula-
tive gain (NDCG@N) and recall (Recall@N) with
Nâˆˆ[5,10]. The predictions are ranked against all
items in the dataset. More implementation details
on baseline methods are in Appendix A.
5.2 Evaluation: Overall Recommendation
Performance
The first set of results are reported in Table 1,
where we compare the recommendation perfor-
mance of all schemes. In Table 1, for clarity, we
highlight the best results in bold and underline the
second best results. Note that the ranking results
are from the entire item scope (i.e., a complete
ranking of all items). From Table 1, it is observed:
(1) GPT-FedRec generally achieves better recom-
00.1 0.3 0.5 0.7 0.9 1.00.010.020.030.040.050.06PerformanceR@5 N@5 R@10 N@10
00.1 0.3 0.5 0.7 0.9 1.00.020.040.06
(a) Beauty
00.1 0.3 0.5 0.7 0.9 1.00.0000.0250.0500.075
 (b) Games
00.1 0.3 0.5 0.7 0.9 1.00.000.020.040.06
(c) Toys
00.1 0.3 0.5 0.7 0.9 1.00.000.050.10
 (d) ML-100K
Figure 4: Sensitivity Analysis. We change Î»in Equa-
tion 6, and evaluate the recommendation performance
based on the hybrid retrieval results of stage 1.
mendation performance than the baseline meth-
ods. For instance, compared to the second best
baseline method over all datasets, GPT-FedRec
achieves 36.12%, 29.88%, 45.44% and 36.56%
average improvements w.r.t. all 4 metrics, respec-
tively. (2) GPT-FedRec achieves satisfying perfor-
mance on ML-100K, whereas some baseline meth-
ods, especially text-based ones, could barely con-
verge. This is expected, because some of them (e.g.,
RecFmr, UniSR) are pretrained using Amazon re-
view datasets, whose domain is different from the
domain of movie recommendation. Moreover, the
user history of ML-100K is much longer than that
in Amazon review datasets. Since the text-based
baseline methods could not handle long user his-
tory, they are prone to suffer from performance
degradation. On the contrary, GPT-FedRec lever-
ages hybrid retrieval and exploits the pre-trained
knowledge in LLMs, thus enjoying a more compre-
hensive understanding of user preferences.
5.3 Sensitivity Analysis
In this section, we conduct a sensitivity analysis
w.r.t. Î±in Equation 63. This is a key factor affect-
ing the hybrid retrieval before LLM. In particular,
we change it from 0to1and keep other configura-
tions the same. The results are shown in Figure 4.
We observe that the balance between ID-based re-
trieval and text-based retrieval play an important
role in terms of hybrid retrieval. As shown in Fig-
ure 4, there exists an optimal Î±between 0and1
for different datasets respectively, indicating the
necessity of hybrid retrieval in GPT-FedRec.
3Due to the limit budget of calling GPT API, we only
perform sensitivity analysis for the first stage of GPT-FedRec.Dataset Metric GPT-FedRec w/o LRU w/o E5 w/o LLM
BeautyR@5â†‘ 0.0348 0.0306 0.0254 0.0348
N@5â†‘ 0.0233 0.0203 0.0156 0.0232
R@10 â†‘ 0.0563 0.0504 0.0478 0.0520
N@10 â†‘ 0.0302 0.0267 0.0227 0.0288
GamesR@5â†‘ 0.0471 0.0425 0.0438 0.0435
N@5â†‘ 0.0331 0.0259 0.0290 0.0281
R@10 â†‘ 0.0764 0.0779 0.0722 0.0689
N@10 â†‘ 0.0406 0.0372 0.0381 0.0364
Table 2: Ablation Study. We mask out different com-
ponents of GPT-FedRec separately, and evaluate the
recommendation performance.
5.4 Ablation Study
Finally, we conduct an ablation study to evalu-
ate the contribution of each key module of GPT-
FedRec, namely the hybrid retrieval in the first
stage and the LLM-based re-ranking in the second
stage. The results are reported in Table 2. In Ta-
ble 2, w/o LRU refers to GPT-FedRec only with E5
as retriever in the first stage, and w/o E5 indicates
that there is only LRURec in the first stage. w/o
LLM represents GPT-FedRec without the LLM-
based re-rank. As expected, we observe that both
hybrid retrieval and LLM-based re-ranking con-
tributes to a better recommendation performance.
For instance, without either module, the recommen-
dation performance basically drops. Such results
also validate the merit of our design: our hybrid re-
trieval mechanism and the LLM-based re-ranking
are indeed effective in terms of addressing the data
sparsity and data heterogeneity in FR, which leads
to better recommendation performance.
6 Conclusion
This work presents a novel federated recommen-
dation framework that exploits ChatGPT and a
novel hybrid retrieval mechanism. GPT-FedRec
provides an effective privacy-aware solution to
build a recommender system for data-sparse and
data-heterogeneous federated recommendation sce-
narios. We highlight the significance of this work:
despite the active research on federated recommen-
dation, existing methods largely suffer from the
data sparsity and data heterogeneity issue in FR.
In contrast, our work is deliberately designed to
overcome such an issue, achieving generalized rec-
ommendation performance. Finally, within GPT-
FedRec, there is also a hybrid RAG mechanism
to prevent LLM hallucination, improving the au-
thenticity of recommendation results in real-world
applications.
7 Limitations
One limitation of this work is that our method in-
troduces extra hyperparameters. For different ap-
plications, one might need to finetune these hy-
perparameters, which brings extra computational
cost. Another limitation of this work is that our
method does not take the inherent bias of GPT into
account. However, it is known that such pretrained
LLMs usually have encoded the bias in the pre-
training data (e.g., stereotypical data, racism and
hate speech). Such bias could have negative ethical
implications on the downstream FR applications.
Therefore, a future research direction is to develop
a benign and fair FR framework.
References
Muhammad Ammad-Ud-Din, Elena Ivannikova,
Suleiman A Khan, Were Oyomno, Qiang Fu,
Kuan Eeik Tan, and Adrian Flanagan. 2019. Feder-
ated collaborative filtering for privacy-preserving
personalized recommendation system. arXiv
preprint arXiv:1901.09888 .
Keqin Bao, Jizhi Zhang, Yang Zhang, Wenjie Wang,
Fuli Feng, and Xiangnan He. 2023. Tallrec: An effec-
tive and efficient tuning framework to align large lan-
guage model with recommendation. arXiv preprint
arXiv:2305.00447 .
Di Chai, Leye Wang, Kai Chen, and Qiang Yang. 2020.
Secure federated matrix factorization. IEEE Intelli-
gent Systems , 36(5):11â€“20.
Zheng Chen. 2023. Palr: Personalization aware llms for
recommendation. arXiv preprint arXiv:2305.07622 .
Nicola De Cao, Gautier Izacard, Sebastian Riedel, and
Fabio Petroni. 2020. Autoregressive entity retrieval.
arXiv preprint arXiv:2010.00904 .
Wenqi Fan, Yao Ma, Qing Li, Yuan He, Eric Zhao,
Jiliang Tang, and Dawei Yin. 2019. Graph neural
networks for social recommendation. In The world
wide web conference , pages 417â€“426.
Shijie Geng, Shuchang Liu, Zuohui Fu, Yingqiang Ge,
and Yongfeng Zhang. 2022. Recommendation as
language processing (rlp): A unified pretrain, person-
alized prompt & predict paradigm (p5). In Proceed-
ings of the 16th ACM Conference on Recommender
Systems , pages 299â€“315.
F Maxwell Harper and Joseph A Konstan. 2015. The
movielens datasets: History and context. Acm trans-
actions on interactive intelligent systems (tiis) , 5(4):1â€“
19.
Jesse Harte, Wouter Zorgdrager, Panos Louridas, As-
terios Katsifodimos, Dietmar Jannach, and Marios
Fragkoulis. 2023. Leveraging large language modelsfor sequential recommendation. In Proceedings of
the 17th ACM Conference on Recommender Systems ,
pages 1096â€“1102.
Ruining He and Julian McAuley. 2016. Ups and downs:
Modeling the visual evolution of fashion trends with
one-class collaborative filtering. In proceedings of
the 25th international conference on world wide web ,
pages 507â€“517.
Zhankui He, Zhouhang Xie, Rahul Jha, Harald Steck,
Dawen Liang, Yesu Feng, Bodhisattwa Prasad Ma-
jumder, Nathan Kallus, and Julian McAuley. 2023.
Large language models as zero-shot conversational
recommenders. In Proceedings of the 32nd ACM
international conference on information and knowl-
edge management , pages 720â€“730.
Yupeng Hou, Zhankui He, Julian McAuley, and
Wayne Xin Zhao. 2023a. Learning vector-quantized
item representation for transferable sequential recom-
menders. In Proceedings of the ACM Web Confer-
ence 2023 , pages 1162â€“1171.
Yupeng Hou, Shanlei Mu, Wayne Xin Zhao, Yaliang
Li, Bolin Ding, and Ji-Rong Wen. 2022. Towards
universal sequence representation learning for recom-
mender systems. In Proceedings of the 28th ACM
SIGKDD Conference on Knowledge Discovery and
Data Mining , pages 585â€“593.
Yupeng Hou, Junjie Zhang, Zihan Lin, Hongyu Lu,
Ruobing Xie, Julian McAuley, and Wayne Xin
Zhao. 2023b. Large language models are zero-shot
rankers for recommender systems. arXiv preprint
arXiv:2305.08845 .
Wang-Cheng Kang and Julian McAuley. 2018. Self-
attentive sequential recommendation. In 2018 IEEE
International Conference on Data Mining (ICDM) ,
pages 197â€“206. IEEE.
Wang-Cheng Kang, Jianmo Ni, Nikhil Mehta, Mah-
eswaran Sathiamoorthy, Lichan Hong, Ed Chi, and
Derek Zhiyuan Cheng. 2023. Do llms understand
user preferences? evaluating llms on user rating pre-
diction. arXiv preprint arXiv:2305.06474 .
Jiacheng Li, Ming Wang, Jin Li, Jinmiao Fu, Xin
Shen, Jingbo Shang, and Julian McAuley. 2023a.
Text is all you need: Learning language representa-
tions for sequential recommendation. arXiv preprint
arXiv:2305.13731 .
Lei Li, Yongfeng Zhang, Dugang Liu, and Li Chen.
2023b. Large language models for generative rec-
ommendation: A survey and visionary discussions.
arXiv preprint arXiv:2309.01157 .
Zhiyu Li, Yanfang Chen, Xuan Zhang, and Xun Liang.
2023c. Bookgpt: A general framework for book rec-
ommendation empowered by large language model.
Electronics , 12(22):4654.
Guanyu Lin, Feng Liang, Weike Pan, and Zhong Ming.
2020. Fedrec: Federated recommendation with ex-
plicit feedback. IEEE Intelligent Systems , 36(5):21â€“
30.
Sichun Luo, Yuanzhang Xiao, Yang Liu, Congduan
Li, and Linqi Song. 2022. Towards communication
efficient and fair federated personalized sequential
recommendation. In 2022 5th International Con-
ference on Information Communication and Signal
Processing (ICICSP) , pages 1â€“6. IEEE.
Julian McAuley, Christopher Targett, Qinfeng Shi, and
Anton Van Den Hengel. 2015. Image-based recom-
mendations on styles and substitutes. In Proceedings
of the 38th international ACM SIGIR conference on
research and development in information retrieval ,
pages 43â€“52.
Brendan McMahan, Eider Moore, Daniel Ramage,
Seth Hampson, and Blaise Aguera y Arcas. 2017.
Communication-efficient learning of deep networks
from decentralized data. In Artificial intelligence and
statistics , pages 1273â€“1282. PMLR.
Aaron van den Oord, Yazhe Li, and Oriol Vinyals. 2018.
Representation learning with contrastive predictive
coding. arXiv preprint arXiv:1807.03748 .
OpenAI. Chatgpt: Optimizing language models for
dialogue. openai.
Damien Sileo, Wout V ossen, and Robbe Raymaekers.
2022. Zero-shot recommendation as language mod-
eling. In European Conference on Information Re-
trieval , pages 223â€“230. Springer.
Weiwei Sun, Lingyong Yan, Xinyu Ma, Pengjie
Ren, Dawei Yin, and Zhaochun Ren. 2023. Is
chatgpt good at search? investigating large lan-
guage models as re-ranking agent. arXiv preprint
arXiv:2304.09542 .
Yi Tay, Vinh Tran, Mostafa Dehghani, Jianmo Ni, Dara
Bahri, Harsh Mehta, Zhen Qin, Kai Hui, Zhe Zhao,
Jai Gupta, et al. 2022. Transformer memory as a
differentiable search index. Advances in Neural In-
formation Processing Systems , 35:21831â€“21843.
Andrei Nikolaevich Tikhonov. 1963. On the solution of
ill-posed problems and the method of regularization.
InDoklady akademii nauk , volume 151, pages 501â€“
504. Russian Academy of Sciences.
Liang Wang, Nan Yang, Xiaolong Huang, Binxing
Jiao, Linjun Yang, Daxin Jiang, Rangan Majumder,
and Furu Wei. 2022. Text embeddings by weakly-
supervised contrastive pre-training. arXiv preprint
arXiv:2212.03533 .
Chuhan Wu, Fangzhao Wu, Tao Qi, Yongfeng Huang,
and Xing Xie. 2022. Fedcl: Federated contrastive
learning for privacy-preserving recommendation.
arXiv preprint arXiv:2204.09850 .Rex Ying, Ruining He, Kaifeng Chen, Pong Eksombat-
chai, William L Hamilton, and Jure Leskovec. 2018.
Graph convolutional neural networks for web-scale
recommender systems. In Proceedings of the 24th
ACM SIGKDD international conference on knowl-
edge discovery & data mining , pages 974â€“983.
Zhenrui Yue, Sara Rabhi, Gabriel de Souza Pereira
Moreira, Dong Wang, and Even Oldridge. 2023a.
Llamarec: Two-stage recommendation using large
language models for ranking. arXiv preprint
arXiv:2311.02089 .
Zhenrui Yue, Yueqi Wang, Zhankui He, Huimin Zeng,
Julian McAuley, and Dong Wang. 2023b. Linear
recurrent units for sequential recommendation. arXiv
preprint arXiv:2310.02367 .
Zhenrui Yue, Huimin Zeng, Ziyi Kou, Lanyu Shang, and
Dong Wang. 2022. Defending substitution-based pro-
file pollution attacks on sequential recommenders. In
Proceedings of the 16th ACM Conference on Recom-
mender Systems , pages 59â€“70.
Honglei Zhang, He Liu, Haoxuan Li, and Yidong Li.
2024. Transfr: Transferable federated recommen-
dation with pre-trained language models. arXiv
preprint arXiv:2402.01124 .
Junjie Zhang, Ruobing Xie, Yupeng Hou, Wayne Xin
Zhao, Leyu Lin, and Ji-Rong Wen. 2023. Recom-
mendation as instruction following: A large language
model empowered recommendation approach. arXiv
preprint arXiv:2305.07001 .
A Implementation Details
A.1 Datasets Details and FR Setup
Overall Dataset Statistics. The detailed dataset statistics (after 5-core processing) is reported in Table 3.
According to Table 3, it is observed that the averaged sequence length in ML-100K is significantly larger
than that of other datasets. In addition, the density of ML-100K is also much higher than others. Finally,
the Beauty, Games, Toys and Auto datasets are all Amazon review datasets, whose domain is rather
different from that of ML-100K.
Datasets users Items Interaction Length Density
Beauty 22332 12086 198K 8.88 7e-4
Games 15264 7676 147K 9.69 1e-3
Toys 19412 11924 167K 8.63 7e-3
Auto 1281 844 8K 6.70 8e-3
ML-100K 610 3650 89K 146.70 4e-2
Table 3: Overall dataset statistics.
Federated Dataset Statistics. In our experiments, we randomly sample a set of users from the original
datasets, and randomly distributed them onto different local clients. In terms of users, it is guaranteed
that the local datasets are mutually exclusive: one user could one exist in one local dataset or only in the
test dataset. The per-client statistics is summarized in Table 4. Note that considering the dataset size
and training convergence, we sampled different number of training users for different datasets. For each
dataset, after sampling the training users, the remaining users are used for validation and evaluation. It is
observed that for Beauty, Games and Toys, the test item scope is significantly larger than each local item
scope, leading to a data sparse and data heterogeneous FR setting.
Datasets Users/Client Items/Client Test Users Test Items
Beauty 1000 4161 17332 12086
Games 1000 3826 10264 7614
Toys 1000 4412 14412 11766
Auto 200 503 281 591
ML-100K 100 3134 109 3060
Table 4: Averaged statistics on local clients and the statistics of test users.
A.2 Implementation.
GPT-FedRec. To implement GPT-FedRec, we train LRURec from scratch, and finetune the pretrained
E5 (e5-base-v2 ) using the training data. When training LRURec, the learning rate is initialized as 1e-3,
and the number of local/global epochs is 80/5 (for Beauty, Games, Toys) and 60/5 (for Auto and ML-100k).
As for E5, the learning rate is initialized as 1e-6, and the number of local/global epochs is 2/2. We use
AdamW as the optimizer for both LRURec and E5. When generating the candidate set Ë†Iin the first stage,
we pick the top-20 items from the hybrid score Ë†P.
In the second stage, when performing the LLM-based re-ranking, the ideal procedure is to re-rank the
candidate sets of all users. However, due to the limited GPT API query budget, such an ideal evaluation
procedure is too expensive and infeasible. Moreover, since we are only interested in the recommendation
performance w.r.t. the top-20 items, it is equivalent and sufficient to only perform the LLM re-ranking for
a subset of test users, whose candidate set includes the ground-truth item. This procedure is meaningful
and fair. To see this, we emphasize that we only feed the predicted top-20 items into LLM for re-ranking.
In this setting, for a test user, if the ground-truth item is not within these predicted top-20 items, then
the ground-truth item will not participate in the LLM re-ranking. As such, re-ranking will not affect the
ranking of the ground-truth item, and therefore, will not change the values of Recall@5, Recall@10,
NDCG@5 and NDCG@10 either. Technically, to determine whether the recommendation results of a test
user should be re-ranked or not, we first validate whether the ground-truth item is included its predicted
candidate set (i.e., top-20 items). That is, for a test user, if the ground-truth item is within the predicted
top-20 items, then the predicted top-20 items will be fed into LLM for re-ranking.
Finally, when post-processing the generated texts, we also filter out the re-ranked results without
ground-truth items. This procedure makes sense, because the re-ranking process is expected to explicitly
focuses on re-ranking the top-20 items with ground-truth items in them. However, if a generated re-ranked
item list does not contain the ground-truth item, we ignore this re-ranked list and use the candidate set
from stage one as the final recommendation for this test user. For instance, we observe that GPT-3.5 may
ignore some technical parameters within some product titles or abbreviate some product titles. This leads
to a discrepancy between the true titles of the ground-truth items and the generated ones, even if in human
eyes they may represent the same product. Such generated results are treated as noisy generation and are
ignored when calculating the evaluation metrics in our evaluation.
Baselines. For all baseline methods, we refer to the original papers and the official implementations.
Moreover, for non-FR methods, we used the same code of FedAvg used for GPT-FedRec to perform global
model aggregation. For all baselines, we train the models by starting with the default training/finetuning
configuration. For FedSAS, FedLRU, CF-FedSR and TransFR, the models are trained from scratch. In
comparison, we load the released pretrained weights for P5, RecFmr and UniSR, and finetune them in
our FR setting. Finally, we observed training divergence and overfitting of some baseline methods, and
therefore, adjusted both local epochs and global epoch until find the best performance.
B Prompt Engineering
E5 Templates. We follow the instructions in (Wang et al., 2022), and design our E5 templates as follows:
### query: { history }
### passage: { candidate },
where history shall be replaced with history item titles and genres/categories. candidate shall be
replaced with the title and category/genre of a single candidate item. Moreover, in our experiments, we
notice that it is more beneficial to only use last several movies for the ML-100K dataset, and does not use
genre. For instance, an exemplar complete template on ML-100K is like (note that the history does not
need to be the complete history and the description of genres may be removed for better performance):
### query:
The Shawshank Redemption, a movie about Thriller ;
Ex Machina , a movie about Sci-Fi, Thriller ;
Unchained, a movie about Drama, Western .
### passage:
Whiplash, a movie about Drama .
GPT-3.5-Turbo Templates. Inspired by (Hou et al., 2023b), we use the following templates to prompt
GPT-3.5-Turbo:
### system:
You are a helpful { role }, {role description }.
### user:
Iâ€™ve browsed the following items in the past in order:
{history }.
There is also candidate pool:
{candidates }.
{task instruction }.
In the above template, role androle description are replaced with a concrete real-world job (e.g.,
movie reviewer) and its job description (e.g., recommending movies for people). history is instantiated
as item texts containing item titles and item categories/genres. As for candidates , it is replaced with the
hybrid retrieval results. task instruction shall be replaced with a direct re-rank order. We also add
additional formatting instructions in the template for post-processing purposes. An exemplar prompt for
ML-100K is like:
### system:
You are a movie fan and movie reviewer . Therefore, people might ask you to recommend
movies.
### user:
Iâ€™ve browsed the following items in the past in order:
The Shawshank Redemption, a movie about Thriller ;
Ex Machina , a movie about Sci-Fi, Thriller ;
Unchained, a movie about Drama, Western .
There is also candidate pool:
1. The Green Mile (1999)
2. Pulp Fiction (1994)
3. Seven (1995)
Please rank these movies by measuring the possibilities that I would like
to watch next most, according to my watching history. Please think step by
step. Please show me your ranking results with order numbers. Split your
output with line break. You MUST rank the given candidate movies. You can
not generate movies that are not in the given candidate list .