THE NUMERICAL RANGE OF A PERIODIC TRIDIAGONAL OPERATOR

REDUCES TO THE NUMERICAL RANGE OF A FINITE MATRIX

BENJAMIN A. ITZ [´] A-ORTIZ, RUB [´] EN A. MART [´] INEZ-AVENDA [´] NO, AND HIROSHI NAKAZATO [˜]

_Dedicated to the memory of Rudolf Kippenhahn (1926–2020)_

Abstract. In this paper we show that the closure of the numerical range of an _n_ +1-periodic
tridiagonal operator is equal to the numerical range of a 2( _n_ +1) × 2( _n_ +1) complex matrix.

Introduction

Consider A to be a finite set of complex numbers and let _a_ = ( _a_ _i_ ) _i_ ∈Z be a biinfinite
sequence in the total shift space A [Z] . In [13], the tridiagonal operator _A_ _a_ : _ℓ_ [2] (Z) → _ℓ_ [2] (Z)
associated to _a_ is defined as






(1) _A_ _a_ =






_... ..._

_..._ 0 1

_a_ −2 0 1
_a_ −1 0 1
_a_ 0 0 1

_a_ 1 0 _[..]_ _._

_... ..._


where the square marks the matrix entry at (0 _,_ 0). In the particular case of the alphabet
A = {−1 _,_ 1}, the corresponding operator _A_ _a_ is related to the so called “hopping sign model”
introduced in [7] and subsequently studied in many other works, such as [1–6,9,10,13],
just to name a few. On the other hand, when the alphabet is A = {0 _,_ 1} some results for
computing the numerical range of _A_ _a_ are presented in [13,14]. In particular, work in [14]
addresses the case when _a_ is an _n_ + 1-periodic sequence. Relying on the fact that the
closure of the numerical range of _A_ _a_ may be written as the closure of the convex hull
of an uncountable union of numerical ranges of certain matrices, in [14] the closure of
the numerical range of the 2-periodic case is computed by substituting such uncountable
union of numerical ranges by the convex hull of the union of the numerical ranges of just
two 2×2 matrices. In this work, we further contribute to the study of the numerical range
of _A_ _a_ when _a_ is an _n_ + 1 periodic biinfinite sequence.
Instead of working with the operators _A_ _a_, we work with the more general tridiagonal
operators _T_ = _T_ ( _a,b,c_ ) defined in Section 2, since, as can be seen in [14], the computation
of the closure of the numerical range of _A_ _a_ is a particular case of that of _T_ . Using a result
of Plaumann and Vinzant [20], we show that the closure of the numerical range of the

_Date_ : January 2021.
The second author’s research is partially supported by the Asociaci´on Mexicana de Cultura A.C..

1

2 BENJAMIN A. ITZ [´] A-ORTIZ, RUB [´] EN A. MART [´] INEZ-AVENDA [´] NO, AND HIROSHI NAKAZATO [˜]

_n_ + 1 periodic tridiagonal operator _T_ is the numerical range of a 2( _n_ + 1) × 2( _n_ + 1) matrix
(cf. Theorem 2.6).
We divide this work in two sections. In Section 1 we briefly introduce the notation
and terminologies needed in the rest of the paper. In Section 2 we develop the required
machinery, first by computing the Kippenhahn polynomial of the symbol of _n_ +1 periodc
tridiagonal operatos _T_ on _ℓ_ [2] (N 0 ) and then by combining our computations with results
of Plaumann and Vizant. We will conclude that the closure of the numerical range of _T_
is equal to the numerical range of a 2( _n_ + 1) × 2( _n_ + 1) matrix _A_ . Furthermore, we provide
some examples where _A_ can be explicitly computed and we show that the size of _A_ is
optimal.

1. Preliminaries

In this section we introduce the notation required which will be needed in the following
sections. As usual, the symbols N, N 0, Z, R and C will denote the set of positive integers,
the sets of nonnegative integers, the set of integers, the set of real numbers and the set of
complex numbers, respectively.
For a given _n_ ∈ N, let _a_, _b_ and _c_ be ( _n_ + 1)-periodic infinite sequences in A [N] [0] . We will
denote by _T_ = _T_ ( _a,b,c_ ) the ( _n_ + 1)-periodic tridiagonal operator on _ℓ_ [2] (N 0 ) given by






_T_ =


 _b_ 0 _c_ 0

_a_ 1 _b_ 1 _c_ 1
_a_ 2 _b_ 2 _c_ 2

_... ... ..._

_a_ _n_ _b_ _n_ _c_ _n_
_a_ 0 _b_ 0 _c_ 0

_..._ _..._ _..._

_a_ _n_ −1 _b_ _n_ −1 _c_ _n_ −1
_a_ _n_ _b_ _n_ _c_ _n_

_... ... ..._




_._


We should observe that _T_ is a bounded operator since the sum of the moduli of the entries in each column (and in each row) is uniformly bounded (see, e.g., [16, Example 2.3]).
The biinfinite matrix _A_ _a_ is also a bounded operator, as long as the biinfinite sequence _a_
arises from a finite alphabet.
If _n >_ 1, for each _φ_ ∈ [0 _,_ 2 _π_ ), following [1,14] we define the symbol of _T_, as the following
( _n_ + 1) × ( _n_ + 1) matrix






_b_ 0 _c_ 0 0 0 _a_ 0 _e_ [−] _[iφ]_


(2) _T_ _φ_ =






_a_ 1 _b_ 1 _c_ 1 0 0
0 _a_ 2 _b_ 2 _c_ 2 0

_... ..._ _..._ _..._ _..._

0 _a_ _n_ −2 _b_ _n_ −2 _c_ _n_ −2 0
0 0 _a_ _n_ −1 _b_ _n_ −1 _c_ _n_ −1
_c_ _n_ _e_ _[iφ]_ 0 0 _a_ _n_ _b_ _n_


;

NUMERICAL RANGE OF A TRIDIAGONAL OPERATOR 3

while the symbol of _T_ for _n_ = 1 is the 2 × 2 matrix


(3) _T_ _φ_ = � _a_ 1 + _b c_ 01 _e_ _[iφ]_ _c_ 0 + _ab_ 10 _e_ [−] _[iφ]_


_._
�


Recall that given a Hilbert space H and a bounded operator _A_ on it, the numerical range
is defined as the set
_W_ ( _A_ ) = {⟨ _Ax,x_ ⟩ : ∥ _x_ ∥ = 1} _._
The Toeplitz-Haussdorf Theorem establishes that _W_ ( _A_ ) is a bounded convex subset of C
(closed, if the Hilbert space is finite dimensional) and hence the closure of the numerical
range can be seen as the intersection of the closed half-spaces containing the numerical

range.
Kippenhahn [17] (see also [18]) characterized two vertical support lines of _W_ ( _A_ ) for
a given _n_ × _n_ matrix as Re( _z_ ) = _λ_ 1 ( _A_ ) and Re( _z_ ) = _λ_ _n_ ( _A_ ), where _λ_ 1 ( _A_ ) and _λ_ _n_ ( _A_ ) are
the respective largest and least eigenvalues of Re( _A_ ) (recall that Re( _A_ ) := [1] 2 [(] _[A]_ [ +] _[ A]_ [∗] [) and]


the respective largest and least eigenvalues of Re( _A_ ) (recall that Re( _A_ ) := 2 [(] _[A]_ [ +] _[ A]_ [∗] [) and]

Im( _A_ ) := [1] [(] _[A]_ [ −] _[A]_ [∗] [)). In fact, if] _[ α]_ [ ∈] _[W]_ [ (] _[A]_ [) then] _[ λ]_ _[n]_ [(] _[A]_ [)][ ≤] [Re(] _[α]_ [)][ ≤] _[λ]_ [1] [(] _[A]_ [) (and the equali-]


Im( _A_ ) := 2 _i_ [(] _[A]_ [ −] _[A]_ [∗] [)). In fact, if] _[ α]_ [ ∈] _[W]_ [ (] _[A]_ [) then] _[ λ]_ _[n]_ [(] _[A]_ [)][ ≤] [Re(] _[α]_ [)][ ≤] _[λ]_ [1] [(] _[A]_ [) (and the equali-]

ties hold for some points _α_ 1 _,α_ 2 ∈ _W_ ( _A_ )). Since _e_ _[iθ]_ _W_ ( _A_ ) = _W_ ( _e_ _[iθ]_ _A_ ) for each _θ_ ∈ [0 _,_ 2 _π_ ),
it follows that if _α_ ∈ _W_ ( _A_ ), then _e_ [−] _[iθ]_ _α_ ∈ _W_ ( _e_ [−] _[iθ]_ _A_ ) and hence Re( _e_ [−] _[iθ]_ _α_ ) ≤ _λ_ 1 ( _e_ [−] _[iθ]_ _A_ ). It
follows that the lines Re( _e_ [−] _[iθ]_ _z_ ) = _λ_ 1 ( _e_ [−] _[iθ]_ _A_ ) are support lines of _W_ ( _A_ ). Hence the convex set _W_ ( _A_ ) is uniquely determined by the numbers _λ_ 1 ( _e_ [−] _[iθ]_ _A_ ), as _θ_ varies on the interval [0 _,_ 2 _π_ ); i.e. _W_ ( _A_ ) is determined by the largest eigenvalue of Re( _e_ [−] _[iθ]_ _A_ ), which equals
cos( _θ_ )Re( _A_ ) + sin( _θ_ )Im( _A_ ). Thus the numerical range is determined by the largest roots
of the family of characteristic polynomials

det( _tI_ _n_ − cos( _θ_ )Re( _A_ ) − sin( _θ_ )Im( _A_ )) _._

The homogeneous polynomial _F_ _A_ ( _t,x,y_ ) = det( _tI_ _n_ + _x_ Re( _A_ ) + _y_ Im( _A_ )) is called the Kippenhahn polynomial of the matrix _A_ . It clearly follows that two matrices have the same
numerical range if their Kippenhahn polynomials coincide. Furthermore,

max{ _t_ ∈ R : _F_ _A_ ( _t,_ − cos( _θ_ ) _,_ − sin( _θ_ )) = 0} = max{Re( _e_ [−] _[iθ]_ _z_ ) : _z_ ∈ _W_ ( _A_ )}

for each _θ_ ∈ [0 _,_ 2 _π_ ).

2. The Kippenhahn polynomial of the symbol _T_
_φ_

In this section, after some preliminary work, we show that the closure of the numerical
range of a _n_ +1-periodic tridiagonal operator _T_ is the numerical range of a 2( _n_ +1)×2( _n_ +1)
matrix.
We will need the following lemma.

Lemma 2.1. Consider the ( _n_ + 1) × ( _n_ + 1) “almost tridiagonal” matrix






Λ =


 _λ_ 1 _,_ 1 _λ_ 1 _,_ 2 0 0 _..._ 0 0 _λ_ 1 _,n_ +1

_λ_ 2 _,_ 1 _λ_ 2 _,_ 2 _λ_ 2 _,_ 3 0 _..._ 0 0 0
0 _λ_ 3 _,_ 2 _λ_ 3 _,_ 3 _λ_ 3 _,_ 4 _..._ 0 0 0
0 0 _λ_ 4 _,_ 3 _λ_ 4 _,_ 4 _..._ 0 0 0

_..._ _..._ _..._ _..._ _..._ _..._ _..._ _..._
0 0 0 0 _... λ_ _n_ −1 _,n_ −1 _λ_ _n_ −1 _,n_ 0
0 0 0 0 _..._ _λ_ _n,n_ −1 _λ_ _n,n_ _λ_ _n,n_ +1

 _λ_ _n_ +1 _,_ 1 0 0 0 _..._ 0 _λ_ _n_ +1 _,n_ _λ_ _n_ +1 _,n_ +1


_,_

4 BENJAMIN A. ITZ [´] A-ORTIZ, RUB [´] EN A. MART [´] INEZ-AVENDA [´] NO, AND HIROSHI NAKAZATO [˜]

where every _λ_ _i,j_ ∈ C. Then, det(Λ) equals


_λ_ 1 _,_ 1 _λ_ 1 _,_ 2 0 _..._ 0 0 
_λ_ 2 _,_ 1 _λ_ 2 _,_ 2 _λ_ 2 _,_ 3 _..._ 0 0
0 _λ_ 3 _,_ 2 _λ_ 3 _,_ 3 _..._ 0 0

_..._ _..._ _..._ _..._ _..._ _..._
0 0 0 _... λ_ _n_ −1 _,n_ 0
0 0 0 _..._ _λ_ _n,n_ _λ_ _n,n_ +1
0 0 0 _... λ_ _n_ +1 _,n_ _λ_ _n_ +1 _,n_ +1 


det






− _λ_ 1 _,n_ +1 _λ_ _n_ +1 _,_ 1 det


 _λ_ 2 _,_ 2 _λ_ 2 _,_ 3 _..._ 0 0

_λ_ 3 _,_ 2 _λ_ 3 _,_ 3 _..._ 0 0

_..._ _..._ _..._ _..._ _..._
0 0 _... λ_ _n_ −1 _,n_ −1 _λ_ _n_ −1 _,n_

 0 0 _..._ _λ_ _n,n_ −1 _λ_ _n,n_






+ (−1) _[n]_ _λ_ _n_ +1 _,_ 1 _λ_ 1 _,_ 2 _λ_ 2 _,_ 3  - ·· _λ_ _n_ −1 _,n_ _λ_ _n,n_ +1 + (−1) _[n]_ _λ_ 1 _,n_ +1 _λ_ 2 _,_ 1 _λ_ 3 _,_ 2  - ·· _λ_ _n,n_ −1 _λ_ _n_ +1 _,n_ _._

_Proof._ This follows by a long (but straightforward) application of the multilinearity of the
determinant function and the Laplace Expansion Theorem. 
Let us set the following notation for the rest of this paper. For 0 ≤ _j < n_ we define


_c_ _j_ + _a_ _j_ +1
_α_ _j_ =


2 _i_


_a_ _j_ +1 _c_ _j_ − _a_ _j_ +1

_,_ _γ_ _j_ =
2 2 _i_


and



[+] _[ c]_ _[n]_
_α_ _n_ = _[a]_ [0]


2 _i_ _._



[+] _[ c]_ _[n]_ [−] _[c]_ _[n]_

_,_ _γ_ _n_ = _[a]_ [0]
2 2 _i_


We now find an expression for the Kippenhahn polynomial _F_ _T_ _φ_ of the symbol matrix
_T_ _φ_ of an arbitrary _n_ + 1-periodic tridiagonal matrix _T_ acting on _ℓ_ [2] (N 0 ), involving the determinants of some tridiagonal matrices. This expression will be useful in what follows.

Proposition 2.2. Let _n_ ∈ N. Consider the symbol _T_ _φ_, that is, the ( _n_ + 1) × ( _n_ + 1) matrix
defined as in (2) for _n_ ≥ 2 and as in (3) for _n_ = 1. Then the Kippenhahn polynomial of _T_ _φ_
is equal to



cos _φ_



_F_ _T_ _φ_ ( _t,x,y_ ) = _G_ _n_ ( _t,x,y_ ) −| _α_ _n_ _x_ + _γ_ _n_ _y_ | [2] _H_ _n_ ( _t,x,y_ ) + 2(−1) _[n]_ Re



( _α_ _n_ _x_ + _γ_ _n_ _y_ )



_n_ −1
�


�( _α_ _j_ _x_ + _γ_ _j_ _y_ )

_j_ =0



sin _φ,_



− 2(−1) _[n]_ Im



( _α_ _n_ _x_ + _γ_ _n_ _y_ )



_n_ −1
�


�( _α_ _j_ _x_ + _γ_ _j_ _y_ )

_j_ =0


where _G_ _n_ ( _t,x,y_ ) is the determinant of the tridiagonal ( _n_ + 1) × ( _n_ + 1) matrix

 _λ_ 1 _,_ 1 _λ_ 1 _,_ 2 0 0 _..._ 0 0 

_λ_ 2 _,_ 1 _λ_ 2 _,_ 2 _λ_ 2 _,_ 3 0          - ·· 0 0
0 _λ_ 3 _,_ 2 _λ_ 3 _,_ 3 _λ_ 3 _,_ 3            - ·· 0 0
0 0 _λ_ 4 _,_ 3 _λ_ 4 _,_ 4            - ·· 0 0 _,_

_..._ _..._ _..._ _..._ _..._ _..._
0 0 0 0            - ·· _λ_ _n,n_ _λ_ _n,n_ +1

 0 0 0 0                                                                                                                                                                                                                                                                                                                            - ·· _λ_ _n_ +1 _λ_ _n_ +1 +1 


_λ_ 1 _,_ 1 _λ_ 1 _,_ 2 0 0 _..._ 0 0
_λ_ 2 _,_ 1 _λ_ 2 _,_ 2 _λ_ 2 _,_ 3 0 - ·· 0 0
0 _λ_ 3 _,_ 2 _λ_ 3 _,_ 3 _λ_ 3 _,_ 3 - ·· 0 0
0 0 _λ_ 4 _,_ 3 _λ_ 4 _,_ 4 - ·· 0 0

_..._ _..._ _..._ _..._ _..._ _..._
0 0 0 0 - ·· _λ_ _n,n_ _λ_ _n,n_ +1
0 0 0 0 - ·· _λ_ _n_ +1 _,n_ _λ_ _n_ +1 _,n_ +1






_,_

NUMERICAL RANGE OF A TRIDIAGONAL OPERATOR 5


and, where we set _H_ _n_ ( _t,x,y_ ) = 1 when _n_ = 1, and, for _n_ ≥ 2, we set _H_ _n_ ( _t,x,y_ ) to be the
determinant of ( _n_ − 1) × ( _n_ − 1) tridiagonal matrix

 _λ_ 2 _,_ 2 _λ_ 2 _,_ 3 0              - ·· 0 0 

_λ_ 3 _,_ 2 _λ_ 3 _,_ 3 _λ_ 3 _,_ 4           - ·· 0 0
0 _λ_ 4 _,_ 3 _λ_ 4 _,_ 4             - ·· 0 0
_..._ _..._ _..._ _..._ _..._ _._
0 0 0             - ·· _λ_ _n_ −1 _,n_ −1 _λ_ _n_ −1 _,n_

 0 0 0                                                                                                                                                                                                                                                                                                 - ·· _λ_ _n,n_ −1 _λ_ _n,n_ 


_λ_ 2 _,_ 2 _λ_ 2 _,_ 3 0 - ·· 0 0
_λ_ 3 _,_ 2 _λ_ 3 _,_ 3 _λ_ 3 _,_ 4 - ·· 0 0
0 _λ_ 4 _,_ 3 _λ_ 4 _,_ 4 - ·· 0 0

_..._ _..._ _..._ _..._ _..._
0 0 0 - ·· _λ_ _n_ −1 _,n_ −1 _λ_ _n_ −1 _,n_
0 0 0 - ·· _λ_ _n,n_ −1 _λ_ _n,n_






_._


Here we have set, for 1 ≤ _j_ ≤ _n_ + 1,

_λ_ _j,j_ = _t_ + Re( _b_ _j_ −1 ) _x_ + Im( _b_ _j_ −1 ) _y,_

and for 1 ≤ _j_ ≤ _n_,

_λ_ _j,j_ +1 = _α_ _j_ −1 _x_ + _γ_ _j_ − _i_ _y_ and _λ_ _j_ +1 _,j_ = _α_ _j_ −1 _x_ + _γ_ _j_ −1 _y._


_Proof._ We divide the proof in two cases. For _n_ +1 = 2, by computing the real and imaginary
parts of the matrix _T_ _φ_ in (3), we obtain that the 2×2 matrix _tI_ 2 + _x_ Re( _T_ _φ_ )+ _y_ Im( _T_ _φ_ ) is given
by
_t_ + Re( _b_ 0 ) _x_ + Im( _b_ 0 ) _y_ _α_ 0 _x_ + _γ_ 0 _y_ + ( _α_ 1 _x_ + _γ_ 1 _y_ ) _e_ [−] _[iφ]_
�( _α_ 0 _x_ + _γ_ 0 _y_ ) + ( _α_ 1 _x_ + _γ_ 1 _y_ ) _e_ _[iφ]_ _t_ + Re( _b_ 1 ) _x_ + Im( _b_ 1 ) _y_ � _,_

where _α_ 0, _α_ 1, _γ_ 0 and _γ_ 1 are as defined above. The determinant of this matrix can be
simplified to

_F_ _T_ _φ_ ( _t,x,y_ ) = ( _t_ + Re( _b_ 0 ) _x_ + Im( _b_ 0 ) _y_ )( _t_ + Re( _b_ 1 ) _x_ + Im( _b_ 1 ) _y_ ) −| _α_ 0 _x_ + _γ_ 0 _y_ | [2] −| _α_ 1 _x_ + _γ_ 1 _y_ | [2]

− 2Re ( _α_ 0 _x_ + _γ_ 0 _y_ ) ~~(~~ _α_ 1 _x_ + _γ_ 1 _y_ ) _e_ _[iφ]_ [�]
�

= ( _t_ + Re( _b_ 0 ) _x_ + Im( _b_ 0 ) _y_ )( _t_ + Re( _b_ 1 ) _x_ + Im( _b_ 1 ) _y_ ) −| _α_ 0 _x_ + _γ_ 0 _y_ | [2] −| _α_ 1 _x_ + _γ_ 1 _y_ | [2]

− 2Re(( _α_ 0 _x_ + _γ_ 0 _y_ ) ~~(~~ _α_ 1 _x_ + _γ_ 1 _y_ ))cos _φ_ + 2Im(( _α_ 0 _x_ + _γ_ 0 _y_ ) ~~(~~ _α_ 1 _x_ + _γ_ 1 _y_ ))sin _φ_

= _G_ 1 ( _t,x,y_ ) −| _α_ 1 _x_ + _γ_ 1 _t_ | [2] _H_ 1 ( _t,x,y_ )

− 2Re(( _α_ 0 _x_ + _γ_ 0 _y_ ) ~~(~~ _α_ 1 _x_ + _γ_ 1 _y_ ))cos _φ_ + 2Im(( _α_ 0 _x_ + _γ_ 0 _y_ ) ~~(~~ _α_ 1 _x_ + _γ_ 1 _y_ ))sin _φ,_

as desired.
Now, for the case _n_ +1 ≥ 3, by computing the real and imaginary parts of the matrix _T_ _φ_
in (2), we can observe that _tI_ _n_ +1 + _x_ Re( _T_ _φ_ ) + _y_ Im( _T_ _φ_ ) is the matrix

 _λ_ 1 _,_ 1 _λ_ 1 _,_ 2 0 0 _..._ 0 _λ_ 1 _,n_ +1 

_λ_ 2 _,_ 1 _λ_ 2 _,_ 2 _λ_ 2 _,_ 3 0          - ·· 0 0
0 _λ_ 3 _,_ 2 _λ_ 3 _,_ 3 _λ_ 3 _,_ 3            - ·· 0 0
0 0 _λ_ 4 _,_ 3 _λ_ 4 _,_ 4            - ·· 0 0 _,_

_..._ _..._ _..._ _..._ _..._ _..._
0 0 0 0            - ·· _λ_ _n,n_ _λ_ _n,n_ +1

 _λ_ _n_ +1 1 0 0 0                                                                                                                                                                                                                                                                                                               - ·· _λ_ _n_ +1 _λ_ _n_ +1 +1 


( _α_ 0 _x_ + _γ_ 0 _y_ ) + ( _α_ 1 _x_ + _γ_ 1 _y_ ) _e_ _[iφ]_ _t_ + Re( _b_ 1 ) _x_ + Im( _b_ 1 ) _y_


_,_
�


_λ_ 1 _,_ 1 _λ_ 1 _,_ 2 0 0 _..._ 0 _λ_ 1 _,n_ +1
_λ_ 2 _,_ 1 _λ_ 2 _,_ 2 _λ_ 2 _,_ 3 0 - ·· 0 0
0 _λ_ 3 _,_ 2 _λ_ 3 _,_ 3 _λ_ 3 _,_ 3  - ·· 0 0
0 0 _λ_ 4 _,_ 3 _λ_ 4 _,_ 4  - ·· 0 0

_..._ _..._ _..._ _..._ _..._ _..._
0 0 0 0  - ·· _λ_ _n,n_ _λ_ _n,n_ +1
_λ_ _n_ +1 _,_ 1 0 0 0 - ·· _λ_ _n_ +1 _,n_ _λ_ _n_ +1 _,n_ +1






_,_


where we have now set

_λ_ 1 _,n_ +1 = ( _α_ _n_ _x_ + _γ_ _n_ _y_ ) _e_ [−] _[iφ]_ and _λ_ _n_ +1 _,_ 1 = ( _α_ _n_ _x_ + _γ_ _n_ _y_ ) _e_ _[iφ]_ _._

The above matrix is tridiagonal, except for the upper-right and bottom-left corners.

6 BENJAMIN A. ITZ [´] A-ORTIZ, RUB [´] EN A. MART [´] INEZ-AVENDA [´] NO, AND HIROSHI NAKAZATO [˜]

We can compute the determinant of the matrix polynomial _tI_ _n_ +1 + _x_ Re( _T_ _φ_ )+ _y_ Im( _T_ _φ_ ) by
using Lemma 2.1 obtaining

_F_ _T_ _φ_ ( _t,x,y_ ) = det( _tI_ _n_ +1 + _x_ Re( _T_ _φ_ ) + _y_ Im( _T_ _φ_ ))

= _G_ _n_ ( _t,x,y_ ) −| _α_ _n_ _x_ + _γ_ _n_ _y_ | [2] _H_ _n_ ( _t,x,y_ )


_n_ −1
� ~~(~~ _α_ _j_ _x_ + _γ_ _j_ _y_ ) _e_ [−] _[iφ]_

_j_ =0


+ (−1) _[n]_ ( _α_ _n_ _x_ + _γ_ _n_ _y_ )


_n_ −1
�( _α_ _j_ _x_ + _γ_ _j_ _y_ ) _e_ _[iφ]_ + (−1) _[n]_ ( _α_ _n_ _x_ + _γ_ _n_ _y_ )

_j_ =0



( _α_ _n_ _x_ + _γ_ _n_ _y_ )



_n_ −1 
�( _α_ _j_ _x_ + _γ_ _j_ _y_ ) _e_ _[iφ]_ _._

_j_ =0 


= _G_ _n_ ( _t,x,y_ ) −| _α_ _n_ _x_ + _γ_ _n_ _y_ | [2] _H_ _n_ ( _t,x,y_ ) + 2(−1) _[n]_ Re


_n_ −1 
�( _α_ _j_ _x_ + _γ_ _j_ _y_ ) _e_ _[iφ]_ _._

_j_ =0 


Computing the real part of the last term above, we obtain the equation



cos _φ_



_F_ _T_ _φ_ ( _t,x,y_ ) = _G_ _n_ ( _t,x,y_ ) −| _α_ _n_ _x_ + _γ_ _n_ _y_ | [2] _H_ _n_ ( _t,x,y_ ) + 2(−1) _[n]_ Re



( _α_ _n_ _x_ + _γ_ _n_ _y_ )



_n_ −1
�


�( _α_ _j_ _x_ + _γ_ _j_ _y_ )

_j_ =0



sin _φ,_



− 2(−1) _[n]_ Im



( _α_ _n_ _x_ + _γ_ _n_ _y_ )



_n_ −1
�


�( _α_ _j_ _x_ + _γ_ _j_ _y_ )

_j_ =0


which completes the proof. 
For every _n_ ∈ N and for a fixed point ( _x,y_ ) ∈ R [2], the angle _φ_ ∈ [0 _,_ 2 _π_ ) is involved only
in the constant term (with respect to the variable _t_ ) of the polynomial _F_ _T_ _φ_ ( _t,x,y_ ). Furthermore, for every ( _x,y_ ) ∈ R [2] and for every _φ_ ∈ [0 _,_ 2 _π_ ), the polynomial _F_ _T_ _φ_ ( _t,x,y_ ), seen
as a polynomial in _t_, has _n_ +1 real roots, counting multiplicities, as it is the characteristic
polynomial of the Hermitian matrix − _x_ Re( _T_ _φ_ ) − _y_ Im( _T_ _φ_ ). The following lemma will be
useful later when applied to the polynomial _F_ _T_ .
_φ_

Lemma 2.3. Let _F_ ( _t_ : _φ_ ) be a family of polynomials in R[ _t_ ] given by the expression

_F_ ( _t_ : _φ_ ) = _t_ _[n]_ [+1] + _p_ _n_ _t_ _[n]_ + _..._ + _p_ 1 _t_ + _p_ 0 − _u_ cos _φ_ − _v_ sin _φ,_

where _φ_ ∈ [0 _,_ 2 _π_ ). Assume that the polynomial _F_ ( _t_ : _φ_ ) has _n_ + 1 real roots counting
multiplicities for any angle _φ_ ∈ [0 _,_ 2 _π_ ). Let _φ_ 0, _φ_ 1 ∈ [0 _,_ 2 _π_ ) be such that


_u_ cos _φ_ 0 + _v_ sin _φ_ 0 = −√


_u_ [2] + _v_ [2] and _u_ cos _φ_ 1 + _v_ sin _φ_ 1 = √


_u_ [2] + _v_ [2] _._


Then

max {max { _t_ ∈ R : _F_ ( _t_ : _φ_ ) = 0} : 0 ≤ _φ <_ 2 _π_ } = max { _t_ ∈ R : _F_ ( _t_ : _φ_ 1 ) = 0} _,_

and

min {max { _t_ ∈ R : _F_ ( _t_ : _φ_ ) = 0} : 0 ≤ _φ <_ 2 _π_ } = max { _t_ ∈ R : _F_ ( _t_ : _φ_ 0 ) = 0} _._

_Proof._ Define _p_ ( _t_ ) as
_p_ ( _t_ ) = _t_ _[n]_ [+1] + _p_ _n_ _t_ _[n]_ + _..._ + _p_ 1 _t_ + _p_ 0 _._

Observe that, by assumption, the equation

_p_ ( _t_ ) = _u_ cos _φ_ + _v_ sin _φ_

NUMERICAL RANGE OF A TRIDIAGONAL OPERATOR 7

has _n_ +1 real solutions (counting multiplicities) for every _φ_ ∈ [0 _,_ 2 _π_ ). For some _φ_ ∈ [0 _,_ 2 _π_ ),
we have _u_ cos _φ_ + _v_ sin _φ_ = 0, and hence _p_ has _n_ +1 real roots (counting multiplicities) and
the derivative of _p_ has _n_ real roots (counting multiplicities). Let _r_ 0 be the largest root of
_p_ [′] ( _t_ ). Hence, _p_ is increasing on the interval [ _r_ 0 _,_ ∞) and the equations

_p_ ( _t_ ) = _u_ cos _φ_ + _v_ sin _φ_

have a unique solution on the interval [ _r_ 0 _,_ ∞).
Observe that for every _φ_ ∈ [0 _,_ 2 _π_ )


−
√


_u_ [2] + _v_ [2] ≤ _u_ cos _φ_ + _v_ sin _φ_ ≤ √


_u_ [2] + _v_ [2] ;


equality occurs on the left-hand-side inequality at _φ_ 0 while equality occurs on the righthand-side inequality at _φ_ 1 .
For each _φ_ ∈ [0 _,_ 2 _π_ ), consider the number

max{ _t_ ∈ R : _p_ ( _t_ ) = _u_ cos _φ_ + _v_ sin _φ_ } _._

Since the function _p_ is increasing on [ _r_ 0 _,_ ∞), the largest of these numbers, when _φ_ varies,
occurs when _t_ is the largest solution of the equation


_p_ ( _t_ ) = √


_u_ [2] + _v_ [2] _._


Hence we have

max {max { _t_ ∈ R : _F_ ( _t,φ_ ) = 0} : 0 ≤ _φ <_ 2 _π_ } = max { _t_ ∈ R : _F_ ( _t,φ_ 1 ) = 0} _._

Analogously, the smallest, when _φ_ varies in [0 _,_ 2 _π_ ), among the largest solutions _t_ of the
equations
_p_ ( _t_ ) = _u_ cos _φ_ + _v_ sin _φ,_
occurs when _t_ is the largest solution of the equation


_p_ ( _t_ ) = −√


_u_ [2] + _v_ [2] _._


Hence we have

min {max { _t_ ∈ R : _F_ ( _t,φ_ ) = 0} : 0 ≤ _φ <_ 2 _π_ } = max { _t_ ∈ R : _F_ ( _t,φ_ 0 ) = 0} _._     
In Theorem 2.7, we will show that the closure of the numerical range of _T_ is the numerical range of a single matrix. One of the key steps in the proof of said theorem will
be to use the following proposition, which computes the closure of the numerical range
of _T_ by using a single homogeneous polynomial, instead of the uncountable number of
Kippenhahn polynomials of the symbols _T_ _φ_, which Theorem 2.8 in [14] would suggest:
this is achieved by getting rid of the parameter _φ_ in the expression of the Kippenhahn
polynomial of the symbol _T_ _φ_ in Proposition 2.2.

Proposition 2.4. Let _n_ ∈ N. Suppose that _T_ ( _a,b,c_ ) is an _n_ + 1-periodic tridiagonal operator acting on _ℓ_ [2] (N 0 ). Let _G_ _n_ and _H_ _n_ be as in Proposition 2.2 and let _P_ be the real

_n_
homogeneous polynomial of degree 2( + 1) given by


2
_P_ ( _t,x,y_ ) = _G_ _n_ ( _t,x,y_ ) −| _α_ _n_ _x_ + _γ_ _n_ _y_ | [2] _H_ _n_ ( _t,x,y_ ) − 4
� �

Then _P_ ( _t,_ 0 _,_ 0) = _t_ [2(] _[n]_ [+1)] and


_n_
�

_j_ =0


2
��� _α_ _j_ _x_ + _γ_ _j_ _y_ ��� _._


sup Re( _e_ [−] _[iθ]_ _z_ ): _z_ ∈ _W_ ( _T_ ( _a,b,c_ )) = max{ _t_ ∈ R : _P_ ( _t,_ − cos _θ,_ − sin _θ_ ) = 0} _,_
� �

8 BENJAMIN A. ITZ [´] A-ORTIZ, RUB [´] EN A. MART [´] INEZ-AVENDA [´] NO, AND HIROSHI NAKAZATO [˜]

for each _θ_ ∈ [0 _,_ 2 _π_ ).

_Proof._ It is trivial to check that _P_ ( _t,_ 0 _,_ 0) = _t_ [2(] _[n]_ [+1)] . Now, let _F_ ( _t_ : _φ_ ) = _F_ _T_ _φ_ ( _t,x,y_ ), where we
know by Proposition 2.2 that

_F_ _T_ _φ_ ( _t,x,y_ ) = _G_ _n_ ( _t,x,y_ ) −| _α_ _n_ _x_ + _γ_ _n_ _y_ | [2] _H_ _n_ ( _t,x,y_ ) − _u_ cos _φ_ − _v_ sin _φ,_

where






_u_ = −2(−1) _[n]_ Re



~~(~~ _α_ _n_ _x_ + _γ_ _n_ _y_ )



_n_ −1
�( _α_ _j_ _x_ + _γ_ _j_ _y_ )

_j_ =0


and

Notice that




_._



_v_ = 2(−1) _[n]_ Im



( _α_ _n_ _x_ + _γ_ _n_ _y_ )



_n_ −1
�


�( _α_ _j_ _x_ + _γ_ _j_ _y_ )

_j_ =0



_u_ [2] + _v_ [2] = 4Re [2] ~~(~~ _α_ _n_ _x_ + _γ_ _n_ _y_ )



_n_ −1
�


 
2
+ 4Im ( _α_ _n_ _x_ + _γ_ _n_ _y_ )
 






�( _α_ _j_ _x_ + _γ_ _j_ _y_ )

_j_ =0


_n_ −1
�( _α_ _j_ _x_ + _γ_ _j_ _y_ )

_j_ =0


�������� 2


= 4

=4


( _α_ _n_ _x_ + _γ_ _n_ _y_ )
��������


_n_
�

_j_ =0


2
��� _α_ _j_ _x_ + _γ_ _j_ _y_ ��� _._


_n_ −1
�( _α_ _j_ _x_ + _γ_ _j_ _y_ )

_j_ =0


The polynomial _F_ ( _t_ : _φ_ ) has the form outlined in Lemma 2.3 and, as was mentioned
before Lemma 2.3, it has _n_ + 1 real roots, counting multiplicities. Hence, by Lemma 2.3,
for _φ_ 0 and _φ_ 1 satisfying


_u_ cos( _φ_ 0 ) + _v_ sin( _φ_ 0 ) = −√

we have that


_u_ [2] + _v_ [2] _,_ _u_ cos( _φ_ 1 ) + _v_ sin( _φ_ 1 ) = √


_u_ [2] + _v_ [2] _,_


max {max { _t_ : _F_ ( _t_ : _φ_ ) = 0} : 0 ≤ _φ <_ 2 _π_ } = max { _t_ : _F_ ( _t_ : _φ_ 1 ) = 0} _,_

and

min {max { _t_ : _F_ ( _t_ : _φ_ ) = 0} : 0 ≤ _φ <_ 2 _π_ } = max { _t_ : _F_ ( _t_ : _φ_ 0 ) = 0} _._

Notice that

_F_ ( _t_ : _φ_ 0 ) · _F_ ( _t_ : _φ_ 1 ) = _G_ _n_ ( _t,x,y_ ) −| _α_ _n_ _x_ + _γ_ _n_ _y_ | [2] _H_ _n_ ( _t,x,y_ ) − ( _u_ cos( _φ_ 0 ) + _v_ sin( _φ_ 0 ))
� �

                       - _G_ _n_ ( _t,x,y_ ) −| _α_ _n_ _x_ + _γ_ _n_ _y_ | [2] _H_ _n_ ( _t,x,y_ ) − ( _u_ cos( _φ_ 1 ) + _v_ sin( _φ_ 1 ))
� �

2
= _G_ _n_ ( _t,x,y_ ) −| _α_ _n_ _x_ + _γ_ _n_ _y_ | [2] _H_ _n_ ( _t,x,y_ ) − ~~√~~ _u_ [2] + _v_ [2] [�] [2]
� � �

2
2 2
= _G_ _n_ ( _t,x,y_ ) −| _α_ _n_ _x_ + _γ_ _n_ _y_ | [2] _H_ _n_ ( _t,x,y_ ) − ( _u_ + _v_ )
� �

= _P_ ( _t,x,y_ ) _._

NUMERICAL RANGE OF A TRIDIAGONAL OPERATOR 9

We also have, for each _θ_ ∈ [0 _,_ 2 _π_ ), that

max{ _t_ ∈ R : _F_ _T_ _φ_ ( _t,_ − cos _θ,_ − sin _θ_ ) = 0 _,_ 0 ≤ _φ <_ 2 _π_ }


(4)


= max �max � _t_ ∈ R : _F_ _T_ _φ_ ( _t,_ − cos _θ,_ − sin _θ_ ) = 0� : 0 ≤ _φ <_ 2 _π_ �

= max _t_ ∈ R : _F_ _T_ ( _t,_ − cos _θ,_ − sin _θ_ ) = 0
� _φ_ 1 �

= max{ _t_ ∈ R : _P_ ( _t,_ − cos _θ,_ − sin _θ_ ) = 0} _._


The last equality follows since the roots of _P_ ( _t,_ − cos _θ,_ − sin _θ_ ) are those of _F_ ( _t_ : _φ_ 1 ) =
_F_ _T_ _φ_ 1 ( _t,_ − cos _θ,_ − sin _θ_ ) and _F_ ( _t_ : _φ_ 0 ) = _F_ _T_ _φ_ 0 ( _t,_ − cos _θ,_ − sin _θ_ ), so by the choice of _φ_ 0 and _φ_ 1,
the largest root of _P_ ( _t,_ − cos _θ,_ − sin _θ_ ) is the largest root of _F_ _T_ ( _t,_ − cos _θ,_ − sin _θ_ ).
_φ_ 1
By the definition of the Kippenhahn polynomial, we have

max � _t_ ∈ R : _F_ _T_ _φ_ ( _t,_ − cos( _θ_ ) _,_ − sin( _θ_ )) = 0� = max �Re( _e_ [−] _[iθ]_ _z_ ) : _z_ ∈ _W_ ( _T_ _φ_ )� _._

and hence we obtain

max � _t_ ∈ R : _F_ _T_ _φ_ ( _t,_ − cos( _θ_ ) _,_ − sin( _θ_ )) = 0 _,_ 0 ≤ _φ <_ 2 _π_ �

(5)
= max �Re( _e_ [−] _[iθ]_ _z_ ) : _z_ ∈ _W_ ( _T_ _φ_ ) _,_ 0 ≤ _φ <_ 2 _π_ � _._

Lastly, the equality

(6) sup �Re( _e_ [−] _[iθ]_ _z_ ) : _z_ ∈ _W_ ( _T_ ( _a,b,c_ ))� = max �Re( _e_ [−] _[iθ]_ _z_ ) : _z_ ∈ _W_ � _T_ _φ_ � _,_ 0 ≤ _φ <_ 2 _π_ �

follows from Theorem 2.8 in [14]. Putting together equations (4), (5) and (6), we obtain
the desired conclusion. 
The following definition will be useful.

Definition 2.5. Suppose that _Q_ ( _t,x,y_ ) is a real homogeneous polynomial in 3 variables
_t,x,y_ of degree _m_ with _Q_ (1 _,_ 0 _,_ 0) _>_ 0. If the equation _Q_ ( _t,x_ 0 _,y_ 0 ) = 0 in _t_ has _m_ real solutions
counting multiplicities for any ( _x_ 0 _,y_ 0 ) ∈ R [2] with _x_ 0 [2] [+] _[ y]_ 0 [2] _[>]_ [ 0, we say that] _[ Q]_ [ is] _[ hyperbolic]_
(with respect to (1 _,_ 0 _,_ 0)).

The above condition may also be formulated as: “the equation _Q_ ( _t,_ − cos _θ,_ − sin _θ_ ) = 0
in _t_ has _m_ real solutions for any angle 0 ≤ _θ <_ 2 _π_ ”.

Theorem 2.6 (Plaumann and Vinzant [20]). Suppose that _Q_ ( _t,x,y_ ) is a real homogeneous
hyperbolic polynomial of degree _m_ with _Q_ (1 _,_ 0 _,_ 0) = 1. Then there exists an _m_ × _m_ complex
matrix _A_ satisfying
_Q_ ( _t,x,y_ ) = det( _tI_ _m_ + _x_ Re( _A_ ) + _y_ Im( _A_ )) _._

Remark. Helton and Vinnikov [12] (cf. [11]) proved a result stronger than the above
theorem which guarantees that we can construct an _m_ × _m_ complex _symmetric_ matrix _A_
_A_ .
satisfying a similar property. In this paper we do not use the symmetry of the matrix

Depending on the above Theorem 2.6, we obtain the main theorem of this paper.

Theorem 2.7. Suppose that _T_ ( _a,b,c_ ) is an _n_ + 1-periodic tridiagonal operator acting on
_ℓ_ [2] (N 0 ). Then there exists a 2( _n_ + 1) × 2( _n_ + 1) complex matrix _A_ such that

_W_ ( _T_ ( _a,b,c_ )) = _W_ ( _A_ )

10 BENJAMIN A. ITZ [´] A-ORTIZ, RUB [´] EN A. MART [´] INEZ-AVENDA [´] NO, AND HIROSHI NAKAZATO [˜]

where the matrix _A_ is chosen so that it satisfies


2
_F_ _A_ ( _t,x,y_ ) = _G_ _n_ ( _t,x,y_ ) −| _α_ _n_ _x_ + _γ_ _n_ _y_ | [2] _H_ _n_ ( _t,x,y_ ) − 4
� �

where the polynomials _G_ _n_ and _H_ _n_ are as in Proposition 2.2.


_n_
�

_j_ =0


2
��� _α_ _j_ _x_ + _γ_ _j_ _y_ ��� _,_


_Proof._ By Theorem 2.6, there exists a 2( _n_ + 1) × 2( _n_ + 1) matrix _A_ such that _P_ ( _t,x,y_ ) =
_F_ _A_ ( _t,x,y_ ), where _P_ is the homogeneous polynomial in Proposition 2.4. But also, by the
same proposition,

sup Re( _e_ [−] _[iθ]_ _z_ ): _z_ ∈ _W_ ( _T_ ( _a,b,c_ )) = max{ _t_ ∈ R : _F_ _A_ ( _t,_ − cos _θ,_ − sin _θ_ ) = 0}
� �

= max Re( _e_ [−] _[iθ]_ _z_ ): _z_ ∈ _W_ ( _A_ )
� �

for each _θ_ ∈ [0 _,_ 2 _π_ ), and hence the closure of the numerical range of _T_ ( _a,b,c_ ) equals the
_A_ .         numerical range of

It is clear that given the operator _T_, one can compute the polynomial _P_ which, by
the Plaumann-Vinzant Theorem, is the Kippenhahn polynomial of some matrix _A_ . The
question arises on whether the matrix _A_ can be explicitly computed. The paper [20]
shows a method for constructing such a matrix _A_ (see also [12,19]).
In some cases, the matrix _A_ can be found explicitly, as the next proposition shows. The
reader should compare our next result to Theorem 4.1 in [1], where an alternative method
for computing the numerical range of the tridiagonal operator _T_ ( _a,b,c_ ) is obtained, when
_a_, _b_ and _c_ are real 2-periodic sequences.

Proposition 2.8. Let _a_ and _c_ be real 2-periodic sequences and let _b_ the constant 0 sequence. If






_S_ =

then _W_ ( _T_ ( _a,b,c_ )) = _W_ ( _S_ ).


 _α_ 0 + _α_ 1 − _γ_ 0 − _γ_ 1 0

− _γ_ 0 − _α_ 0 + _α_ 1 0 − _γ_ 1
− _γ_ 1 0 _α_ 0 − _α_ 1 − _γ_ 0

 0 − _γ_ 1 − _γ_ 0 − _α_ 0 − _α_ 1


_Proof._ It is a straightforward computation that the polynomial _P_ in Proposition 2.4 equals

_P_ ( _t,x,y_ ) = _t_ [2] −| _α_ 0 _x_ + _γ_ 0 _y_ | [2] −| _α_ 1 _x_ + _γ_ 1 _y_ | [2] [�] [2] − 4| _α_ 0 _x_ + _γ_ 0 _y_ | [2] | _α_ 1 _x_ + _γ_ 1 _y_ | [2]
�

But a computation also shows that _F_ _S_ ( _t,x,y_ ) = _P_ ( _t,x,y_ ) and hence, by Theorem 2.7, we
have _W_ ( _T_ ( _a,b,c_ )) = _W_ ( _S_ ). 
We illustrate the above proposition with some examples.

Example 2.9. Let _a_ be the 2-periodic sequence with period word 1 3, let _b_ be the constant 0 sequence and let _c_ be the 2-periodic sequence with period word 4 8. Then, by
Proposition 2.8, if


8 1 0
2 _[i]_ [ −] 2 [7] _[i]_

1 1 0 − [7]
2 _[i]_ 2 _[i]_


0 − [7] 1 −8

2 _[i]_ 2 _[i]_


_S_ =






− [7]



[7] 0 −1 1

2 _[i]_ 2 _[i]_


_,_





NUMERICAL RANGE OF A TRIDIAGONAL OPERATOR 11

Figure 1. Boundary of the numerical range of _S_

then _W_ ( _T_ ( _a,b,c_ )) = _W_ ( _S_ ). The boundary of the numerical range of _S_ is shown in Figure
1. The Kippenhahn polynomial of _S_ equals

_P_ ( _t,x,y_ ) = _t_ [4] − 65 _t_ [2] _x_ [2] − 25 _t_ [2] _y_ [2] + 64 _x_ [4] + 192 _x_ [2] _y_ [2] + 144 _y_ [4] _._

The quartic curve _P_ ( _t,x,y_ ) = 0 in the complex projective plane has a pair of ordinary
singular points of multiplicity 2 at ( _t,x,y_ ) = (0 _,_ 1 _,_ ± _i_ ~~√~~ 2 _/_ 3) and there is no other singular

point. So the algebraic curve theory tell us that the homogeneous polynomial _P_ ( _t,x,y_ ) is
irreducible in the polynomial ring.
Hence, using for example Proposition 2.3 in [8], there cannot be a matrix _R_ of size _m_ × _m_,
with 1 ≤ _m <_ 4 with _W_ ( _R_ ) = _W_ ( _S_ ). Incidentally, this shows that the size of the matrix _A_
in Theorem 2.7 is optimal.

Example 2.10. Let _a_ and _c_ be real 2-periodic sequences with period words _a_ 0 _a_ 1 and _c_ 0 _c_ 1
respectively, and let _b_ be the constant sequence 0. If _a_ 0 = _c_ 1, then _γ_ 1 = 0 and then, by
Proposition 2.8, _W_ ( _T_ ( _a,b,c_ )) = _W_ ( _S_ ), where




_._



_S_ =


 _α_ 0 + _α_ 1 − _γ_ 0 0 0

− _γ_ 0 − _α_ 0 + _α_ 1 0 0
0 0 _α_ 0 − _α_ 1 − _γ_ 0

 0 0 − _γ_ 0 − _α_ 0 − _α_ 1


But this implies that

where


_W_ ( _T_ ( _a,b,c_ )) = conv( _W_ ( _A_ + _α_ 1 _I_ ) ∪ _W_ ( _A_ − _α_ 1 _I_ )) _,_


_α_ 0 − _γ_ 0
_A_ =
�− _γ_ 0 − _α_ 0


_._
�


That is, _W_ ( _T_ ( _a,b,c_ )) is the convex hull of two ellipses (possibly degenerate), each one a
translation of a single elllipse (possibly degenarate) centered at the origin.

12 BENJAMIN A. ITZ [´] A-ORTIZ, RUB [´] EN A. MART [´] INEZ-AVENDA [´] NO, AND HIROSHI NAKAZATO [˜]

Example 2.11. Let _a_ be the 2-periodic sequence with period word 1 _,_ −1, let _b_ be the constant 0 sequence and let _c_ be the constant 1 sequence. Then, by Example 2.10, we have
that _W_ ( _T_ ( _a,b,c_ )) = conv( _W_ ( _A_ + _I_ ) ∪ _W_ ( _A_ − _I_ )), where


0 _i_
_A_ =

_i_ 0

�


_._
�


_i_ 0


But it is easy to see that _W_ ( _A_ ) is the closed line segment joining − _i_ and _i_ . Hence, _W_ ( _T_ ( _a,b,c_ ))
equals the convex hull of the closed line segment joining −1 − _i_ and −1 + _i_ and the closed
line segment joining 1 − _i_ and 1 + _i_ ; i.e., the square with vertices −1 − _i_, −1 + _i_, 1 − _i_ and
1 + _i_, recovering (most of) Theorem 9 in [5].

Example 2.12. Let _a_ and _c_ be real 2-periodic sequences with period words _a_ 0 _a_ 1 and _c_ 0 _c_ 1
respectively, and let _b_ be the constant sequence 0. If _c_ 0 = _a_ 1, then _γ_ 0 = 0 and then, by
Proposition 2.8, _W_ ( _T_ ( _a,b,c_ )) = _W_ ( _S_ ), where




_._



_S_ =


 _α_ 0 + _α_ 1 0 − _γ_ 1 0

0 − _α_ 0 + _α_ 1 0 − _γ_ 1
− _γ_ 1 0 _α_ 0 − _α_ 1 0

 0 − _γ_ 1 0 − _α_ 0 − _α_ 1


But if

then

_U_ [∗] _SU_ =

But this implies that


1 0 0 0

0 0 1 0

0 1 0 0

0 0 0 1








_,_



_U_ =


 _α_ 0 + _α_ 1 − _γ_ 1 0 0

− _γ_ 1 _α_ 0 − _α_ 1 0 0
0 0 − _α_ 0 + _α_ 1 − _γ_ 1

 0 0 − _γ_ 1 − _α_ 0 − _α_ 1




_._



_W_ ( _T_ ( _a,b,c_ )) = conv( _W_ ( _A_ + _α_ 0 _I_ ) ∪ _W_ ( _A_ − _α_ 0 _I_ )) _,_


where


_α_ 1 − _γ_ 1
_A_ = _._
�− _γ_ 1 − _α_ 1 �


That is, _W_ ( _T_ ( _a,b,c_ )) is the convex hull of two ellipses (possibly degenerate), each one a
translation of a single elllipse (possibly degenarate) centered at the origin.

Example 2.13. Let _a_ be the 2-periodic sequence with period word 01, let _b_ be the constant
0 sequence and let _c_ be the constant 1 sequence. Then, by Example 2.12, we have that
_W_ ( _T_ ( _a,b,c_ )) = conv( _W_ ( _A_ + _I_ ) ∪ _W_ ( _A_ − _I_ )), where






1 − [1]
2 2 _[i]_

[1]

2 _[i]_ [ −] [1] 2


2


_A_ =


− [1]




_._


NUMERICAL RANGE OF A TRIDIAGONAL OPERATOR 13


But, if


2

2 _[i]_


1
~~√~~


1
2 ~~√~~

1
2 _[i]_ ~~√~~




_,_



_U_ =






− [1]
~~√~~


then _U_ is unitary and _U_ [∗] _AU_ equals

0 1

0 0
�


_._
�


Therefore, _W_ ( _T_ ( _a,b,c_ )) = conv( _W_ ( _B_ + _I_ ) ∪ _W_ ( _B_ − _I_ )), recovering the result in [14, Theorem 3.6].

In the paper [15] we explore some sufficient conditions under which the matrix _A_ can
be explicitly found, namely if _b_ = 0 and there is some symmetry in the periodic sequences
_a_ and _c_, then the polynomial _P_ can be factored as the product of the Kippenhahn polynomials of two computable matrices, which generalizes the previous four examples.

References

[1] N. Bebiano, J. da Providˆencia, and A. Nata. The numerical range of banded periodic Toeplitz operators.
_J. Math. Anal. Appl._, 398:189–197, 2013.

[2] S.N. Chandler-Wilde, R. Chonchaiya, and M. Lindner. Eigenvalue problem meets Sierpinski triangle:
computing the spectrum of a non-self-adjoint random operator. _Oper. Matrices_, 5:633–648, 2011.

[3] S. N. Chandler-Wilde, R. Chonchaiya, and M. Lindner. On the spectra and pseudospectra of a class of
non-self-adjoint random matrices and operators. _Oper. Matrices_, 7:739–775, 2013.

[4] S. N. Chandler-Wilde and E. B. Davies. Spectrum of a Feinberg-Zee random hopping matrix.
_J. Spectr. Theory_, 2:147–179, 2012.

[5] M. T. Chien and H. Nakazato. The numerical range of a tridiagonal operator. _J. Math. Anal. Appl._
373:297-304, 2011.

[6] R.T. Chien and I.M. Spitkovsky. On the numerical ranges of some tridiagonal matrices. _Linear Algebra_
_Appl._, 470:228–240, 2015.

[7] J. Feinberg and A. Zee. Spectral curves of non-hermitean Hamiltonians. _Nuclear Phys. B_, 552:599–623,
1999.

[8] H. L. Gau and P. Y. Wu. Companion matrices: reducibility, numerical ranges and similarity to contractions. _Linear Algebra Appl._ 383:127–142, 2004.

[9] R. Hagger. The eigenvalues of tridiagonal sign matrices are dense in the spectra of periodic tridiagonal
sign operators. _J. Funct. Anal._, 269:1563–1570, 2015.

[10] R. Hagger. On the spectrum and numerical range of tridiagonal random operators. _J. Spectr. Theory_,
6:215266, 2016.

[11] J. W. Helton and I. M. Spitkovsky. The possible shapes of numerical ranges. _Operators and Matrices_,
6:607-611, 2012.

[12] J. W. Helton and V. Vinnikov. Linear matrix inequality representations of sets. _Communications on Pure_
_and Applied Mathematics_,60: 654-674, 2007.

[13] C. Hern´andez-Becerra and B. A. Itz´a-Ortiz. A class of tridiagonal operators associated to some subshifts. _Open Math._, 14:2391–5455, 2016.

[14] B. A. Itz´a-Ortiz and R. A. Mart´ınez-Avenda˜no. The numerical range of a class of periodic tridiagonal
operators. _Linear Multilinear Algebra_ . 69:786–806, 2021.

[15] B. A. Itz´a-Ort´ız, R. A. Mart´ınez-Avenda˜no and H. Nakazato. The numerical range of some tridiagonal
[operators is the convex hull of the numerical ranges of two finite matrices. Preprint arXiv:2103.01866](http://arxiv.org/abs/2103.01866)

[math.FA].

[16] T. Kato. _Perturbation theory for linear operators_ . Die Grundlehren der mathematischen Wissenschaften,
Band 132. Springer-Verlag New York, Inc., New York, 1966.

[17] R. Kippenhahn, Uber den wertevorrat einer Matrix. [¨] _Math. Nachr._, 6:193-228, 1951.

14 BENJAMIN A. ITZ [´] A-ORTIZ, RUB [´] EN A. MART [´] INEZ-AVENDA [´] NO, AND HIROSHI NAKAZATO [˜]

[18] R. Kippenhahn. On the numerical range of a matrix. Translated from the German by Paul F. Zachlin
and Michiel E. Hochstenbach. _Linear Multilinear Algebra_ 56:185-225, 2008.

[19] D. Plaumann, B. Sturmfels and C. Vinzant, Computing linear matrix representations of HeltonVinnikov curves, in _Mathematical methods in systems, optimization, and control_, Oper. Theory Adv. Appl.
222, 259–277, Birkh¨auser/Springer Basel AG, Basel, 2012.

[20] D. Plaumann and C. Vinzant. Determinantal representations of hyperbolic plane curves: An elementary approach, _J. Symbolic Comput._, 57:48–60, 2013.

Centro de Investigaci´on en Matem´aticas, Universidad Aut´onoma del Estado de Hidalgo, Pachuca,
Hidalgo, Mexico

Departamento Acad´emico de Matem´aticas, Instituto Tecnol´ogico Aut´onomo de M´exico, Mexico
City, Mexico

Department of Mathematics and Physics, Hirosaki University, Hirosaki City, Japan

