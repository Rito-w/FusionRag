# æŸ¥è¯¢æ„å›¾æ„ŸçŸ¥çš„è‡ªé€‚åº”æ£€ç´¢ç­–ç•¥ - è¯¦ç»†æŠ€æœ¯æ–¹æ¡ˆ

## ğŸ¯ æ ¸å¿ƒæŠ€æœ¯æ¶æ„

### ç³»ç»Ÿæ•´ä½“è®¾è®¡
```python
class IntentAwareAdaptiveRetrieval:
    def __init__(self):
        # 1. æŸ¥è¯¢æ„å›¾åˆ†ç±»å™¨
        self.intent_classifier = IntentClassifier(
            model_name="distilbert-base-uncased",  # è½»é‡çº§BERT
            num_classes=4,
            max_length=128
        )
        
        # 2. æ£€ç´¢ç­–ç•¥åº“
        self.retrieval_strategies = {
            'factual': FactualRetrievalStrategy(),
            'conceptual': ConceptualRetrievalStrategy(), 
            'procedural': ProceduralRetrievalStrategy(),
            'comparative': ComparativeRetrievalStrategy()
        }
        
        # 3. ç­–ç•¥é€‰æ‹©å™¨
        self.strategy_selector = StrategySelector()
        
        # 4. ç»“æœèåˆå™¨
        self.result_fusion = AdaptiveResultFusion()
    
    def search(self, query):
        # Step 1: æ„å›¾åˆ†ç±»
        intent = self.intent_classifier.predict(query)
        confidence = self.intent_classifier.get_confidence()
        
        # Step 2: ç­–ç•¥é€‰æ‹©
        if confidence > 0.8:
            # é«˜ç½®ä¿¡åº¦ï¼šä½¿ç”¨å•ä¸€ç­–ç•¥
            strategy = self.retrieval_strategies[intent]
            results = strategy.retrieve(query)
        else:
            # ä½ç½®ä¿¡åº¦ï¼šä½¿ç”¨æ··åˆç­–ç•¥
            results = self._hybrid_retrieve(query, intent)
        
        return results
```

## ğŸ§  æ¨¡å‹é€‰æ‹©ä¸è®¾è®¡

### 1. æŸ¥è¯¢æ„å›¾åˆ†ç±»å™¨

#### æ¨¡å‹é€‰æ‹©ï¼šDistilBERT
**ä¸ºä»€ä¹ˆé€‰æ‹©DistilBERTï¼Ÿ**
- **è½»é‡çº§**: 66Må‚æ•°ï¼Œæ¯”BERT-baseå°40%
- **é«˜æ•ˆ**: æ¨ç†é€Ÿåº¦æ¯”BERTå¿«60%
- **æ€§èƒ½**: åœ¨åˆ†ç±»ä»»åŠ¡ä¸Šä¿æŒ97%çš„BERTæ€§èƒ½
- **éƒ¨ç½²å‹å¥½**: å†…å­˜å ç”¨å°ï¼Œé€‚åˆç”Ÿäº§ç¯å¢ƒ

#### ç½‘ç»œæ¶æ„
```python
class IntentClassifier(nn.Module):
    def __init__(self, model_name, num_classes=4):
        super().__init__()
        self.bert = DistilBertModel.from_pretrained(model_name)
        self.dropout = nn.Dropout(0.3)
        self.classifier = nn.Linear(768, num_classes)
        self.softmax = nn.Softmax(dim=1)
    
    def forward(self, input_ids, attention_mask):
        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)
        pooled_output = outputs.last_hidden_state[:, 0]  # [CLS] token
        pooled_output = self.dropout(pooled_output)
        logits = self.classifier(pooled_output)
        probabilities = self.softmax(logits)
        return logits, probabilities
```

#### è®­ç»ƒç­–ç•¥
- **å­¦ä¹ ç‡**: 2e-5 (BERTæ ‡å‡†å­¦ä¹ ç‡)
- **æ‰¹æ¬¡å¤§å°**: 32
- **è®­ç»ƒè½®æ•°**: 5 epochs
- **ä¼˜åŒ–å™¨**: AdamW
- **æŸå¤±å‡½æ•°**: CrossEntropyLoss
- **æ­£åˆ™åŒ–**: Dropout(0.3) + Weight Decay(0.01)

### 2. æŸ¥è¯¢æ„å›¾åˆ†ç±»ä½“ç³»

#### å››ç±»æŸ¥è¯¢æ„å›¾å®šä¹‰
```python
INTENT_DEFINITIONS = {
    'factual': {
        'description': 'å¯»æ±‚å…·ä½“äº‹å®ã€æ•°æ®ã€å®šä¹‰çš„æŸ¥è¯¢',
        'examples': [
            'å˜å‹å™¨çš„é¢å®šåŠŸç‡æ˜¯å¤šå°‘ï¼Ÿ',
            'ç”µç½‘é¢‘ç‡æ ‡å‡†å€¼',
            'ä»€ä¹ˆæ˜¯çŸ­è·¯ç”µæµï¼Ÿ'
        ],
        'keywords': ['ä»€ä¹ˆæ˜¯', 'å¤šå°‘', 'å®šä¹‰', 'æ•°å€¼', 'æ ‡å‡†']
    },
    
    'conceptual': {
        'description': 'å¯»æ±‚æ¦‚å¿µè§£é‡Šã€åŸç†è¯´æ˜çš„æŸ¥è¯¢', 
        'examples': [
            'è§£é‡Šç”µç½‘ç¨³å®šæ€§çš„åŸç†',
            'ä¸ºä»€ä¹ˆä¼šå‘ç”Ÿç”µå‹æ³¢åŠ¨ï¼Ÿ',
            'ç”µåŠ›ç³»ç»Ÿä¿æŠ¤çš„ä½œç”¨æœºåˆ¶'
        ],
        'keywords': ['ä¸ºä»€ä¹ˆ', 'å¦‚ä½•', 'åŸç†', 'æœºåˆ¶', 'è§£é‡Š']
    },
    
    'procedural': {
        'description': 'å¯»æ±‚æ“ä½œæ­¥éª¤ã€æµç¨‹æ–¹æ³•çš„æŸ¥è¯¢',
        'examples': [
            'å¦‚ä½•è¿›è¡Œå˜å‹å™¨ç»´æŠ¤ï¼Ÿ',
            'ç”µç½‘æ•…éšœå¤„ç†æµç¨‹',
            'è®¾å¤‡å®‰è£…æ­¥éª¤'
        ],
        'keywords': ['å¦‚ä½•', 'æ­¥éª¤', 'æµç¨‹', 'æ–¹æ³•', 'æ“ä½œ']
    },
    
    'comparative': {
        'description': 'å¯»æ±‚æ¯”è¾ƒåˆ†æã€ä¼˜ç¼ºç‚¹å¯¹æ¯”çš„æŸ¥è¯¢',
        'examples': [
            'æ¯”è¾ƒä¸åŒç±»å‹çš„å‘ç”µæœº',
            'äº¤æµä¸ç›´æµè¾“ç”µçš„ä¼˜ç¼ºç‚¹',
            'å„ç§ä¿æŠ¤è£…ç½®çš„å·®å¼‚'
        ],
        'keywords': ['æ¯”è¾ƒ', 'å¯¹æ¯”', 'å·®å¼‚', 'ä¼˜ç¼ºç‚¹', 'åŒºåˆ«']
    }
}
```

## ğŸ” æ£€ç´¢ç­–ç•¥è®¾è®¡

### 1. äº‹å®æ€§æŸ¥è¯¢ç­–ç•¥ (Factual Strategy)
```python
class FactualRetrievalStrategy:
    def __init__(self):
        self.exact_matcher = ExactMatcher()      # ç²¾ç¡®åŒ¹é…
        self.keyword_retriever = BM25Retriever() # å…³é”®è¯æ£€ç´¢
        self.vector_retriever = FAISSRetriever() # å‘é‡æ£€ç´¢
    
    def retrieve(self, query, top_k=20):
        # æƒé‡åˆ†é…: ç²¾ç¡®åŒ¹é…(0.5) + å…³é”®è¯(0.3) + å‘é‡(0.2)
        exact_results = self.exact_matcher.search(query, top_k//2)
        keyword_results = self.keyword_retriever.search(query, top_k//2)
        vector_results = self.vector_retriever.search(query, top_k//4)
        
        # åŠ æƒèåˆ
        final_results = self._weighted_fusion(
            [(exact_results, 0.5), (keyword_results, 0.3), (vector_results, 0.2)]
        )
        return final_results[:top_k]
```

### 2. æ¦‚å¿µæ€§æŸ¥è¯¢ç­–ç•¥ (Conceptual Strategy)
```python
class ConceptualRetrievalStrategy:
    def __init__(self):
        self.vector_retriever = FAISSRetriever()
        self.semantic_expander = SemanticQueryExpander()
        self.keyword_retriever = BM25Retriever()
    
    def retrieve(self, query, top_k=20):
        # æŸ¥è¯¢æ‰©å±•
        expanded_query = self.semantic_expander.expand(query)
        
        # æƒé‡åˆ†é…: å‘é‡æ£€ç´¢(0.6) + æ‰©å±•æŸ¥è¯¢(0.3) + å…³é”®è¯(0.1)
        vector_results = self.vector_retriever.search(query, top_k)
        expanded_results = self.vector_retriever.search(expanded_query, top_k//2)
        keyword_results = self.keyword_retriever.search(query, top_k//4)
        
        return self._weighted_fusion([
            (vector_results, 0.6), (expanded_results, 0.3), (keyword_results, 0.1)
        ])[:top_k]
```

### 3. ç¨‹åºæ€§æŸ¥è¯¢ç­–ç•¥ (Procedural Strategy)
```python
class ProceduralRetrievalStrategy:
    def __init__(self):
        self.sequence_matcher = SequenceMatcher()    # åºåˆ—åŒ¹é…
        self.structure_retriever = StructureRetriever() # ç»“æ„åŒ–æ£€ç´¢
        self.vector_retriever = FAISSRetriever()
    
    def retrieve(self, query, top_k=20):
        # æƒé‡åˆ†é…: åºåˆ—åŒ¹é…(0.4) + ç»“æ„åŒ–(0.4) + å‘é‡(0.2)
        sequence_results = self.sequence_matcher.search(query, top_k//2)
        structure_results = self.structure_retriever.search(query, top_k//2)
        vector_results = self.vector_retriever.search(query, top_k//4)
        
        return self._weighted_fusion([
            (sequence_results, 0.4), (structure_results, 0.4), (vector_results, 0.2)
        ])[:top_k]
```

### 4. æ¯”è¾ƒæ€§æŸ¥è¯¢ç­–ç•¥ (Comparative Strategy)
```python
class ComparativeRetrievalStrategy:
    def __init__(self):
        self.diversity_retriever = DiversityRetriever() # å¤šæ ·æ€§æ£€ç´¢
        self.contrast_matcher = ContrastMatcher()       # å¯¹æ¯”åŒ¹é…
        self.vector_retriever = FAISSRetriever()
    
    def retrieve(self, query, top_k=20):
        # æƒé‡åˆ†é…: å¤šæ ·æ€§(0.4) + å¯¹æ¯”åŒ¹é…(0.4) + å‘é‡(0.2)
        diversity_results = self.diversity_retriever.search(query, top_k)
        contrast_results = self.contrast_matcher.search(query, top_k//2)
        vector_results = self.vector_retriever.search(query, top_k//2)
        
        return self._weighted_fusion([
            (diversity_results, 0.4), (contrast_results, 0.4), (vector_results, 0.2)
        ])[:top_k]
```

## ğŸ“Š æ•°æ®é›†è®¾è®¡

### 1. æŸ¥è¯¢æ„å›¾æ ‡æ³¨æ•°æ®é›†
```python
# æ•°æ®é›†æ„å»ºè®¡åˆ’
INTENT_DATASET = {
    'total_queries': 2000,
    'distribution': {
        'factual': 500,      # 25%
        'conceptual': 600,   # 30%
        'procedural': 500,   # 25%
        'comparative': 400   # 20%
    },
    'sources': [
        'MS MARCO queries',           # é€šç”¨æŸ¥è¯¢
        'Natural Questions',          # äº‹å®æ€§æŸ¥è¯¢
        'Stack Overflow',            # ç¨‹åºæ€§æŸ¥è¯¢
        'è‡ªå»ºç”µç½‘é¢†åŸŸæŸ¥è¯¢',            # é¢†åŸŸç‰¹å®šæŸ¥è¯¢
    ],
    'annotation_guidelines': {
        'annotators': 3,             # 3äººæ ‡æ³¨
        'agreement_threshold': 0.8,   # ä¸€è‡´æ€§é˜ˆå€¼
        'conflict_resolution': 'majority_vote'
    }
}
```

### 2. æ£€ç´¢è¯„ä¼°æ•°æ®é›†
```python
EVALUATION_DATASETS = {
    'primary': {
        'MS_MARCO_Passage': {
            'size': '8.8M passages',
            'queries': '6,980 dev queries',
            'relevance': 'human-labeled',
            'use_case': 'ä¸»è¦è¯„ä¼°æ•°æ®é›†'
        }
    },
    
    'secondary': {
        'Natural_Questions': {
            'size': '2.7M passages', 
            'queries': '3,610 dev queries',
            'relevance': 'human-labeled',
            'use_case': 'äº‹å®æ€§æŸ¥è¯¢è¯„ä¼°'
        },
        
        'TREC_DL_2019': {
            'size': '3.2M passages',
            'queries': '43 queries', 
            'relevance': 'graded relevance',
            'use_case': 'æ·±åº¦è¯„ä¼°'
        }
    },
    
    'domain_specific': {
        'PowerGrid_QA': {
            'size': 'è‡ªå»ºæ•°æ®é›†',
            'queries': '500 queries',
            'relevance': 'ä¸“å®¶æ ‡æ³¨',
            'use_case': 'é¢†åŸŸé€‚åº”æ€§è¯„ä¼°'
        }
    }
}
```

## ğŸ“š ç›¸å…³å·¥ä½œä¸å¯¹æ¯”åŸºçº¿

### 1. ä¸»è¦å¯¹æ¯”è®ºæ–‡
```python
BASELINE_PAPERS = {
    'primary_baselines': [
        {
            'paper': 'DAT: Dynamic Alpha Tuning for Hybrid Retrieval',
            'arxiv': '2506.08276',
            'method': 'Dynamic weight tuning between dense and sparse',
            'limitation': 'Only binary weight adjustment, no intent awareness'
        },
        
        {
            'paper': 'HYRR: Hybrid Infused Reranking for Passage Retrieval', 
            'method': 'Hybrid training for reranking',
            'limitation': 'Reranking stage only, no first-stage optimization'
        }
    ],
    
    'classical_baselines': [
        {
            'method': 'BM25',
            'description': 'Traditional sparse retrieval'
        },
        {
            'method': 'DPR (Dense Passage Retrieval)',
            'description': 'Dense retrieval baseline'
        },
        {
            'method': 'RRF (Reciprocal Rank Fusion)',
            'description': 'Simple fusion method'
        },
        {
            'method': 'Fixed Weight Hybrid',
            'description': 'Fixed 0.5:0.5 weight combination'
        }
    ],
    
    'query_understanding': [
        {
            'paper': 'Query Classification for Web Search',
            'focus': 'Query intent classification methods'
        },
        {
            'paper': 'Understanding User Intent in Search',
            'focus': 'Intent-aware search strategies'
        }
    ]
}
```

### 2. æŠ€æœ¯å¯¹æ¯”åˆ†æ
```python
COMPARISON_MATRIX = {
    'DAT': {
        'intent_awareness': False,
        'strategy_adaptation': False, 
        'weight_dimensions': 2,  # dense vs sparse
        'computational_cost': 'High (LLM-based)',
        'our_advantage': 'Intent-aware strategy selection'
    },
    
    'HYRR': {
        'intent_awareness': False,
        'strategy_adaptation': False,
        'stage': 'Reranking only',
        'our_advantage': 'First-stage retrieval optimization'
    },
    
    'Fixed_Hybrid': {
        'adaptability': False,
        'query_specificity': False,
        'our_advantage': 'Query-specific strategy adaptation'
    }
}
```

## ğŸ§ª å®éªŒè®¾è®¡

### 1. å®éªŒè®¾ç½®
```python
EXPERIMENT_CONFIG = {
    'models': {
        'intent_classifier': 'distilbert-base-uncased',
        'vector_encoder': 'sentence-transformers/all-MiniLM-L6-v2',
        'reranker': 'cross-encoder/ms-marco-MiniLM-L-6-v2'
    },
    
    'hyperparameters': {
        'learning_rate': 2e-5,
        'batch_size': 32,
        'max_length': 128,
        'top_k': 20,
        'temperature': 0.1
    },
    
    'evaluation_metrics': [
        'NDCG@10', 'MRR', 'Recall@100', 
        'MAP', 'Precision@5', 'Latency'
    ]
}
```

### 2. æ ¸å¿ƒå®éªŒ
```python
EXPERIMENTS = {
    'exp1_intent_classification': {
        'objective': 'éªŒè¯æ„å›¾åˆ†ç±»å™¨æ€§èƒ½',
        'dataset': '2000 labeled queries',
        'metrics': ['Accuracy', 'F1-score', 'Confusion Matrix'],
        'expected_result': 'Accuracy > 85%'
    },
    
    'exp2_strategy_effectiveness': {
        'objective': 'éªŒè¯ä¸åŒç­–ç•¥çš„æœ‰æ•ˆæ€§',
        'setup': 'æ¯ç§æ„å›¾ç±»å‹å•ç‹¬è¯„ä¼°',
        'metrics': ['NDCG@10 per intent type'],
        'expected_result': 'Each strategy outperforms general approach'
    },
    
    'exp3_end_to_end_comparison': {
        'objective': 'ç«¯åˆ°ç«¯æ€§èƒ½å¯¹æ¯”',
        'baselines': ['DAT', 'HYRR', 'Fixed Hybrid', 'BM25', 'DPR'],
        'datasets': ['MS MARCO', 'Natural Questions', 'TREC DL'],
        'expected_result': 'Overall NDCG@10 improvement 8-12%'
    },
    
    'exp4_ablation_study': {
        'objective': 'æ¶ˆèç ”ç©¶',
        'ablations': [
            'Without intent classification',
            'With single strategy only', 
            'Without confidence-based hybrid',
            'Different weight combinations'
        ],
        'expected_result': 'Each component contributes positively'
    },
    
    'exp5_efficiency_analysis': {
        'objective': 'è®¡ç®—æ•ˆç‡åˆ†æ',
        'metrics': ['Query latency', 'Memory usage', 'Throughput'],
        'comparison': 'vs DAT and other baselines',
        'expected_result': '40% latency reduction vs DAT'
    }
}
```

### 3. è¯„ä¼°æŒ‡æ ‡è¯¦ç»†å®šä¹‰
```python
EVALUATION_METRICS = {
    'NDCG@10': {
        'formula': 'DCG@10 / IDCG@10',
        'purpose': 'ä¸»è¦æ€§èƒ½æŒ‡æ ‡',
        'interpretation': 'è€ƒè™‘æ’åºè´¨é‡çš„ç›¸å…³æ€§æŒ‡æ ‡'
    },
    
    'MRR': {
        'formula': '1/|Q| * Î£(1/rank_i)',
        'purpose': 'é¦–ä¸ªç›¸å…³ç»“æœçš„æ’å',
        'interpretation': 'è¶Šé«˜è¶Šå¥½ï¼Œå…³æ³¨topç»“æœè´¨é‡'
    },
    
    'Recall@100': {
        'formula': 'Retrieved relevant / Total relevant',
        'purpose': 'å¬å›èƒ½åŠ›è¯„ä¼°',
        'interpretation': 'æ£€ç´¢ç³»ç»Ÿçš„è¦†ç›–èƒ½åŠ›'
    },
    
    'Intent_Accuracy': {
        'formula': 'Correct predictions / Total predictions',
        'purpose': 'æ„å›¾åˆ†ç±»å‡†ç¡®ç‡',
        'interpretation': 'åˆ†ç±»å™¨çš„åŸºç¡€æ€§èƒ½'
    },
    
    'Latency': {
        'unit': 'milliseconds',
        'purpose': 'å“åº”é€Ÿåº¦è¯„ä¼°',
        'interpretation': 'å®é™…éƒ¨ç½²çš„å…³é”®æŒ‡æ ‡'
    }
}
```

## ğŸ“ˆ é¢„æœŸç»“æœä¸åˆ†æ

### 1. æ€§èƒ½é¢„æœŸ
```python
EXPECTED_RESULTS = {
    'overall_performance': {
        'NDCG@10_improvement': '8-12% vs best baseline',
        'MRR_improvement': '6-10% vs best baseline',
        'Recall@100_improvement': '5-8% vs best baseline'
    },
    
    'intent_specific_performance': {
        'factual_queries': '15-20% NDCG@10 improvement',
        'conceptual_queries': '10-15% NDCG@10 improvement', 
        'procedural_queries': '12-18% NDCG@10 improvement',
        'comparative_queries': '8-12% NDCG@10 improvement'
    },
    
    'efficiency_gains': {
        'latency_reduction': '40% vs DAT',
        'memory_overhead': '<10% vs baseline',
        'throughput_improvement': '30-50% vs DAT'
    }
}
```

### 2. ç»Ÿè®¡æ˜¾è‘—æ€§æµ‹è¯•
```python
STATISTICAL_TESTS = {
    'significance_test': 'Paired t-test',
    'confidence_level': 0.95,
    'effect_size': 'Cohen\'s d',
    'multiple_comparison': 'Bonferroni correction',
    'sample_size': 'Power analysis for 80% power'
}
```

## ğŸ’» å®ç°ç»†èŠ‚

### 1. é¡¹ç›®ç»“æ„
```
intent_aware_retrieval/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ intent_classifier.py      # æ„å›¾åˆ†ç±»å™¨
â”‚   â”‚   â”œâ”€â”€ retrieval_strategies.py   # æ£€ç´¢ç­–ç•¥
â”‚   â”‚   â””â”€â”€ result_fusion.py         # ç»“æœèåˆ
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ intent_dataset.py        # æ„å›¾æ•°æ®é›†
â”‚   â”‚   â””â”€â”€ evaluation_dataset.py    # è¯„ä¼°æ•°æ®é›†
â”‚   â”œâ”€â”€ experiments/
â”‚   â”‚   â”œâ”€â”€ train_classifier.py      # è®­ç»ƒåˆ†ç±»å™¨
â”‚   â”‚   â”œâ”€â”€ evaluate_strategies.py   # ç­–ç•¥è¯„ä¼°
â”‚   â”‚   â””â”€â”€ end_to_end_eval.py      # ç«¯åˆ°ç«¯è¯„ä¼°
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ metrics.py              # è¯„ä¼°æŒ‡æ ‡
â”‚       â””â”€â”€ config.py               # é…ç½®æ–‡ä»¶
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ intent_labels/              # æ„å›¾æ ‡æ³¨æ•°æ®
â”‚   â”œâ”€â”€ retrieval_corpus/           # æ£€ç´¢è¯­æ–™
â”‚   â””â”€â”€ evaluation_sets/            # è¯„ä¼°æ•°æ®é›†
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ intent_classifier.pt        # è®­ç»ƒå¥½çš„åˆ†ç±»å™¨
â”‚   â””â”€â”€ retrieval_indices/          # æ£€ç´¢ç´¢å¼•
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ experiments/                # å®éªŒç»“æœ
â”‚   â””â”€â”€ analysis/                   # ç»“æœåˆ†æ
â””â”€â”€ requirements.txt
```

### 2. æ ¸å¿ƒä»£ç å®ç°
```python
# src/models/intent_classifier.py
import torch
import torch.nn as nn
from transformers import DistilBertModel, DistilBertTokenizer

class IntentClassifier(nn.Module):
    def __init__(self, model_name="distilbert-base-uncased", num_classes=4):
        super().__init__()
        self.bert = DistilBertModel.from_pretrained(model_name)
        self.dropout = nn.Dropout(0.3)
        self.classifier = nn.Linear(768, num_classes)
        self.tokenizer = DistilBertTokenizer.from_pretrained(model_name)

        # æ„å›¾æ ‡ç­¾æ˜ å°„
        self.intent_labels = {
            0: 'factual',
            1: 'conceptual',
            2: 'procedural',
            3: 'comparative'
        }

    def forward(self, input_ids, attention_mask):
        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)
        pooled_output = outputs.last_hidden_state[:, 0]  # [CLS] token
        pooled_output = self.dropout(pooled_output)
        logits = self.classifier(pooled_output)
        return logits

    def predict(self, query_text):
        """é¢„æµ‹æŸ¥è¯¢æ„å›¾"""
        inputs = self.tokenizer(
            query_text,
            return_tensors="pt",
            max_length=128,
            padding=True,
            truncation=True
        )

        with torch.no_grad():
            logits = self.forward(inputs['input_ids'], inputs['attention_mask'])
            probabilities = torch.softmax(logits, dim=1)
            predicted_class = torch.argmax(probabilities, dim=1).item()
            confidence = torch.max(probabilities).item()

        return self.intent_labels[predicted_class], confidence
```

### 3. è®­ç»ƒè„šæœ¬
```python
# src/experiments/train_classifier.py
import torch
from torch.utils.data import DataLoader
from transformers import AdamW
from sklearn.metrics import classification_report
import wandb  # å®éªŒè·Ÿè¸ª

def train_intent_classifier():
    # åˆå§‹åŒ–wandb
    wandb.init(project="intent-aware-retrieval", name="intent-classifier")

    # åŠ è½½æ•°æ®
    train_dataset = IntentDataset("data/intent_labels/train.json")
    val_dataset = IntentDataset("data/intent_labels/val.json")

    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=32)

    # åˆå§‹åŒ–æ¨¡å‹
    model = IntentClassifier()
    optimizer = AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)
    criterion = nn.CrossEntropyLoss()

    # è®­ç»ƒå¾ªç¯
    for epoch in range(5):
        model.train()
        total_loss = 0

        for batch in train_loader:
            optimizer.zero_grad()

            logits = model(batch['input_ids'], batch['attention_mask'])
            loss = criterion(logits, batch['labels'])

            loss.backward()
            optimizer.step()

            total_loss += loss.item()

        # éªŒè¯
        val_accuracy = evaluate_classifier(model, val_loader)

        # è®°å½•æŒ‡æ ‡
        wandb.log({
            "epoch": epoch,
            "train_loss": total_loss / len(train_loader),
            "val_accuracy": val_accuracy
        })

        print(f"Epoch {epoch}: Loss={total_loss/len(train_loader):.4f}, Val Acc={val_accuracy:.4f}")

    # ä¿å­˜æ¨¡å‹
    torch.save(model.state_dict(), "models/intent_classifier.pt")
    return model
```

### 4. å®éªŒé…ç½®æ–‡ä»¶
```python
# src/utils/config.py
import os
from dataclasses import dataclass
from typing import Dict, List

@dataclass
class ExperimentConfig:
    # æ¨¡å‹é…ç½®
    intent_model_name: str = "distilbert-base-uncased"
    vector_model_name: str = "sentence-transformers/all-MiniLM-L6-v2"

    # è®­ç»ƒé…ç½®
    learning_rate: float = 2e-5
    batch_size: int = 32
    num_epochs: int = 5
    max_length: int = 128

    # æ£€ç´¢é…ç½®
    top_k: int = 20
    confidence_threshold: float = 0.8

    # ç­–ç•¥æƒé‡é…ç½®
    strategy_weights: Dict[str, Dict[str, float]] = None

    def __post_init__(self):
        if self.strategy_weights is None:
            self.strategy_weights = {
                'factual': {'exact': 0.5, 'keyword': 0.3, 'vector': 0.2},
                'conceptual': {'vector': 0.6, 'expanded': 0.3, 'keyword': 0.1},
                'procedural': {'sequence': 0.4, 'structure': 0.4, 'vector': 0.2},
                'comparative': {'diversity': 0.4, 'contrast': 0.4, 'vector': 0.2}
            }

    # æ•°æ®é›†è·¯å¾„
    datasets: Dict[str, str] = None

    def __post_init__(self):
        if self.datasets is None:
            self.datasets = {
                'ms_marco': 'data/ms_marco/',
                'natural_questions': 'data/natural_questions/',
                'intent_labels': 'data/intent_labels/',
                'evaluation': 'data/evaluation_sets/'
            }

# å…¨å±€é…ç½®å®ä¾‹
config = ExperimentConfig()
```

### 5. è¯„ä¼°è„šæœ¬
```python
# src/experiments/end_to_end_eval.py
import json
import numpy as np
from typing import Dict, List
import matplotlib.pyplot as plt
import seaborn as sns

class ExperimentEvaluator:
    def __init__(self, config):
        self.config = config
        self.results = {}

    def run_full_evaluation(self):
        """è¿è¡Œå®Œæ•´çš„è¯„ä¼°å®éªŒ"""

        # 1. æ„å›¾åˆ†ç±»å™¨è¯„ä¼°
        print("ğŸ” è¯„ä¼°æ„å›¾åˆ†ç±»å™¨...")
        intent_results = self.evaluate_intent_classifier()

        # 2. ç­–ç•¥æœ‰æ•ˆæ€§è¯„ä¼°
        print("ğŸ¯ è¯„ä¼°æ£€ç´¢ç­–ç•¥...")
        strategy_results = self.evaluate_strategies()

        # 3. ç«¯åˆ°ç«¯æ€§èƒ½å¯¹æ¯”
        print("ğŸ† ç«¯åˆ°ç«¯æ€§èƒ½å¯¹æ¯”...")
        comparison_results = self.compare_with_baselines()

        # 4. æ¶ˆèç ”ç©¶
        print("ğŸ”¬ æ¶ˆèç ”ç©¶...")
        ablation_results = self.ablation_study()

        # 5. æ•ˆç‡åˆ†æ
        print("âš¡ æ•ˆç‡åˆ†æ...")
        efficiency_results = self.efficiency_analysis()

        # æ±‡æ€»ç»“æœ
        self.results = {
            'intent_classification': intent_results,
            'strategy_effectiveness': strategy_results,
            'baseline_comparison': comparison_results,
            'ablation_study': ablation_results,
            'efficiency_analysis': efficiency_results
        }

        # ç”ŸæˆæŠ¥å‘Š
        self.generate_report()

        return self.results

    def compare_with_baselines(self):
        """ä¸åŸºçº¿æ–¹æ³•å¯¹æ¯”"""
        baselines = ['DAT', 'HYRR', 'Fixed_Hybrid', 'BM25', 'DPR']
        datasets = ['ms_marco', 'natural_questions', 'trec_dl']

        results = {}

        for dataset in datasets:
            results[dataset] = {}

            for baseline in baselines:
                # è¿è¡ŒåŸºçº¿æ–¹æ³•
                baseline_scores = self.run_baseline(baseline, dataset)
                results[dataset][baseline] = baseline_scores

            # è¿è¡Œæˆ‘ä»¬çš„æ–¹æ³•
            our_scores = self.run_our_method(dataset)
            results[dataset]['ours'] = our_scores

        return results

    def generate_report(self):
        """ç”Ÿæˆå®éªŒæŠ¥å‘Š"""
        report = {
            'summary': self.generate_summary(),
            'detailed_results': self.results,
            'statistical_tests': self.run_statistical_tests(),
            'visualizations': self.create_visualizations()
        }

        # ä¿å­˜æŠ¥å‘Š
        with open('results/experiment_report.json', 'w') as f:
            json.dump(report, f, indent=2)

        print("ğŸ“Š å®éªŒæŠ¥å‘Šå·²ä¿å­˜åˆ° results/experiment_report.json")

        return report
```

### 6. éƒ¨ç½²é…ç½®
```python
# deployment/api_server.py
from flask import Flask, request, jsonify
import torch
from src.models.intent_classifier import IntentClassifier
from src.models.retrieval_strategies import IntentAwareRetrieval

app = Flask(__name__)

# åŠ è½½æ¨¡å‹
intent_model = IntentClassifier()
intent_model.load_state_dict(torch.load('models/intent_classifier.pt'))
retrieval_system = IntentAwareRetrieval(intent_model)

@app.route('/search', methods=['POST'])
def search():
    data = request.json
    query = data.get('query', '')
    top_k = data.get('top_k', 20)

    try:
        # æ‰§è¡Œæ£€ç´¢
        results = retrieval_system.search(query, top_k)

        return jsonify({
            'status': 'success',
            'query': query,
            'intent': results['intent'],
            'confidence': results['confidence'],
            'strategy': results['strategy'],
            'results': results['documents'],
            'latency_ms': results['latency']
        })

    except Exception as e:
        return jsonify({
            'status': 'error',
            'message': str(e)
        }), 500

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000, debug=False)
```

## ğŸ¯ è®ºæ–‡å†™ä½œå¤§çº²

### æ ‡é¢˜
"Query Intent-Aware Adaptive Retrieval: Beyond Binary Weight Tuning for Hybrid Information Retrieval"

### æ‘˜è¦ (150-200è¯)
- é—®é¢˜ï¼šç°æœ‰æ··åˆæ£€ç´¢æ–¹æ³•ç¼ºä¹æŸ¥è¯¢æ„å›¾æ„ŸçŸ¥
- æ–¹æ³•ï¼šæå‡ºæŸ¥è¯¢æ„å›¾æ„ŸçŸ¥çš„è‡ªé€‚åº”æ£€ç´¢ç­–ç•¥
- ç»“æœï¼šåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šæ˜¾è‘—æå‡æ€§èƒ½
- è´¡çŒ®ï¼šé¦–ä¸ªåŸºäºæ„å›¾çš„æ£€ç´¢ç­–ç•¥é€‰æ‹©æ¡†æ¶

### 1. Introduction (1é¡µ)
- æ··åˆæ£€ç´¢çš„é‡è¦æ€§å’Œç°çŠ¶
- ç°æœ‰æ–¹æ³•çš„å±€é™æ€§ï¼ˆDATç­‰ï¼‰
- æˆ‘ä»¬çš„æ ¸å¿ƒæ€æƒ³å’Œè´¡çŒ®
- è®ºæ–‡ç»“æ„

### 2. Related Work (1.5é¡µ)
- æ··åˆæ£€ç´¢æ–¹æ³•ç»¼è¿°
- æŸ¥è¯¢æ„å›¾åˆ†ç±»ç ”ç©¶
- è‡ªé€‚åº”æ£€ç´¢ç­–ç•¥
- ä¸æˆ‘ä»¬å·¥ä½œçš„åŒºåˆ«

### 3. Methodology (2.5é¡µ)
- 3.1 æŸ¥è¯¢æ„å›¾åˆ†ç±»ä½“ç³»
- 3.2 æ„å›¾æ„ŸçŸ¥çš„æ£€ç´¢ç­–ç•¥è®¾è®¡
- 3.3 è‡ªé€‚åº”ç­–ç•¥é€‰æ‹©æœºåˆ¶
- 3.4 ç³»ç»Ÿæ¶æ„å’Œå®ç°

### 4. Experiments (2.5é¡µ)
- 4.1 å®éªŒè®¾ç½®å’Œæ•°æ®é›†
- 4.2 åŸºçº¿æ–¹æ³•å’Œè¯„ä¼°æŒ‡æ ‡
- 4.3 ä¸»è¦å®éªŒç»“æœ
- 4.4 æ¶ˆèç ”ç©¶
- 4.5 æ•ˆç‡åˆ†æ

### 5. Analysis (1é¡µ)
- 5.1 ä¸åŒæ„å›¾ç±»å‹çš„æ€§èƒ½åˆ†æ
- 5.2 ç­–ç•¥é€‰æ‹©çš„æœ‰æ•ˆæ€§åˆ†æ
- 5.3 é”™è¯¯æ¡ˆä¾‹åˆ†æ
- 5.4 å±€é™æ€§è®¨è®º

### 6. Conclusion (0.5é¡µ)
- ä¸»è¦è´¡çŒ®æ€»ç»“
- å®é™…åº”ç”¨ä»·å€¼
- æœªæ¥å·¥ä½œæ–¹å‘

---

è¿™ä¸ªè¯¦ç»†çš„æŠ€æœ¯æ–¹æ¡ˆæ¶µç›–äº†ä»æ¨¡å‹é€‰æ‹©åˆ°å®éªŒè®¾è®¡ã€ä»£ç å®ç°ã€éƒ¨ç½²é…ç½®çš„æ‰€æœ‰å…³é”®ç¯èŠ‚ï¼Œä¸ºè®ºæ–‡çš„å®æ–½æä¾›äº†å®Œæ•´çš„æŠ€æœ¯è·¯çº¿å›¾ã€‚æ•´ä¸ªæ–¹æ¡ˆä¸“æ³¨äºçº¯æ–‡æœ¬æ£€ç´¢ï¼Œç®—åŠ›è¦æ±‚é€‚ä¸­ï¼Œå…·æœ‰å¾ˆå¼ºçš„åˆ›æ–°æ€§å’Œå®ç”¨ä»·å€¼ã€‚
