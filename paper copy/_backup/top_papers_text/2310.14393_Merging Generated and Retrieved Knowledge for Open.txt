Merging Generated and Retrieved Knowledge for Open-Domain QA
Yunxiang Zhang‚àó, Muhammad Khalifa‚àó, Lajanugen Logeswaran‚Ä†,
Moontae Lee‚Ä†‚Ä°,Honglak Lee‚àó‚Ä†, Lu Wang‚àó
University of Michigan‚àó, LG AI Research‚Ä†, University of Illinois at Chicago‚Ä°
Abstract
Open-domain question answering (QA) sys-
tems are often built with retrieval modules.
However, retrieving passages from a given
source is known to suffer from insufficient
knowledge coverage. Alternatively, prompt-
ing large language models (LLMs) to gener-
ate contextual passages based on their para-
metric knowledge has been shown to improve
QA performance. Yet, LLMs tend to ‚Äúhal-
lucinate‚Äù content that conflicts with the re-
trieved knowledge. Based on the intuition that
answers supported by both sources are more
likely to be correct, we propose COMBO , a
Compatibility- Oriented knowledge Merging for
BetterOpen-domain QA framework, to effec-
tively leverage the two sources of informa-
tion. Concretely, we match LLM-generated
passages with retrieved counterparts into com-
patible pairs , based on discriminators trained
with silver compatibility labels. Then a Fusion-
in-Decoder-based (Izacard and Grave, 2021b)
reader model handles passage pairs to arrive
at the final answer. Experiments show that
COMBO outperforms competitive baselines
on three out of four tested open-domain QA
benchmarks. Further analysis reveals that our
proposed framework demonstrates greater effi-
cacy in scenarios with a higher degree of knowl-
edge conflicts.1
1 Introduction
Open-domain question answering (QA) typically
requires models to consolidate and reason over in-
formation from external knowledge sources (Chen
et al., 2017; Petroni et al., 2021). A common
retrieve-then-read framework (Izacard and Grave,
2021a,b; Izacard et al., 2022; Karpukhin et al.,
2020) would first fetch relevant passages from an
external corpus and pass them to a reader model
to arrive at an answer. Retrieving from reliable
‚àóCorrespondence to yunxiang@umich.edu
1Our code is publicly available at https://github.com/
yunx-z/COMBO .
NaturalQuestions(Single-hopQA)Question:Who plays Charlotte in ‚ÄúThe Strain‚Äù season 4?CorrectAnswer:Rhona Mitra‚àöPrediction:Alexandra Breckenridge √óHotpotQA(Multi-hopQA)Question:Gail Matthiusco-anchored the Weekend Update segment of "Saturday Night Live" with the actor who played the villain Nicholas Andre in what movie? Answer:Dumb and Dumber‚àöPrediction:The Goonies √óRetrievedPassage1.(Gail Matthius) ‚Ä¶co-anchored the Weekend Update segment with Charles Rocket in 1981.2.(Charles Rocket)‚Ä¶He was best known for his role as the villain Nicholas Andre in the film ‚ÄúDumb and Dumber‚Äù‚Ä¶1.Gail Matthiusis an American actress ‚Ä¶ She also co-anchored the Weekend Update segment of the show "Saturday Night Live" ‚Ä¶2.Robert Davi‚Ä¶ is perhaps best known for his roles in movies such as ‚Ä¶ "The Goonies‚Äù ‚Ä¶ where he played the character Nicholas Andre.LLM-generatedPassageLLM-generatedPassageThe Strain is an American horror drama television series ‚Ä¶. Charlotte ‚Ä¶is played by Alexandra Breckenridge in season 4.RetrievedPassage(Rhona Mitra) ‚Ä¶she played Charlotte in the fourth season of ‚ÄúThe Strain‚Äù TV Series‚Ä¶Figure 1: A Fusion-in-Decoder-based (Izacard and
Grave, 2021b) QA model is misled by the knowledge
conflict between retrieved passage and hallucinating
LLM-generated passage on an example from Natu-
ralQuestions (Kwiatkowski et al., 2019). This is because
QA models tend to favor LLM passages when conflict
exists. More detailed analyses are in Appendix A.1.
sources, e.g., Wikipedia, enjoys the benefits of be-
ing factual, but may suffer from incomplete knowl-
edge coverage and contain irrelevant information.
Large Language Models (LLMs) have been
shown to store a wide range of knowledge in their
parameters, which can serve as an alternative in-
formation source (Brown et al., 2020; Chowdhery
et al., 2022; OpenAI, 2023; Ouyang et al., 2022).
Capitalizing on the success of leveraging LLMs‚Äô
parametric knowledge for natural language under-
standing tasks, a new paradigm known as generate-
then-read (Yu et al., 2023) has emerged. It prompts
an LLM to generate contextual passages for a ques-
tion in lieu of retrieval from static corpora. Com-
pared to retrieved passages, LLM-generated texts
are more relevant to the question, as its generative
nature implicitly optimizes for content relevance.
Yet, they frequently contain factual errors due to
hallucinations (Ji et al., 2023; Peng et al., 2023).
This work aims to address how to combine re-
trieved and parametric knowledge to get the best
of both worlds for open-domain QA . Specifically,arXiv:2310.14393v1  [cs.CL]  22 Oct 2023
we want to maintain the factuality of retrieved
knowledge while leveraging the relevance of LLM
knowledge. Yu et al. (2023) have explored a simple
merging approach by separately encoding the two
types of passages into a Fusion-in-Decoder (Izac-
ard and Grave, 2021b) reader (Figure 2a). While
this setting outperforms using either source alone,
the direct merging approach ignores inconsistent
facts between the sources, which can easily con-
fuse the reader model. Figure 1 shows an exam-
ple of knowledge conflicts where LLM-generated
passage contains fabrication, contradicting the re-
trieved knowledge.2
To address this challenge, we propose a novel
Compatibility- Oriented knowledge Merging for
Better Open-domain ( COMBO ) QA framework.
Intuitively, an answer tends to be correct if it is sup-
ported by information from both sources. There-
fore, we promote the model‚Äôs usage of factual and
relevant information by combining retrieved and
generated knowledge into compatible pairs , which
are then fed into a reader module.
To date, there has been no gold-standard annota-
tion for training a compatibility scorer for passage
pairs. To this end, we introduce a novel method that
automatically mines silver labels of compatibility
at scale, without the need for human annotation
or dataset-specific heuristics. Specifically, we esti-
mate the silver compatibility by checking whether
the prediction correctness of a QA model would
flip if one or both passages from a target pair were
to be removed from the input. Afterward, we train
discriminators on silver labels to compute passage
pairs‚Äô compatibility scores.
Lastly, we benchmark COMBO in a fully-
supervised setting on four popular open-domain
QA datasets, including both single-hop (Natu-
ralQuestions (Kwiatkowski et al., 2019), Triv-
iaQA (Joshi et al., 2017), WebQuestion (Be-
rant et al., 2013)) and multi-hop questions (Hot-
potQA (Yang et al., 2018)). Using state-of-the-
art retrievers, DPR (Karpukhin et al., 2020) and
MDR (Xiong et al., 2021), as well as performant
LLMs, e.g., InstructGPT (Ouyang et al., 2022) and
ChatGPT, COMBO outperforms competitive base-
lines on all testbeds except HotpotQA by up to +1.9
exact match score.
To summarize, the main contributions of our
work are three-fold:
2Figure 8 in Appendix A shows another example of knowl-
edge conflict on HotpotQA (Yang et al., 2018).‚Ä¢We introduce COMBO , a novel compatibility-
oriented framework for merging LLM knowl-
edge and retrieved knowledge in open-domain
QA.
‚Ä¢We automatically mine silver labels for train-
ing compatibility scorers without human an-
notations.
‚Ä¢We demonstrate the effectiveness of our frame-
work with extensive experiments and analyses
over four open-domain QA datasets.
2 Related Work
Parametric and Retrieved Knowledge for QA.
QA models commonly have access to two knowl-
edge sources: parametric knowledge stored in lan-
guage models and retrieved knowledge from ex-
ternal corpora. Previous work (Chen et al., 2022;
Longpre et al., 2021; Pan et al., 2021) focuses on
analyzing knowledge conflicts in simulated settings
by perturbing retrieved contexts, e.g., replacing en-
tities with incorrect counterparts. These studies
reveal that reader models overly rely on the para-
metric knowledge and demonstrate limited abilities
of resolving conflicting information. In contrast,
we propose solutions to repress models from using
generated knowledge that contradicts with retrieved
contexts. Other works (Li et al., 2022a; Mallen
et al., 2022; Neeman et al., 2022) leverage prede-
fined rules to guide the models to choose between
parametric vs. retrieved knowledge sources un-
der conflicts. Instead of relying on dataset-specific
heuristics, we introduce a generalizable approach
that teaches QA models to prioritize compatible
information over conflicting ones.
Augmentation with Large Language Model Out-
puts. LLMs, such as InstructGPT (Ouyang et al.,
2022) or PaLM (Chowdhery et al., 2022), store
rich world knowledge in their model weights
and demonstrate impressive performance on open-
domain QA tasks with prompting techniques. Re-
cent studies further boost their performance by elic-
iting supporting evidence before answer prediction.
The types of supporting evidence include encyclo-
pedia knowledge (Li et al., 2022b; Sun et al., 2022;
Yu et al., 2023), commonsense knowledge (Liu
et al., 2022a,b; Shwartz et al., 2020; Wang et al.,
2022; West et al., 2022) and chain-of-thought rea-
soning steps (Magister et al., 2022; Trivedi et al.,
2022; Wei et al., 2022; Zhang et al., 2022). Most
xx
RP 1LLMPsg5QRetrievedPsg3LLMPsg3QLLMPsg4QRetrievedPsg4RetrievedPsg5AFiD2.PairwiseCompatibilityMatching3.PredictingwithPassagePairs1.CompatibilityScoring
ü•§
üçîxxx
ü•§
üçîLP ùëñRP j
ConsistencyDiscriminatorEvidentialityDiscriminatorLP 1LP 2LP 3LP 4LP 5RP 2RP 3RP 4RP 5‚Ä¶‚Ä¶LLMPsg1QRetrievedPsg1QLLMPsg2QLLMPsg5Q¬∑¬∑¬∑¬∑¬∑¬∑RetrievedPsg2Q¬∑¬∑¬∑¬∑¬∑¬∑RetrievedPsg5QAFiD(a) Direct Merging (Yu et al.,
2023)
xx
RP 1LLMPsg5QRetrievedPsg3LLMPsg3QLLMPsg4QRetrievedPsg4RetrievedPsg5AFiD2.PairwiseCompatibilityMatching3.PredictingwithPassagePairs1.CompatibilityScoring
ü•§
üçîxxx
ü•§
üçîLP ùëñRP j
ConsistencyDiscriminatorEvidentialityDiscriminatorLP 1LP 2LP 3LP 4LP 5RP 2RP 3RP 4RP 5‚Ä¶‚Ä¶LLMPsg1QRetrievedPsg1QLLMPsg2QLLMPsg5Q¬∑¬∑¬∑¬∑¬∑¬∑RetrievedPsg2Q¬∑¬∑¬∑¬∑¬∑¬∑RetrievedPsg5QAFiD (b) COMBO (Ours)
Figure 2: Overview of COMBO framework (right) that uses both LLM-generated passages and retrieved passages
for open-domain QA. 1. We compute pairwise compatibility scores, which quantify the extent to which the two
passages support each other regarding evidence related to the question. 2. We then match them into pairs by
maximizing their overall compatibility (matched pairs are highlighted in red boxes). 3. Finally, passage pairs are
sorted by their compatibility and fed to a FiD-based (Izacard and Grave, 2021b) reader model to produce an answer.
relevant to our work, Yu et al. (2023) directly aug-
ment retrieval passages with LLM-generated texts,
but they do not take knowledge conflicts into ac-
count, which could mislead the model and degrade
the prediction. Our work promotes the model‚Äôs
usage of factual evidence over hallucinating infor-
mation in LLM outputs (Creswell and Shanahan,
2022; OpenAI, 2023; Peng et al., 2023; Zhao et al.,
2023) with the help of retrieval knowledge.
Evidentiality-guided QA. Traditionally, the
field of Open-Domain QA has been dominated
byretrieve-then-read models (Izacard et al., 2021;
Izacard and Grave, 2021a; Karpukhin et al., 2020;
Xiong et al., 2021). The performance of the readers
largely depends on the evidentiality of the retrieved
passages‚Äîwhether they contain the correct evi-
dence to support the answer. Recent work (Asai
et al., 2022; Fajcik et al., 2021; Lee et al., 2021)
augments QA performance by adding a (silver) ev-
identiality signal of each retrieved passage to the
training of reader models. However, their method is
insufficient to work with LLM-generated passages
that contain hallucination errors. We further incor-
porate the evidentiality of LLM-generated passages
and leverage both sources to highlight the correct
evidence for the reader.
3 Method
In this section, we present COMBO , which com-
bines both the retrieved passages and the LLM‚Äôs
parametric knowledge to improve open-domain
QA performance over the existing retrieved-then-read and generate-then-read counterparts.3The
core idea is to feed paired passages‚Äîone from
an LLM, one from a retriever‚Äîinto a FiD-based
reader model. The passages are paired in such a
way that they provide consistent evidence to the
question for the reader to identify both the fac-
tual and relevant information. Specifically, for
each question, Nretrieved passages and MLLM-
generated passages are given to COMBO . The an-
swer is produced in three steps shown in Figure 2b.
1.The compatibility scores of all possible pas-
sage pairs are computed according to an evi-
dentiality discriminator and a consistency dis-
criminator (¬ß3.1), trained using silver labeled
data (¬ß3.2).
2.Acompatibility-oriented matching strategy se-
lects passage pairs to maximize overall com-
patibility while balancing the usage of all pas-
sages (¬ß3.3).
3.A FiD-based reader handles passage pairs,
sorted by compatibility scores, to generate
the final answer.
3.1 Defining Compatibility
We first describe two assumptions, based on a pre-
liminary analysis provided in Appendix A.4, which
lay the basis for the compatibility formulation.4
3We provide a brief introduction to the retrieved-then-read
and generate-then-read QA frameworks in Appendix A.2.
4For simplicity, we illustrate our method under the single-
hop QA setting in the main paper. Appendix A.3 shows how to
adapt it to the multi-hop setting with minimal modifications.
Assumption 1 Retrieved passages are faithful to
real-world facts, i.e., being factual, regardless of
its relevance to the question.
Assumption 2 LLM-generated passages contain
relevant evidence to the question, i.e., being plausi-
ble, irrespective of its factuality.
Figure 1 shows an example of Assumption 2, where
a plausible answer (‚ÄúAlexandra Breckenridge‚Äù) is
supported by the LLM-generated text despite its
inconsistency with the retrieved passage.
With these two assumptions, when an answer
can be evinced by both the retrieved passage and
the LLM-generated passage, it is likely that the
retrieved knowledge contains the relevant evidence
whereas the generated knowledge is factual. More-
over, the answer tends to be correct in such situa-
tions. Therefore, we define the compatibility of a
pair of passages as follows.
Definition 1 A passage pair is COMPATIBLE if
both passages contain the proper evidence to sup-
port answering the question correctly.
With this concept, we hope to match two passages,
one from each source, into compatible pairs. The
pairs will facilitate a reader model by promoting the
correct evidence when knowledge conflicts exist.
Compatibility Formulation. To illustrate how
we compute passage compatibility, we formulate
the concept of compatibility with mathematical
notations. Given a question Q, we use lpito denote
thei-th LLM-generated passage for Q, and rpj
for the j-th retrieved passage. lpi‚ä®Qmeans lpi
contains the correct evidence for Q, and similarly
forrpj‚ä®Q. Following Definition 1, given Q, for
a pair of LLM-generated and retrieved passages lpi
andrpj, we formulate the compatibility score cQ
i,j
asP(lpi‚ä®Q, rp j‚ä®Q), which could be further
factorized into two components:5
compatibility scorez }| {
P(lpi‚ä®Q, rp j‚ä®Q) =
P(rpj‚ä®Q)|{z}
evidentiality score¬∑P(lpi‚ä®Q|rpj‚ä®Q)| {z }
consistency score.(1)
P(rpj‚ä®Q)measures whether the retrieved pas-
sage contains the correct evidence (i.e., evidential-
5Notice that we do not factorize the compatibility score the
other way round (i.e., P(lpi‚ä®Q)¬∑P(rpj‚ä®Q|lpi‚ä®Q)).
This is because lpialways contains plausible evidence to the
question (Assumption 2) so the discriminator cannot measure
the evidentiality of lpion its own ( P(lpi‚ä®Q)). Instead, we
use a retrieved factual passage (Assumption 1) to determine
whether the lpiis hallucinating or not.
Question:When did Italy host the FIFA World Cup?Answer: 1934
QRP1RP2RP3QRP2RP3LP1QRP1RP2RP3LP1QRP2RP3FinetunedBaseReader1984 √ó1934 ‚àö1934 ‚àö1934 ‚àö(FIFA World Cup hosts) ‚Ä¶ the only remaining candidate Italy to take the hosting job for the 1934 World Cup. The decision was ratified ‚Ä¶Retrieved Passage 1(Italy national football team) ‚Ä¶ Italy is one of the most successful national teams in the history of the World Cup, having won four titles (1934, ‚Ä¶Retrieved Passage 2(1990 FIFA World Cup) ‚Ä¶ The vote to choose the hosts of the 1990 tournament was held on 19 May 1984 in Z√ºrich, Switzerland. ‚Ä¶Retrieved Passage 3‚Ä¶ The 1934 FIFA World Cup was the second FIFA World Cup, andwas held in Italy from 27 May to 10 June 1934.LLM-generated Passage 1
RP1LP1ConsistentQuestion:who plays Charlotte in ‚ÄúThe Strain‚Äù season 4?Answer: Rhona Mitra
QRP1RP2RP3QRP2RP3LP7QRP1RP2RP3LP7QRP2RP3FinetunedBaseReaderLauren Collins √óRhona Mitra ‚àöAlexandra Breckenridge √óAlexandra Breckenridge √ó(Rhona Mitra) ‚Ä¶ she played Charlotte in the fourth season of "The Strain" TV Series. in 2018, Mitra was cast as Mercy Graves in The CW television series ‚Ä¶Retrieved Passage 1(Lauren Collins) In 2013, she appeared ‚Ä¶ as a recurring guest role in the upcoming fourth season of the FX series "The Strain" (2017).Retrieved Passage 2(The Strain (TV series)) ‚Ä¶ The Strain is an American horror drama television series that aired on FX from July 13, 2014, to September 17, 2017‚Ä¶Retrieved Passage 3The Strain is an American horror drama television series ‚Ä¶ Charlotte is a character in the series ‚Ä¶ She is played by Alexandra Breckenridge in season 4.LLM-generated Passage 7
RP1LP7ConflictingI.II.III.IV .Figure 3: Example for demonstrating the construction
of silver consistent labels to train the consistency dis-
criminator DC.
ity).P(lpi‚ä®Q|rpj‚ä®Q)characterizes the con-
sistency between the retrieved and LLM-generated
knowledge.
Based on the decomposition in Equation 1,
we train two binary discriminators accordingly:
anevidentiality discriminator DEfor modeling
P(rpj‚ä®Q)and a consistency discriminator
DCfor modeling P(lpi‚ä®Q|rpj‚ä®Q). Con-
cretely, DEtakes a question Qand the j-th re-
trieved passage rpjas input, and predicts whether
rpjis evidential (positive) or non-evidential (neg-
ative). If rpjis evidential, DCwill take Q, the
i-th LLM-generated passage lpi, andrpjas input,
and predicts whether (lpi, rpj)is consistent (pos-
itive) or conflicting (negative), i.e., the retrieved
passage contains the correct evidence while the
LLM-generated passage does not. As a result, a
passage pair is considered compatible if it is both
evidential and consistent.
3.2 Mining Silver Labels
We do not have human-annotated evidentiality and
consistency labels in most existing datasets. To
avoid costly manual annotation, we propose an
approach to automatically mine silver labels for
training the two discriminators. To collect silver
evidentiality labels for training DE, we largely fol-
low the leave-one-out generation approach by Asai
et al. (2022). Briefly, a passage is deemed EVI-
DENTIAL if the prediction by a given QA model
changes from correct to incorrect after removing it
from a pool of retrieved passages. We explain the
details in Appendix C.1.
We then extend this idea to mine consistency
labels of passage pairs for training DC, as demon-
strated in Figures 3 and 9 (for negative sample,
in Appendix C.2). Intuitively, if the prediction
changes from correct to incorrect after removing
either passage from the target pair (e.g., IV ‚áíII
for an LLM-generated passage and I ‚áíII for a re-
trieved passage, as in Figure 3), both passages
supposedly contain the correct evidence and they
are therefore a CONSISTENT pair. Concretely,
for each dataset, we first finetune a base reader
model initialized from Fusion-in-Decoder (Izacard
and Grave, 2021b) with top- Nretrieved passages
PR={rp1, rp 2, ..., rp N}as input.6We then la-
bel the consistency of (lpi, rpj)based on the cor-
rectness of predictions with four types of inputs:
I. all the retrieved passages (Q,PR)II. all the re-
trieved passages except the target retrieved passage
(Q,PR\{rpj})III. all the retrieved passages plus
the target LLM-generated passage (Q,PR‚à™ {lpi})
IV . all the retrieved passages without the target re-
trieved passage and with the target LLM-generated
passage (Q,PR‚à™ {lpi}\{rpj}). We consider
(lpi, rpj)as consistent if the model‚Äôs prediction
is incorrect with II and all correct with I, III, and IV .
Conversely, (lpi, rpj)is labeled as CONFLICTING
if the prediction is correct with I and all incorrect
with II, III, IV .7
3.3 Matching Retrieved and LLM-generated
Passages into Pairs
To signal the reader model with the connections
between the two knowledge sources (compatible vs.
conflicting), we adapt FiD to encode passage pairs
as input. Each pair of passages is concatenated
with the question, and processed independently
from other pairs by the encoder. We add special to-
kens: ‚Äú question: ‚Äù, ‚Äúgenerated passage: ‚Äù and
‚Äúretrieved passage: ‚Äù before the question and
the passages, respectively. In this way, the encoder
could perform self-attention (Vaswani et al., 2017)
across the retrieved and LLM-generated passages.
We keep the relative order of LLM-generated and
retrieved passage fixed across all input pairs, by
always putting lpiin front of rpj(Figure 2b). This
6In our experiments, we set N= 10 across all datasets.
7To speed up the consistency label mining process, we
only need to obtain model predictions for III and IV if I is
correct and II is incorrect (i.e., rpjis evidential).trains the model to rely on the factual evidence that
is always located in the latter passage when facing
conflicting information.
To create passage pairs with a balance of fac-
tuality and coverage of supporting evidence, we
design a compatibility-guided optimal matching
strategy with the following two goals. First, for sim-
plicity, we include all passages during the matching
process, leaving it to future work to filter incom-
patible passage pairs. Second, we aim to maximize
the compatibility of matched passage pairs, to min-
imize the adverse impact of knowledge conflicts on
the reader model.
To do so, we first use the two discriminators
together to compute scores for evaluating the com-
patibility of all possible pairwise combinations of
the retrieved and LLM-generated passages of a
question (i.e., {(lpi, rpj)|i‚àà {1,2, ..., M }, j‚àà
{1,2, ..., N}}). This results in a 2-dimensional ma-
trix shown in Figure 2b, where each element rep-
resents the compatibility score for a passage pair.
A subset of all possible M√óNpairs (red boxes
highlighted in the matrix of Figure 2b) are then
selected as input to the reader model. The selection
is solved as a bipartite graph maximum-weighted
matching problem, with details in below paragraph.
The algorithm requires that compatible pairs score
higher than conflicting and non-evidential ones, so
it can achieve the maximum overall compatibil-
ity of matched passage pairs while balancing the
usage of all passages. To this end, we devise a
simple heuristic for compatibility scoring, dubbed
asevidentiality-cutoff :
cQ
i,j=P(lpi‚ä®Q|rpj‚ä®Q)¬∑ 1{P(rpj‚ä®Q)>0.5}
(2)
where 1is an indicator function. It binarizes the
decision from DEto score non-evidential pairs as
zero and prioritize compatible pairs over conflicting
counterparts.
Compatibility-guided Optimal Matching We
view the compatibility-guided matching process
as a maximum-weighted matching problem on a
bipartite graph. Concretely, we treat each pas-
sage as a node and there are edges connecting
LLM-passage-nodes with retrieved-passage-nodes,
whose weights are the corresponding compatibility
score. This results in a complete bipartite graph
G= (PL,PR;E)where E={(lpi, rpj)|i‚àà
{1,2, ..., M }, j‚àà {1,2, ..., N}}. The weight func-
tionw:E‚Üí[0,1]assigns compatibility score of
Equation 2 as edge weight: w((lpi, rpj)) = cQ
i,j.
We want to find a perfect matching Mof maxi-
mum weight where the weight of matching Mis
given by w(M) =P
e‚ààMw(e). This problem is
typically solved by the Hungarian algorithm (Kuhn,
1955, 1956) in polynomial time. This matching is
optimal in the sense that it covers all passages while
maximizing the sum of their compatibility scores.
4 Experiments
4.1 Experimental Setup
We experiment with four open-domain QA datasets:
NaturalQuestions Open (Kwiatkowski et al.,
2019), TriviaQA unfiltered (Joshi et al., 2017),
WebQuestion (Berant et al., 2013) for single-hop
QA and HotpotQA full wiki setting (Yang et al.,
2018) for multi-hop QA. We provide brief introduc-
tions and statistics for each dataset in Appendix B.
We use Exact Match (EM) (Rajpurkar et al., 2016)
as our major evaluation metric across all datasets.
We run each experiment three times with different
random seeds and report the average.8
We focus on the fully-supervised setting and
obtain retrieved and LLM-generated passages for
each question in the dataset. For retrieved passages,
we use retrieval results by DPR (Karpukhin et al.,
2020) for single-hop QA and MDR (Xiong et al.,
2021) for multi-hop QA, where no gold-standard
passages are used in this study. We do not further
finetune the retriever. For LLM-generated passages,
we use the ones provided by Yu et al. (2023)9for
the three single-hop QA datasets, which are based
on InstructGPT. Since there are no available re-
sources for LLM-generated passages on multi-hop
QA, we obtain them by calling ChatGPT‚Äôs API
(gpt-35-turbo ). We choose ChatGPT because it
is a performant LLM with reasonable costs.
We employ FiD (Izacard and Grave, 2021b)
as our reader model. For the discriminators DE
andDC, we use RoBERTa-large (Liu et al., 2019)
for single-hop QA and DeBERTa-large (He et al.,
2021) for multi-hop QA. DeBERTa features rela-
tive positional embedding, making it possible to
adapt to longer input for passages of multi-hop QA.
In our experiments, we train separate discrimina-
torsDEandDCfor each dataset. However, given
the limited amount of silver labels mined from the
small-scale dataset WebQuestions, we warm up
8For results of standard deviation under EM and F1 scores,
please see Table 6 in Appendix D.1.
9https://github.com/wyu97/GenRead.gitMethodsNQ
testTQA
testWebQ
testHQA
allQ
devHQA
bridge Q
dev
Single Knowledge Source
Retrieved Psg. Only 46.7 61.9 48.1 59.9 55.4
LLM Psg. Only 40.3 67.8 51.5 42.6 35.9
Two Knowledge Sources
Direct Merging 52.7 74.2 51.1 61.6 57.8
Random Matching 53.3 74.2 51.6 61.5 57.7
COMBO (ours) 54.2 74.6 53.0 61.6 58.0
Table 1: Exact Match (EM) results on NaturalQues-
tions (Kwiatkowski et al., 2019), TriviaQA (Joshi et al.,
2017), WebQuestion (Berant et al., 2013), and Hot-
potQA (Yang et al., 2018). For experiments under Two
Knowledge Sources , we conduct three runs with differ-
ent random seeds and report the average.
the training of its discriminators with data from
the other two single-hop QA datasets. Note that
the additional warm-up data is only used for train-
ing the discriminators but not the reader model, so
as to ensure a fair comparison with the baselines.
More details of the prompts for LLMs, model im-
plementation and hyperparameters are included in
Appendix C.2.
4.2 Results and Analysis
Comparison with Baselines. Table 1 shows ex-
perimental results on the four open-domain QA
datasets. All methods use 10 retrieved and/or 10
LLM-generated passages for each question Qand
FiD-large (770M) as the reader model. Yu et al.
(2023) presents a strong baseline of directly merg-
ing two knowledge sources. With the improved
coverage of world knowledge, it beats the retrieval-
only model by an average of 7.1 EM over the three
single-hop QA datasets. With the same reader
model and the same set of input passages, our
COMBO framework further improves over Direct
Merging by an average of 1.3 EM scores across the
single-hop QA datasets.
We also compare our proposed algorithm to a
Random Matching baseline, which randomly di-
vides passages into pairs. Our improvement over
Random Matching indicates that compatible pairs
of LLM and retrieved passages are essential for
model to make better predictions. Appendix D.1
also shows the results of an oracle setting assuming
access to ground-truth answers for matching and
the state-of-the-art results reported in existing liter-
ature. Since our approach does not modify retriever
or reader architecture, it can be easily extended to
LLMPsg5QRetrievedPsg3LLMPsg3QLLMPsg4Q¬∑¬∑¬∑¬∑¬∑¬∑RetrievedPsg4¬∑¬∑¬∑RetrievedPsg5AFiDCOMBO(ours)LLMPsg5QRetrievedPsg3LLMPsg3QLLMPsg4Q¬∑¬∑¬∑¬∑¬∑¬∑RetrievedPsg4¬∑¬∑¬∑RetrievedPsg5AFiDLLMPsg5QRetrievedPsg3LLMPsg3QLLMPsg4Q¬∑¬∑¬∑¬∑¬∑¬∑RetrievedPsg4RetrievedPsg5AFiDQQQw/opairwiseinputw/ofixedùëôùëù!,ùëüùëù"orderFigure 4: Illustrations of the input formats for two of the ablation experiments in Table 2.
capitalize on larger models, more retrieved pas-
sages and additional knowledge sources (e.g., ta-
bles and KBs), as already leveraged in state-of-the-
art systems. We also note that any potential per-
formance improvements are somewhat constrained
by the percentage of the hallucinated (generated)
and evidential (retrieved) passages provided. In the
extreme scenario where all generated passages are
devoid of hallucinations or all retrieved passages
lack correct evidence, our method would default to
Random Matching, as the compatibility matching
score would be uniform.
Different from single-hop QA, we do not ob-
serve improvements on HotpotQA. However, mi-
nor improvement is observed on the subset (73%)
of bridge questions that require the retriever or
LLM to find a bridge entity that connects two
pieces of evidence together to reveal the answer.
It shows that our method is not directly generaliz-
able to the more challenging multi-hop setting, and
thus calls for a more fine-grained modeling of the
compatibility between hops of evidence. We note
that for the rest of comparison questions in Hot-
potQA (e.g., ‚Äú who is younger, Keith Bostic or Jerry
Glanville? ‚Äù), models could make the right predic-
tion even if the LLM-generated passages contain
hallucinated evidence (see Appendix D.2 for an
example). This explains why our compatibility-
oriented framework appears to be less effective on
this subset.10
Ablation Study. We create several variants to val-
idate the effectiveness of different components of
ourCOMBO framework, by removing or replacing
each component individually. Results are shown in
Table 2. First, we remove the evidentiality discrim-
inatorDEand only use the probability given by the
10We are unable to show results of multiple methods on the
hidden test set of HotpotQA, as the official leaderboard of Hot-
potQA ( https://hotpotqa.github.io/ ) allows submitting
predictions only once . Therefore, we show results on the dev
set instead.MethodNQ
devTQA
dev
COMBO (ours) 52.3 73.9
w/o evidentiality discriminator 51.8 73.5
w/o pairwise input 51.5 73.4
w/o sorting pairs 51.7 73.7
w/o fixed (lpi, rpj)order 50.8 73.3
w/o evidentiality-cutoff 51.7 73.6
w/o optimal matching 51.6 73.6
Table 2: Ablation study results on NaturalQuestions
(NQ) and TriviaQA (TQA).
consistency discriminator DCas the compatibility
score for ranking passage pairs ( w/o evidentiality
discriminator ) . The performance drop highlights
the importance of having an evidentiality discrim-
inator to filter out irrelevant (i.e., non-evidential)
retrieved passages before computing the passage
consistency and thus echoes our compatibility de-
composition motivated by Equation 1.
Second, we remove the pairwise formulation by
linearizing the matched pairs into a sequence of
single passages as input ( w/o pairwise input ). See
Figure 4 in Appendix C.2 for an illustration of
the linearized inputs. The performance loss vali-
dates the usefulness of the encoder‚Äôs self-attention
between tokens of LLM-generated and retrieved
passages, which allows the reader module to jointly
reason over passage pairs as aggregated evidence.
Third, we randomly shuffle the order of input
passage pairs instead of ranking by their compati-
bility scores ( w/o sorting pairs ). The score worsens,
as this model variant fails to learn to prioritize com-
patible information. Further analysis of model‚Äôs
behavior in Appendix D.4 verifies that our model
could attribute higher attention scores to compati-
ble pairs than others when making predictions.
For the fourth ablation experiment ( w/o fixed
(lpi, rpj)order ), we randomly shuffle the order of
lpiandrpjwithin each passage pair, instead of
always putting lpiin front of rpj(Figure 4, Ap-
Conflicting
RateSubset%Retrieved
Psg. OnlyDirect
MergingCOMBO
0 ‚Äì 0.1 56.2% 41.6 47.7 48.5 (+0.8)
0.1 ‚Äì 0.2 22.7% 45.1 53.1 53.3 (+0.2)
0.2 ‚Äì 0.3 15.5% 52.5 59.0 59.9 (+0.9)
0.3 ‚Äì 0.4 1.8% 62.5 65.0 67.5 (+2.5)
0.4 ‚Äì 0.5 2.2% 57.4 64.0 66.0 (+2.0)
0.5 ‚Äì 1.0 1.6% 61.8 56.6 61.0 (+4.4)
Table 3: The performance of our method compared to
others on NaturalQuestions dev set w.r.t. conflicting rate
(percentage of conflicting passage pairs, Equation 3).
Larger improvements of COMBO over Direct Merging
are shaded with darker orange. Overall, COMBO ‚Äôs
improvement over Direct Merging is greater when the
conflicting rate is higher, suggesting the robustness of
our method to knowledge conflicts.
pendix C.2). We find that fixing their order allows
the model to learn to rely on the factual evidence in
the latter retrieved passage when facing conflicting
information.
We also explore other ablations to show the con-
tributions of several heuristics employed in our
system, including evidentiality-cutoff (Equation 2)
andoptimal matching (Section 3.3). We replace
Equation 2 with Equation 1 for producing compati-
bility scores ( w/o evidentiality-cutoff ). Equation 1
directly multiplies the two probabilities given by
the two discriminators together. It demonstrates
that models benefit from a binarized decision by
DEand we hypothesize that this is because the raw
predicted probability is often not well calibrated
(i.e., predicted probabilities do not correlate well
with the probabilities of correctness (Guo et al.,
2017; Jiang et al., 2021)).
Additionally, we replace the optimal matching
(maximum weighted matching) with a greedy strat-
egy ( w/o optimal matching ). Specifically, we first
match compatible passage pairs, followed by con-
flicting and non-evidential pairs. When finding the
k-th pair to match, we only consider passages not
appearing in previous k‚àí1pairs. The performance
drop shows the optimal matching could bring to-
gether more compatible pairs and thus better guide
the model‚Äôs predictions.
Impact of Conflicting Contexts on the Reader
Model. Here we aim to answer a question: How
well can the reader model (i.e., FiD) pinpoint the
correct answer when varying degrees of knowledge
conflicts exist between LLM-generated texts and
retrieved passages? Table 3 shows the performance
of different methods when facing different rates of
(10, 10) (10, 20) (20, 20) (20, 50)
(M,N)47.548.048.549.049.5Exact Match
NaturalQuestions
Direct merging
Random matching
COMBOFigure 5: The performance on NaturalQuestions dev set
when scaling the number of LLM-generated passages
(M) and retrieved passages ( N) for each question. We
report the average number and standard deviation (error
bar) over three runs with different random seeds.
conflicting knowledge. We measure conflict rate
as follows:
conflicting_rate =NA¬∑(M‚àíMA)
N¬∑M.(3)
NArefers to the number of retrieved passages that
contain the gold answer string AandM‚àíMA
means the number of LLM-generated passages that
do not contain the gold answer string. The con-
flicting rate indicates the percentage of conflicting
pairs (i.e., rpicontains the answer while lpjdoes
not) over all possible pairs. Table 3 suggests that
when there is minimal conflicts between the two
sources, both Direct Merging and COMBO can
significantly improve over the Retrieved-passage-
only model. However, when the conflict rate is
high, only COMBO can maintain a consistent im-
provement over the Retrieved-passage-only base-
line, suggesting its robustness.
Scaling with Number of Passages. We further
evaluate the performance of COMBO with respect
to different numbers of LLM-generated passages
(M) and retrieved passages ( N). Figure 5 shows
the results for NaturalQuestions. Given a larger
number of passages, we switch our reader model
from FiD-large to FiD-base due to GPU memory
limits. When Mis smaller than N, we simply
duplicate the LLM-generated passages to match
the number of retrieved passages, so that every
passage is included in the matching results (con-
sistent with Section 3.3). We observe that given
more passages from both sources, our framework
generally achieves greater performance gain over
Question:what NFL coach has the most wins ever?Answer: Don Shula(Don Shula) ‚Ä¶ He currently holds the NFL record for most career wins as a head coach, with 347 ‚Ä¶Retrieved Passage 7(Guy Chamberlin)‚Ä¶He compiled a 58-16-7 record in six years as a head coach in the National Football League (NFL), the best win percentage of any coach in NFL history‚Ä¶Retrieved Passage 1In the National Football League (NFL), the head coach with the most regular season wins is George Halas, who compiled 318 victories in 40 seasons with the ‚Ä¶LLM-generated Passage 10The NFL coach with the most wins ever is Don Shula, who coached the Miami Dolphins from 1970 to 1995‚Ä¶LLM-generated Passage 3Predictions: DirectMerging‚ÜíGeorge Halas√ó;COMBO ‚ÜíDon Shula‚àö
‚Ä¶‚Ä¶Figure 6: An example of a QA pair and the passage matching results by COMBO . Passage pairs are sorted by
their compatibility scores. It shows how COMBO rectifies the prediction of the baseline method under knowledge
conflicts by prioritizing compatible pairs (green connecting line) over incompatible pairs (red connecting line).
the direct merging approach. Additional analysis in
Appendix D.3 shows that more knowledge conflicts
arise from the increased number of input passages,
again highlighting the importance of compatibility-
guided knowledge merging. Because we train our
discriminators only on the top 10 passages, they
may not generalize well when applied to the top 50
passages. This is possibly why our method seems
less effective when provided with 50 retrieved pas-
sages as input.
Case Study of Matching Results. Figure 6
shows an example from NaturalQuestions where
theCOMBO matching results of passages help rec-
tify the prediction of the Direct Merging model. In
the first compatible pair, both passages contain cor-
rect evidence that supports the ground-truth answer
‚ÄúDon Shula‚Äù. The last one is an incompatible pair
where the LLM-generated passages frequently con-
tain a hallucinating error (‚ÄúGeorge Halas‚Äù) that mis-
leads the Direct Merging model to make a wrong
prediction. Since we prioritize compatible pairs
over incompatible pairs, the reader model could
leverage this inductive bias by paying more atten-
tion to the higher-ranked passages.
Human Evaluation of Compatibility Labels.
Figure 7 shows the confusion matrix of the com-
patibly labels predicted by our discriminators on
150 examples from the dev set of NaturalQuestions.
Specifically, we randomly select 25 questions and
sample 2 compatible pairs, 2 conflicting pairs and
2 non-evidential pairs (if applicable) for each ques-
tion. The authors manually analyze whether the
passages actually contain the correct evidence. We
find that our discriminators yield an overall accu-
racy of 78% on this 3-way classification task. It
shows that our discriminators are capable of provid-
ing signals of passage compatibility to the reader
model for making well-informed decisions.
Compatible Conflicting Non-evidential
Annotated LabelCompatible
Conflicting
Non-evidentialPredicted Label40 1 9
4 37 9
5 5 40
510152025303540Figure 7: Confusion matrix of the human annotations vs.
predicted labels by our discriminators on 150 random
samples from NaturalQuestions dev set. The overall
accuracy is 78%.
5 Conclusion and Future Work
In this work, we study the problem of merging
retrieved and LLM-generated knowledge for open-
domain QA. We tackle the challenge of knowledge
conflicts caused by LLM‚Äôs hallucination with a
compatibility-oriented knowledge merging frame-
work ( COMBO ). Specifically, we match LLM-
generated and retrieved passages for a given ques-
tion into pairs based on their compatibility and per-
form information fusion on the encoder side of the
FiD-based reader by feeding matched pairs as in-
put. Experiments on four open-domain QA datasets
demonstrate the empirical success of COMBO.
In the future, we plan to extend our framework
to few-shot QA settings by employing an LLM
with in-context learning to compute the compat-
ibility scores instead of training a discriminator
from scratch, thereby eliminating the necessity for
(weakly) supervised training. But it would also re-
quire carefully examining whether and which LLM
is able to discern the knowledge conflicts between
its own parametric memory and retrieved evidence.
Limitations
1.We only evaluate our knowledge merging
framework on the tasks of open-domain QA.
It would be interesting to apply our method
to other knowledge-intensive NLP tasks such
as fact checking (Thorne et al., 2018) and
knowledge-enhanced text generation (Dinan
et al., 2019; Yu et al., 2022).
2.Under the conditions of our experiment, we
did not manipulate the distribution of ques-
tions or input passages in any way. However,
we anticipate that in more controlled settings,
such as PopQA (Mallen et al., 2023) where
questions about infrequent entities are exam-
ined in more detail, our method could yield
more dramatic performance improvements.
At present, LLMs appear more susceptible
to hallucinating knowledge pertaining to less
frequent entities. We eagerly anticipate inves-
tigating this aspect further in our future work.
3.For each dataset, we only conduct experi-
ments with generated passages from a single
LLM (either InstructGPT or ChatGPT) and re-
trieved passages from a single retriever (either
DPR or MDR). Our experiments are limited to
a generative reader model which is based on
the widely-used Fusion-in-Decoder (Izacard
and Grave, 2021b) architecture.
4.Regarding computational overheads of
COMBO , we leverage the same set of input
passages and same reader model as direct
merging. During the training of the FiD-based
reader model, according to our empirical
observations on NaturalQuestions, it only
introduces minimal computational overheads
of approximately 23% more GPU memory
and 27% more training time, compared to
direct merging. Practitioners who can afford
to train the previous direct merging model
should also be able to train our framework.
5.Our proposed approach for silver label mining
could result in a limited amount of labels on
a small dataset, which could not provide suf-
ficient data to train a dataset-specific discrim-
inator. It thus calls for the need for training
a unified discriminator that works for various
datasets and tasks.Ethics Statement
Large language models are known to have racial
and gender biases and may generate harmful
content such as fabricated facts and toxic re-
sponse (OpenAI, 2023). Since we leverage gen-
erated contextual passages from LLMs to enhance
QA performance, our models may inherit these
biases during generation. Although we aim to pro-
mote the usage of factual information by combin-
ing generated knowledge with retrieved knowledge
from an external trustworthy corpus, we do not
fully eliminate hallucinations from LLMs. Inter-
ested practitioners should carefully address these
risks before deploying our framework in certain
domains such as politics, finance, and healthcare.
Acknowledgements
This work is supported by LG AI Research and
computational resources and services provided by
Advanced Research Computing (ARC), a division
of Information and Technology Services (ITS) at
the University of Michigan, Ann Arbor. Addition-
ally, we would like to thank Wenhao Yu for his
invaluable assistance in clarifying aspects of their
published work and generously sharing code and
data to facilitate the reproducibility of the results
presented in this paper. We also appreciate the
anonymous reviewers for their valuable sugges-
tions. We thank the members of the LAUNCH
group at the University of Michigan for their dis-
cussions and suggestions.
References
Rohan Anil, Andrew M. Dai, Orhan Firat, Melvin John-
son, Dmitry Lepikhin, Alexandre Passos, Siamak
Shakeri, Emanuel Taropa, Paige Bailey, Zhifeng
Chen, Eric Chu, Jonathan H. Clark, Laurent El
Shafey, Yanping Huang, Kathy Meier-Hellstern, Gau-
rav Mishra, Erica Moreira, Mark Omernick, Kevin
Robinson, Sebastian Ruder, Yi Tay, Kefan Xiao,
Yuanzhong Xu, Yujing Zhang, Gustavo Hern√°ndez
√Åbrego, Junwhan Ahn, Jacob Austin, Paul Barham,
Jan A. Botha, James Bradbury, Siddhartha Brahma,
Kevin Brooks, Michele Catasta, Yong Cheng, Colin
Cherry, Christopher A. Choquette-Choo, Aakanksha
Chowdhery, Cl√©ment Crepy, Shachi Dave, Mostafa
Dehghani, Sunipa Dev, Jacob Devlin, Mark D√≠az,
Nan Du, Ethan Dyer, Vladimir Feinberg, Fangxi-
aoyu Feng, Vlad Fienber, Markus Freitag, Xavier
Garcia, Sebastian Gehrmann, Lucas Gonzalez, and
et al. 2023. Palm 2 technical report. CoRR ,
abs/2305.10403.
Akari Asai, Matt Gardner, and Hannaneh Ha-
jishirzi. 2022. Evidentiality-guided generation for
knowledge-intensive NLP tasks. In Proceedings of
the 2022 Conference of the North American Chapter
of the Association for Computational Linguistics: Hu-
man Language Technologies, NAACL 2022, Seattle,
WA, United States, July 10-15, 2022 , pages 2226‚Äì
2243. Association for Computational Linguistics.
Jonathan Berant, Andrew Chou, Roy Frostig, and Percy
Liang. 2013. Semantic parsing on freebase from
question-answer pairs. In Proceedings of the 2013
Conference on Empirical Methods in Natural Lan-
guage Processing, EMNLP 2013, 18-21 October
2013, Grand Hyatt Seattle, Seattle, Washington, USA,
A meeting of SIGDAT, a Special Interest Group of the
ACL, pages 1533‚Äì1544. ACL.
Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie
Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind
Neelakantan, Pranav Shyam, Girish Sastry, Amanda
Askell, Sandhini Agarwal, Ariel Herbert-V oss,
Gretchen Krueger, Tom Henighan, Rewon Child,
Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu,
Clemens Winter, Christopher Hesse, Mark Chen, Eric
Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess,
Jack Clark, Christopher Berner, Sam McCandlish,
Alec Radford, Ilya Sutskever, and Dario Amodei.
2020. Language models are few-shot learners. In Ad-
vances in Neural Information Processing Systems 33:
Annual Conference on Neural Information Process-
ing Systems 2020, NeurIPS 2020, December 6-12,
2020, virtual .
Danqi Chen, Adam Fisch, Jason Weston, and Antoine
Bordes. 2017. Reading wikipedia to answer open-
domain questions. In Proceedings of the 55th Annual
Meeting of the Association for Computational Lin-
guistics, ACL 2017, Vancouver, Canada, July 30 -
August 4, Volume 1: Long Papers , pages 1870‚Äì1879.
Association for Computational Linguistics.
Hung-Ting Chen, Michael J. Q. Zhang, and Eunsol
Choi. 2022. Rich knowledge sources bring complex
knowledge conflicts: Recalibrating models to reflect
conflicting evidence. In Proceedings of the 2022 Con-
ference on Empirical Methods in Natural Language
Processing, EMNLP 2022, Abu Dhabi, United Arab
Emirates, December 7-11, 2022 , pages 2292‚Äì2307.
Association for Computational Linguistics.
Aakanksha Chowdhery, Sharan Narang, Jacob Devlin,
Maarten Bosma, Gaurav Mishra, Adam Roberts,
Paul Barham, Hyung Won Chung, Charles Sutton,
Sebastian Gehrmann, Parker Schuh, Kensen Shi,
Sasha Tsvyashchenko, Joshua Maynez, Abhishek
Rao, Parker Barnes, Yi Tay, Noam Shazeer, Vin-
odkumar Prabhakaran, Emily Reif, Nan Du, Ben
Hutchinson, Reiner Pope, James Bradbury, Jacob
Austin, Michael Isard, Guy Gur-Ari, Pengcheng Yin,
Toju Duke, Anselm Levskaya, Sanjay Ghemawat,
Sunipa Dev, Henryk Michalewski, Xavier Garcia,
Vedant Misra, Kevin Robinson, Liam Fedus, Denny
Zhou, Daphne Ippolito, David Luan, Hyeontaek Lim,
Barret Zoph, Alexander Spiridonov, Ryan Sepassi,David Dohan, Shivani Agrawal, Mark Omernick, An-
drew M. Dai, Thanumalayan Sankaranarayana Pil-
lai, Marie Pellat, Aitor Lewkowycz, Erica Moreira,
Rewon Child, Oleksandr Polozov, Katherine Lee,
Zongwei Zhou, Xuezhi Wang, Brennan Saeta, Mark
Diaz, Orhan Firat, Michele Catasta, Jason Wei, Kathy
Meier-Hellstern, Douglas Eck, Jeff Dean, Slav Petrov,
and Noah Fiedel. 2022. Palm: Scaling language mod-
eling with pathways. CoRR , abs/2204.02311.
Antonia Creswell and Murray Shanahan. 2022. Faith-
ful reasoning using large language models. CoRR ,
abs/2208.14271.
Emily Dinan, Stephen Roller, Kurt Shuster, Angela
Fan, Michael Auli, and Jason Weston. 2019. Wizard
of wikipedia: Knowledge-powered conversational
agents. In 7th International Conference on Learning
Representations, ICLR 2019, New Orleans, LA, USA,
May 6-9, 2019 . OpenReview.net.
Martin Fajcik, Martin Docekal, Karel Ondrej, and Pavel
Smrz. 2021. R2-D2: A modular baseline for open-
domain question answering. In Findings of the Asso-
ciation for Computational Linguistics: EMNLP 2021,
Virtual Event / Punta Cana, Dominican Republic, 16-
20 November, 2021 , pages 854‚Äì870. Association for
Computational Linguistics.
Chuan Guo, Geoff Pleiss, Yu Sun, and Kilian Q. Wein-
berger. 2017. On calibration of modern neural net-
works. In Proceedings of the 34th International Con-
ference on Machine Learning, ICML 2017, Sydney,
NSW, Australia, 6-11 August 2017 , volume 70 of
Proceedings of Machine Learning Research , pages
1321‚Äì1330. PMLR.
Pengcheng He, Xiaodong Liu, Jianfeng Gao, and
Weizhu Chen. 2021. Deberta: decoding-enhanced
bert with disentangled attention. In 9th International
Conference on Learning Representations, ICLR 2021,
Virtual Event, Austria, May 3-7, 2021 . OpenRe-
view.net.
Gautier Izacard, Mathilde Caron, Lucas Hosseini, Se-
bastian Riedel, Piotr Bojanowski, Armand Joulin,
and Edouard Grave. 2021. Towards unsupervised
dense information retrieval with contrastive learning.
CoRR , abs/2112.09118.
Gautier Izacard and Edouard Grave. 2021a. Distilling
knowledge from reader to retriever for question an-
swering. In 9th International Conference on Learn-
ing Representations, ICLR 2021, Virtual Event, Aus-
tria, May 3-7, 2021 . OpenReview.net.
Gautier Izacard and Edouard Grave. 2021b. Leveraging
passage retrieval with generative models for open do-
main question answering. In Proceedings of the 16th
Conference of the European Chapter of the Associ-
ation for Computational Linguistics: Main Volume,
EACL 2021, Online, April 19 - 23, 2021 , pages 874‚Äì
880. Association for Computational Linguistics.
Gautier Izacard, Patrick S. H. Lewis, Maria Lomeli,
Lucas Hosseini, Fabio Petroni, Timo Schick, Jane
Dwivedi-Yu, Armand Joulin, Sebastian Riedel, and
Edouard Grave. 2022. Few-shot learning with
retrieval augmented language models. CoRR ,
abs/2208.03299.
Ziwei Ji, Nayeon Lee, Rita Frieske, Tiezheng Yu, Dan
Su, Yan Xu, Etsuko Ishii, Ye Jin Bang, Andrea
Madotto, and Pascale Fung. 2023. Survey of halluci-
nation in natural language generation. ACM Comput.
Surv. , 55(12).
Zhengbao Jiang, Jun Araki, Haibo Ding, and Graham
Neubig. 2021. How can we know When language
models know? on the calibration of language mod-
els for question answering. Trans. Assoc. Comput.
Linguistics , 9:962‚Äì977.
Mandar Joshi, Eunsol Choi, Daniel S. Weld, and Luke
Zettlemoyer. 2017. Triviaqa: A large scale distantly
supervised challenge dataset for reading comprehen-
sion. In Proceedings of the 55th Annual Meeting of
the Association for Computational Linguistics, ACL
2017, Vancouver, Canada, July 30 - August 4, Volume
1: Long Papers , pages 1601‚Äì1611. Association for
Computational Linguistics.
Vladimir Karpukhin, Barlas Oguz, Sewon Min, Patrick
S. H. Lewis, Ledell Wu, Sergey Edunov, Danqi Chen,
and Wen-tau Yih. 2020. Dense passage retrieval for
open-domain question answering. In Proceedings of
the 2020 Conference on Empirical Methods in Nat-
ural Language Processing, EMNLP 2020, Online,
November 16-20, 2020 , pages 6769‚Äì6781. Associa-
tion for Computational Linguistics.
Harold W Kuhn. 1955. The hungarian method for the
assignment problem. Naval research logistics quar-
terly, 2(1-2):83‚Äì97.
Harold W Kuhn. 1956. Variants of the hungarian
method for assignment problems. Naval research
logistics quarterly , 3(4):253‚Äì258.
Tom Kwiatkowski, Jennimaria Palomaki, Olivia Red-
field, Michael Collins, Ankur P. Parikh, Chris Alberti,
Danielle Epstein, Illia Polosukhin, Jacob Devlin, Ken-
ton Lee, Kristina Toutanova, Llion Jones, Matthew
Kelcey, Ming-Wei Chang, Andrew M. Dai, Jakob
Uszkoreit, Quoc Le, and Slav Petrov. 2019. Natu-
ral questions: a benchmark for question answering
research. Trans. Assoc. Comput. Linguistics , 7:452‚Äì
466.
Kenton Lee, Ming-Wei Chang, and Kristina Toutanova.
2019. Latent retrieval for weakly supervised open do-
main question answering. In Proceedings of the 57th
Conference of the Association for Computational Lin-
guistics, ACL 2019, Florence, Italy, July 28- August
2, 2019, Volume 1: Long Papers , pages 6086‚Äì6096.
Association for Computational Linguistics.
Kyungjae Lee, Seung-won Hwang, Sang-eun Han, and
Dohyeon Lee. 2021. Robustifying multi-hop QAthrough pseudo-evidentiality training. In Proceed-
ings of the 59th Annual Meeting of the Association for
Computational Linguistics and the 11th International
Joint Conference on Natural Language Processing,
ACL/IJCNLP 2021, (Volume 1: Long Papers), Virtual
Event, August 1-6, 2021 , pages 6110‚Äì6119. Associa-
tion for Computational Linguistics.
Nayeon Lee, Wei Ping, Peng Xu, Mostofa Patwary,
Mohammad Shoeybi, and Bryan Catanzaro. 2022.
Factuality enhanced language models for open-ended
text generation. CoRR , abs/2206.04624.
Daliang Li, Ankit Singh Rawat, Manzil Zaheer, Xin
Wang, Michal Lukasik, Andreas Veit, Felix X. Yu,
and Sanjiv Kumar. 2022a. Large language mod-
els with controllable working memory. CoRR ,
abs/2211.05110.
Junlong Li, Zhuosheng Zhang, and Hai Zhao. 2022b.
Self-prompting large language models for open-
domain QA. CoRR , abs/2212.08635.
Jiacheng Liu, Skyler Hallinan, Ximing Lu, Pengfei He,
Sean Welleck, Hannaneh Hajishirzi, and Yejin Choi.
2022a. Rainier: Reinforced knowledge introspector
for commonsense question answering. In Proceed-
ings of the 2022 Conference on Empirical Methods
in Natural Language Processing, EMNLP 2022, Abu
Dhabi, United Arab Emirates, December 7-11, 2022 ,
pages 8938‚Äì8958. Association for Computational
Linguistics.
Jiacheng Liu, Alisa Liu, Ximing Lu, Sean Welleck, Pe-
ter West, Ronan Le Bras, Yejin Choi, and Hannaneh
Hajishirzi. 2022b. Generated knowledge prompting
for commonsense reasoning. In Proceedings of the
60th Annual Meeting of the Association for Compu-
tational Linguistics (Volume 1: Long Papers), ACL
2022, Dublin, Ireland, May 22-27, 2022 , pages 3154‚Äì
3169. Association for Computational Linguistics.
Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Man-
dar Joshi, Danqi Chen, Omer Levy, Mike Lewis,
Luke Zettlemoyer, and Veselin Stoyanov. 2019.
Roberta: A robustly optimized BERT pretraining
approach. CoRR , abs/1907.11692.
Shayne Longpre, Kartik Perisetla, Anthony Chen,
Nikhil Ramesh, Chris DuBois, and Sameer Singh.
2021. Entity-based knowledge conflicts in question
answering. In Proceedings of the 2021 Conference
on Empirical Methods in Natural Language Process-
ing, EMNLP 2021, Virtual Event / Punta Cana, Do-
minican Republic, 7-11 November, 2021 , pages 7052‚Äì
7063. Association for Computational Linguistics.
Kaixin Ma, Hao Cheng, Yu Zhang, Xiaodong Liu, Eric
Nyberg, and Jianfeng Gao. 2023. Chain-of-skills:
A configurable model for open-domain question an-
swering. CoRR , abs/2305.03130.
Lucie Charlotte Magister, Jonathan Mallinson, Jakub
Ad√°mek, Eric Malmi, and Aliaksei Severyn. 2022.
Teaching small language models to reason. CoRR ,
abs/2212.08410.
Alex Mallen, Akari Asai, Victor Zhong, Rajarshi Das,
Hannaneh Hajishirzi, and Daniel Khashabi. 2022.
When not to trust language models: Investigating
effectiveness and limitations of parametric and non-
parametric memories. CoRR , abs/2212.10511.
Alex Mallen, Akari Asai, Victor Zhong, Rajarshi Das,
Daniel Khashabi, and Hannaneh Hajishirzi. 2023.
When not to trust language models: Investigating
effectiveness of parametric and non-parametric mem-
ories. In Proceedings of the 61st Annual Meeting of
the Association for Computational Linguistics (Vol-
ume 1: Long Papers), ACL 2023, Toronto, Canada,
July 9-14, 2023 , pages 9802‚Äì9822. Association for
Computational Linguistics.
Ella Neeman, Roee Aharoni, Or Honovich, Leshem
Choshen, Idan Szpektor, and Omri Abend. 2022.
Disentqa: Disentangling parametric and contextual
knowledge with counterfactual question answering.
CoRR , abs/2211.05655.
Barlas Oguz, Xilun Chen, Vladimir Karpukhin,
Stan Peshterliev, Dmytro Okhonko, Michael Sejr
Schlichtkrull, Sonal Gupta, Yashar Mehdad, and
Scott Yih. 2022. Unik-qa: Unified representations
of structured and unstructured knowledge for open-
domain question answering. In Findings of the Asso-
ciation for Computational Linguistics: NAACL 2022,
Seattle, WA, United States, July 10-15, 2022 , pages
1535‚Äì1546. Association for Computational Linguis-
tics.
OpenAI. 2023. GPT-4 technical report. CoRR ,
abs/2303.08774.
Long Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Car-
roll L. Wainwright, Pamela Mishkin, Chong Zhang,
Sandhini Agarwal, Katarina Slama, Alex Ray, John
Schulman, Jacob Hilton, Fraser Kelton, Luke Miller,
Maddie Simens, Amanda Askell, Peter Welinder,
Paul F. Christiano, Jan Leike, and Ryan Lowe. 2022.
Training language models to follow instructions with
human feedback. CoRR , abs/2203.02155.
Liangming Pan, Wenhu Chen, Min-Yen Kan, and
William Yang Wang. 2021. Contraqa: Question
answering under contradicting contexts. CoRR ,
abs/2110.07803.
Baolin Peng, Michel Galley, Pengcheng He, Hao Cheng,
Yujia Xie, Yu Hu, Qiuyuan Huang, Lars Liden, Zhou
Yu, Weizhu Chen, and Jianfeng Gao. 2023. Check
your facts and try again: Improving large language
models with external knowledge and automated feed-
back. CoRR , abs/2302.12813.
Fabio Petroni, Aleksandra Piktus, Angela Fan, Patrick
S. H. Lewis, Majid Yazdani, Nicola De Cao, James
Thorne, Yacine Jernite, Vladimir Karpukhin, Jean
Maillard, Vassilis Plachouras, Tim Rockt√§schel, and
Sebastian Riedel. 2021. KILT: a benchmark for
knowledge intensive language tasks. In Proceedings
of the 2021 Conference of the North American Chap-
ter of the Association for Computational Linguistics:Human Language Technologies, NAACL-HLT 2021,
Online, June 6-11, 2021 , pages 2523‚Äì2544. Associa-
tion for Computational Linguistics.
Colin Raffel, Noam Shazeer, Adam Roberts, Katherine
Lee, Sharan Narang, Michael Matena, Yanqi Zhou,
Wei Li, and Peter J. Liu. 2020. Exploring the limits
of transfer learning with a unified text-to-text trans-
former. J. Mach. Learn. Res. , 21:140:1‚Äì140:67.
Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and
Percy Liang. 2016. Squad: 100, 000+ questions
for machine comprehension of text. In Proceedings
of the 2016 Conference on Empirical Methods in
Natural Language Processing, EMNLP 2016, Austin,
Texas, USA, November 1-4, 2016 , pages 2383‚Äì2392.
The Association for Computational Linguistics.
Vered Shwartz, Peter West, Ronan Le Bras, Chandra
Bhagavatula, and Yejin Choi. 2020. Unsupervised
commonsense question answering with self-talk. In
Proceedings of the 2020 Conference on Empirical
Methods in Natural Language Processing, EMNLP
2020, Online, November 16-20, 2020 , pages 4615‚Äì
4629. Association for Computational Linguistics.
Zhiqing Sun, Xuezhi Wang, Yi Tay, Yiming Yang, and
Denny Zhou. 2022. Recitation-augmented language
models. CoRR , abs/2210.01296.
James Thorne, Andreas Vlachos, Christos
Christodoulopoulos, and Arpit Mittal. 2018.
FEVER: a large-scale dataset for fact extraction
and verification. In Proceedings of the 2018
Conference of the North American Chapter of the
Association for Computational Linguistics: Human
Language Technologies, NAACL-HLT 2018, New
Orleans, Louisiana, USA, June 1-6, 2018, Volume
1 (Long Papers) , pages 809‚Äì819. Association for
Computational Linguistics.
Harsh Trivedi, Niranjan Balasubramanian, Tushar
Khot, and Ashish Sabharwal. 2022. Interleav-
ing retrieval with chain-of-thought reasoning for
knowledge-intensive multi-step questions. CoRR ,
abs/2212.10509.
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob
Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz
Kaiser, and Illia Polosukhin. 2017. Attention is all
you need. In Advances in Neural Information Pro-
cessing Systems 30: Annual Conference on Neural
Information Processing Systems 2017, December 4-9,
2017, Long Beach, CA, USA , pages 5998‚Äì6008.
Wenya Wang, Vivek Srikumar, Hanna Hajishirzi, and
Noah A. Smith. 2022. Elaboration-generating com-
monsense question answering at scale. CoRR ,
abs/2209.01232.
Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten
Bosma, Ed H. Chi, Quoc Le, and Denny Zhou. 2022.
Chain of thought prompting elicits reasoning in large
language models. CoRR , abs/2201.11903.
Peter West, Chandra Bhagavatula, Jack Hessel, Jena D.
Hwang, Liwei Jiang, Ronan Le Bras, Ximing Lu,
Sean Welleck, and Yejin Choi. 2022. Symbolic
knowledge distillation: from general language mod-
els to commonsense models. In Proceedings of the
2022 Conference of the North American Chapter of
the Association for Computational Linguistics: Hu-
man Language Technologies, NAACL 2022, Seattle,
WA, United States, July 10-15, 2022 , pages 4602‚Äì
4625. Association for Computational Linguistics.
Thomas Wolf, Lysandre Debut, Victor Sanh, Julien
Chaumond, Clement Delangue, Anthony Moi, Pier-
ric Cistac, Tim Rault, R√©mi Louf, Morgan Funtowicz,
and Jamie Brew. 2019. Huggingface‚Äôs transformers:
State-of-the-art natural language processing. CoRR ,
abs/1910.03771.
Wenhan Xiong, Xiang Lorraine Li, Srini Iyer, Jingfei
Du, Patrick S. H. Lewis, William Yang Wang, Yashar
Mehdad, Scott Yih, Sebastian Riedel, Douwe Kiela,
and Barlas Oguz. 2021. Answering complex open-
domain questions with multi-hop dense retrieval. In
9th International Conference on Learning Represen-
tations, ICLR 2021, Virtual Event, Austria, May 3-7,
2021 . OpenReview.net.
Zhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Ben-
gio, William W. Cohen, Ruslan Salakhutdinov, and
Christopher D. Manning. 2018. Hotpotqa: A dataset
for diverse, explainable multi-hop question answer-
ing. In Proceedings of the 2018 Conference on Em-
pirical Methods in Natural Language Processing,
Brussels, Belgium, October 31 - November 4, 2018 ,
pages 2369‚Äì2380. Association for Computational
Linguistics.
Wenhao Yu, Dan Iter, Shuohang Wang, Yichong Xu,
Mingxuan Ju, Soumya Sanyal, Chenguang Zhu,
Michael Zeng, and Meng Jiang. 2023. Generate
rather than retrieve: Large language models are
strong context generators. In 11th International Con-
ference on Learning Representations, ICLR 2023,
Kigali, Rwanda, May 1-5, 2023 . OpenReview.net.
Wenhao Yu, Chenguang Zhu, Zaitang Li, Zhiting Hu,
Qingyun Wang, Heng Ji, and Meng Jiang. 2022. A
survey of knowledge-enhanced text generation. ACM
Comput. Surv. , 54(11s):227:1‚Äì227:38.
Zhuosheng Zhang, Aston Zhang, Mu Li, and Alex
Smola. 2022. Automatic chain of thought prompting
in large language models. CoRR , abs/2210.03493.
Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang,
Xiaolei Wang, Yupeng Hou, Yingqian Min, Be-
ichen Zhang, Junjie Zhang, Zican Dong, Yifan Du,
Chen Yang, Yushuo Chen, Zhipeng Chen, Jinhao
Jiang, Ruiyang Ren, Yifan Li, Xinyu Tang, Zikang
Liu, Peiyu Liu, Jian-Yun Nie, and Ji-Rong Wen.
2023. A survey of large language models. CoRR ,
abs/2303.18223.
A Preliminaries
A.1 Analysis of Reader‚Äôs Predictions under
Knowledge Conflicts
We are interested in the question: does FiD-based
reader model prefer LLM-generated passages over
retrieved ones for making predictions under knowl-
edge conflicts? We compare the outputs of two
models: one is fed with retrieved passages only,
and the other takes the concatenation of retrieved
passage and generated passage as input (i.e., Direct
Merging shown in Figure 2a). We focus on the
examples from dev set of NaturalQuestions where
knowledge conflicts probably exist. Here we se-
lect questions whose retrieved passages contain
correct answer while LLM-generated passages do
not. Specifically, we obtain a subset of questions
with more then 20% of conflicting passage pairs
(i.e., conflicting rate defined in Equation 3). On
this subset, the Retrieved-passage-only model is
not affected by knowledge conflicts since it does
not have access to LLM-generated passages.
We find that on the examples initially predicted
as correct by the Retrieved-passage-only method,
models are fooled by adding LLM-generated pas-
sages on 16% of them (i.e., Direct Merging method
gives the wrong predictions). The performance
drop shows that there is still room for improve-
ment for FiD-based reader to resolve conflicts on its
own, thus calling for the need of our compatibility-
oriented QA framework.
Additionally, we observe that 65% of predic-
tions are sub-spans of at least one of the generated
passages. This shows that the reader favors LLM
passages more than retrieved passages when con-
flict exists. LLM passages often appear to be more
relevant to the question and describe the plausible
evidence in a way more specific to question. We
hypothesize that the reader model find it easier to
extract answer from LLM-generated passages so it
tend to rely on them more for predictions.
A.2 Retrieve/Generate-then-read
Open-domain QA Framework
The task of open-domain QA is typically solved
by a retrieve-then-read framework (Karpukhin
et al., 2020) consisting of two modules: 1) a
retriever Rthat fetches top- Nrelevant passages
PR={rp1, rp 2, ..., rp N}to the question Qfrom
a large corpus ‚Ñ¶Rsuch as Wikipedia and 2) a
generative reader Gthat generates the answer A
conditioned on retrieved passages PR, denoted
NaturalQuestions(Single-hopQA)Question:Who plays Charlotte in ‚ÄúThe Strain‚Äù season 4?CorrectAnswer:Rhona Mitra‚àöPrediction:Alexandra Breckenridge √óHotpotQA(Multi-hopQA)Question:Gail Matthiusco-anchored the Weekend Update segment of "Saturday Night Live" with the actor who played the villain Nicholas Andre in what movie? Answer:Dumb and Dumber‚àöPrediction:The Goonies √óRetrievedPassage1.(Gail Matthius) ‚Ä¶co-anchored the Weekend Update segment with Charles Rocket in 1981.2.(Charles Rocket)‚Ä¶He was best known for his role as the villain Nicholas Andre in the film ‚ÄúDumb and Dumber‚Äù‚Ä¶1.Gail Matthiusis an American actress ‚Ä¶ She also co-anchored the Weekend Update segment of the show "Saturday Night Live" ‚Ä¶2.Robert Davi‚Ä¶ is perhaps best known for his roles in movies such as ‚Ä¶ "The Goonies‚Äù ‚Ä¶ where he played the character Nicholas Andre.LLM-generatedPassageLLM-generatedPassageThe Strain is an American horror drama television series ‚Ä¶. Charlotte ‚Ä¶is played by Alexandra Breckenridge in season 4.RetrievedPassage(Rhona Mitra) ‚Ä¶she played Charlotte in the fourth season of ‚ÄúThe Strain‚Äù TV Series‚Ä¶Figure 8: A Fusion-in-Decoder-based (Izacard and
Grave, 2021b) QA model is misled by the knowl-
edge conflict between retrieved passage and halluci-
nating LLM-generated passage on an example from
HotpotQA (Yang et al., 2018).
asA=G(Q,PR). We use Fusion-in-Decoder
(FiD) (Izacard and Grave, 2021b), a state-of-the-
art retrieval-augmented generation model, as our
reader model. FiD is a sequence-to-sequence ar-
chitecture based on the pretrained T5 models (Raf-
fel et al., 2020). It first encodes separately each
passage riappended to the question, resulting in
representation pj=T5-encoder (Q, rp j). Then
the decoder attends to the concatenation of rep-
resentations of all passages and generates the an-
swer: A=T5-decoder (p1,p2, ...,pN). The cross-
attention mechanism of the decoder enables FiD
to perform evidence aggregation, i.e., assigning
different attention scores to each passage.
The recently proposed generate-then-read
pipeline (Yu et al., 2023) simply substitutes the
retriever Rwith an LLM Lthat generates top- M
contextual passages PL={lp1, lp2, ..., lp M}ex-
pressing knowledge stored in its parameters. Then
these LLM-generated passages are handled by the
reader to give the final answer: A=G(Q,PL).
Yu et al. (2023) also explore a simple approach
(Figure 2a) of directly merging passages from both
sources together: A=G(Q,PL‚à™PR), regardless
of knowledge conflicts between PLandPR.
A.3 Extension of Compatibility Definition
from Single-hop to Multi-hop QA
Different from the single-hop QA setting, our re-
trieved item under the multi-hop QA setting is ac-
tually a passage chain rcj= (rp1
j, rp2
j, ..., rpk
j)
instead of a single passage rpj, following the com-
mon practice proposed by Xiong et al. (2021).
Settings Single-hop QA Multi-hop QA
Assumptions ‚Ä¢ Retrieved passages are factual. ‚Ä¢ Retrieved passage chains are factual.
‚Ä¢LLM-generated passages contain relevant evi-
dence to the question.‚Ä¢LLM-generated passage chains contain a rele-
vant reasoning path to the question.
Definitions Given a question Q, LLM-generated passage lpi
and retrieved passage rpjare . . .Given a question Q, LLM-generated passage chain
lciand retrieved passage chain rcjare . . .
‚Ä¢COMPATIBLE if both lpiandrpjcontain the
correct evidence to support ground-truth answers
of the question Q‚Ä¢COMPATIBLE if both lciandrcjcontain the
correct reasoning path to support the ground-truth
answers of the question Q
‚Ä¢CONFLICTING ifrpjcontains correct evidence
while lpicontains incorrect evidence‚Ä¢CONFLICTING ifrcjcontains correct reasoning
path while lcicontains incorrect reasoning path
‚Ä¢NON-EVIDENTIAL ifrpjdoes not contain
correct evidence‚Ä¢NON-EVIDENTIAL ifrcjdoes not contain
correct reasoning path
Table 4: Comparision of definitions and assumptions for compatibility between single-hop and multi-hop QA
settings.
Specifically, in HotpotQA (Yang et al., 2018), all
questions are supposed to be 2-hop, so a passage
chain rcjis essentially an ordered pair of passages
(rp1
j, rp2
j)that provides sufficient evidence for an-
swering Q. An example of the retrieved passage
chain is shown in Figure 8. We modify the as-
sumptions and definitions for the multi-hop setting
accordingly, as shown in Table 4. Specifically, one
could simply replace rpjwithrcjandlpiwithlci
throughout this paper to obtain the same conclu-
sion. The modifications of definitions from the
single-hop to the multi-hop setting are minimal yet
reasonable, allowing for a unified concept formu-
lation and system implementation to handle both
single-hop and multi-hop QA.
A.4 Validating Assumptions behind the
Compatibility Definition
In Section 3.1, we make two assumptions for com-
puting passage compatibility. Assumption 1 (‚Äú re-
trieved passages are factual ‚Äù) is widely adopted
in the existing literature (Ji et al., 2023; Lee
et al., 2022; Thorne et al., 2018) when retriev-
ing from Wikipedia corpus. For Assumption 2
(‚ÄúLLM-generated passages contain relevant evi-
dence to the question ‚Äù), the authors manually anno-
tate 100 random examples from the NaturalQues-
tions (Kwiatkowski et al., 2019) dataset to verify
the plausibility of LLM‚Äôs generations. For each
example, we first determine whether it contains a
plausible answer. If yes, we further compare it to
the ground-truth answer or search on Wikipedia
to label it as hallucinating or not. We show ex-
amples of annotations in Table 5. We find that
94% of them contain plausible answers, thus sup-
porting our assumption. Of all the passages that
contain plausible answers, 51% of the answers areincorrect, meaning that these passages suffer from
the hallucinations of LLM and pose a risk to the
reliability of QA readers. This highlights the chal-
lenge of knowledge merging and the importance
of our compatibility-oriented matching framework
COMBO.
B Dataset Details
We use three single-hop QA datasets (NaturalQues-
tions (Kwiatkowski et al., 2019), TriviaQA (Joshi
et al., 2017), WebQuestions (Berant et al., 2013))
and one multi-hop (HotpotQA (Yang et al., 2018))
QA dataset as the testbeds for evaluating our
method. NaturalQuestions consists of real-world
information-seeking queries issued to the Google
search engine and their corresponding long answers
(gold evidence passage) and short answers (one or
more entities). We use the open-domain version
created by Lee et al. (2019) which only keeps ques-
tions and short answers with less than five tokens.
TriviaQA includes questions from trivia and quiz-
league websites. WebQuestions contains questions
from Google Suggest API that queries entities in
Freebase. HotpotQA contains questions requiring
reasoning over multiple Wikipedia documents to
answer. We focus on the fullwiki setting where QA
systems need to retrieve relevant evidence from
the whole Wikipedia corpus. For train / dev / test
splits, we use the same setting as Karpukhin et al.
(2020) for NaturalQuestions, TriviaQA, and We-
bQuestions, and the official leaderboard version11
for HotpotQA.
11https://hotpotqa.github.io/
Type Question Gold An-
swerLLM-generated Passage Plausible
AnswerPlau. Hallu. Perc.
I Who played
Floyd on the
Andy Griffith
show?Howard
Terbell
McNearFloyd Lawson was a recurring charac-
ter on The Andy Griffith Show. He was
played by Walter Brennen.Walter
BrennenY Y 48%
II When did the
new 3DS XL
come out?February
13, 2015The New Nintendo 3DS XL was re-
leased on February 13, 2015, in Japan
and North America.February
13, 2015Y N 46%
III Who shifted
the capital
from Calcutta
to Delhi?Government
of British
IndiaIn 1911, the British imperial capital
was shifted from Calcutta to Delhi.
This was done as a strategic move to
make administration more efficient.
The move was also seen as an effort
to co-opt and acculturate the growing
Indian middle class into the colonial
project.- N - 6%
Table 5: Examples of annotations for plausibility (Plau.) and hallucinations (Hallu.) of LLM-generated passages.
Analysis is performed on 100 random samples from the dev set of NaturalQuestion.
C Implementation Details
C.1 Silver Evidentiality Label Mining
We use the same reader Gbfor consistency label
mining in Section 3.2. Inspired by Asai et al.
(2022), we consider rpjas evidential for Qif 1)
the prediction based on top- Nretrieved passages
Gb(Q,PR)is correct and 2) Gb(Q,PR\{rpj}), the
prediction based top- Nretrieved passages except
rpj, is incorrect. rpjis thus believed to contain
the correct evidence since removing itself makes
the predictions change from right to wrong. Sim-
ilarly, we consider rpjas non-evidential for Q
ifGb(Q,PR)is incorrect and Gb(Q,PR\{rpj})is
correct, which indicates adding rpjto the rest of
input passages misleads the model.
C.2 Model Implementations and
Hyperparameters
For LLM-generated passages, we use the ones pro-
vided by Yu et al. (2023)12for the three single-
hop QA datasets. They prompt InstructGPT
(text-davinci-002 ) (Ouyang et al., 2022) with
the prompt ‚Äú Provide a background document
from Wikipedia to answer the given
question. \n\n {question} \n\n ‚Äù and
use sampling to generate 20 documents for each
question. Additionally, we prompt ChatGPT
(gpt-3.5-turbo ) to generate contextual passages
for HotpotQA. We use the prompt ‚Äú You are an
assistant designed to provide a chain
of two 100-word documents from Wikipedia
12https://github.com/wyu97/GenRead.git
Question:When did Italy host the FIFA World Cup?Answer: 1934
QRP1RP2RP3QRP2RP3LP1QRP1RP2RP3LP1QRP2RP3FinetunedBaseReader1984 √ó1934 ‚àö1934 ‚àö1934 ‚àö(FIFA World Cup hosts) ‚Ä¶ the only remaining candidate Italy to take the hosting job for the 1934 World Cup. The decision was ratified ‚Ä¶Retrieved Passage 1(Italy national football team) ‚Ä¶ Italy is one of the most successful national teams in the history of the World Cup, having won four titles (1934, ‚Ä¶Retrieved Passage 2(1990 FIFA World Cup) ‚Ä¶ The vote to choose the hosts of the 1990 tournament was held on 19 May 1984 in Z√ºrich, Switzerland. ‚Ä¶Retrieved Passage 3‚Ä¶ The 1934 FIFA World Cup was the second FIFA World Cup, andwas held in Italy from 27 May to 10 June 1934.LLM-generated Passage 1
RP1LP1ConsistentQuestion:who plays Charlotte in ‚ÄúThe Strain‚Äù season 4?Answer: Rhona Mitra
QRP1RP2RP3QRP2RP3LP7QRP1RP2RP3LP7QRP2RP3FinetunedBaseReaderLauren Collins √óRhona Mitra ‚àöAlexandra Breckenridge √óAlexandra Breckenridge √ó(Rhona Mitra) ‚Ä¶ she played Charlotte in the fourth season of "The Strain" TV Series. in 2018, Mitra was cast as Mercy Graves in The CW television series ‚Ä¶Retrieved Passage 1(Lauren Collins) In 2013, she appeared ‚Ä¶ as a recurring guest role in the upcoming fourth season of the FX series "The Strain" (2017).Retrieved Passage 2(The Strain (TV series)) ‚Ä¶ The Strain is an American horror drama television series that aired on FX from July 13, 2014, to September 17, 2017‚Ä¶Retrieved Passage 3The Strain is an American horror drama television series ‚Ä¶ Charlotte is a character in the series ‚Ä¶ She is played by Alexandra Breckenridge in season 4.LLM-generated Passage 7
RP1LP7ConflictingI.II.III.IV .Figure 9: Overview and examples of our proposed ap-
proach for mining silver conflicting labels. For a pair of
target retrieved and LLM-generated passages (e.g., RP
1 and LP 7 as in this Figure), we create four types of
input by I. using all the retrieved passages, II. masking
the target retrieved passage, III. appending the target
LLM-generated passage, IV . doing both II and III. We
obtain predictions by a finetuned reader model when
using different types of input. If the prediction is cor-
rect with I but all incorrect with II, II, IV , we label it
as a conflicting pair. See Figure 3 in Section 3.2 for an
example of consistent pair.
MethodsNQ
testTQA
testWebQ
testHQA
allQ
devHQA
bridge Q
dev
Direct Merging 52.7 0.60/ 61.2 0.3374.2 0.10/ 80.5 0.1351.1 0.30/ 58.5 0.1461.6 0.30/ 74.1 0.2457.8 0.00/ 72.0 0.00
Random Matching 53.3 0.35/ 61.9 0.1574.2 0.13/ 80.7 0.1051.6 1.55/ 58.6 1.5761.5 0.37/ 74.1 0.3057.7 0.00/ 72.1 0.00
COMBO (ours) 54.2 0.26/62.7 0.2174.6 0.09/80.9 0.0553.0 0.10/60.0 0.1261.6 0.17/74.2 0.2158.0 0.00/72.3 0.00
Table 6: Exact Match (EM) / F1 scores on NaturalQuestions (Kwiatkowski et al., 2019), TriviaQA (Joshi et al.,
2017), WebQuestion (Berant et al., 2013), and HotpotQA (Yang et al., 2018). We conduct three runs with different
random seeds and report the average and standard deviation.
that can be combined together to answer
the user‚Äôs question. Here‚Äôs an example of
your output format: Document 1: ""\n\n
Document 2: ""\n\n {question} ‚Äù. We then
parse the output to get the generated passage chains.
It costs around 400 US dollars to generate 10 pas-
sage chains per question with ChatGPT for Hot-
potQA.
For both the evidentiality discriminator DEand
consistency discriminator DC, we initialize the
model from the pretrained RoBERTa-large13for
single-hop QA and DeBERTa-large14for multi-
hop QA from huggingface (Wolf et al., 2019). We
set the max sequence length of RoBERTa as 512
and DeBERTa as 1024 since each passage chain
of HotpotQA contains two passages. The training
is performed on two A40 GPUs and the batch size
is 16 per GPU. Peak learning rate is set to 1e-5
for RoBERTa and 5e-6 for DeBERTa. We use the
Adam optimizer and linear schedule of learning
rate. We train the model for 7 epochs and select
the best epoch checkpoint based on the F1 score
of the silver dev set, which is mined from the dev
set of the original corresponding dataset. We apply
sample weights in the cross-entropy loss function
to handle imbalanced classes in the silver training
data.
We employ FiD as the backbone architecture for
our reader model in this paper. We train the models
for 100k steps using four A40 GPUs with 46 GB
memory and save checkpoints every 10k steps. The
best checkpoint is selected based on the EM score
on the dev set. For pairwise input, we set the max
input length per passage pair as 400 for single-hop
QA and 1000 for multi-hop QA. For single-passage
input, we set the max input length per passage as
200 for single-hop QA and 500 for multi-hop QA.
Per GPU batch size is 1 and we set the gradient
13https://huggingface.co/roberta-large
14https://huggingface.co/microsoft/
deberta-v3-largeMethodsNQ
testTQA
testWebQ
testHQA
allQ
devHQA
bridge Q
dev
COMBO (ours) 54.2 74.6 53.0 61.6 58.0
Same-answer matching 55.6 74.8 53.5 62.4 58.5
SOTA 64.0186.1257.8368.24-
Table 7: Exact Match (EM) results on NaturalQues-
tions (Kwiatkowski et al., 2019), TriviaQA (Joshi et al.,
2017), WebQuestion (Berant et al., 2013) and Hot-
potQA (Yang et al., 2018) for an oracle setting with
access to ground-truth answers during inference. State-
of-the-art (SOTA) systems ‚Äî1ATLAS (Izacard et al.,
2022),2PALM-2 (Anil et al., 2023),3UNIK-QA (Oguz
et al., 2022),4COS (Ma et al., 2023) ‚Äî leverage larger
models (up to 340B) and additional knowledge.
accumulation step to 16 to imitate a large batch
size. The learning rate is 1e-4 with 2000 warmup
steps and a linear scheduler. Adam is the optimizer
and the dropout probability is set to 0.1.
D Additional Experimental Results and
Analysis
D.1 More Results
We also compare our proposed compatibility-
guided optimal matching algorithm to an oracle
setup for passage matching, in addition to the Ran-
dom Matching baseline mentioned in Table 1. We
first match passages into pairs if both of them con-
tain the ground truth answer string and randomly
pair the rest. We call it same-answer matching .
Although an answer-containing passage does not
necessarily contain the correct evidence (Asai et al.,
2022), this setting still gives us a rough estimate
of the upper bound of the model‚Äôs performance.
Results are shown in Table 7. We show that our
method is close to the upper bound, indicating that
our compatibility discriminators are good at identi-
fying passages that contain the correct evidence.
Table 7 also includes state-of-the-art results on
these datasets. It should be noted that state-of-
0 20 40 60 80 100
Relative Frequency(20,50)(20,20)(10,20)(10,10)(M,N)NaturalQuestions
Compatible
Conflicting
Non-evidentialFigure 10: The relative frequency of each type of pair
on the test set of NaturalQuestions w.r.t the number of
LLM-generated passages ( M) and retrieved passages
(N) for each question. Complement to Figure 5, it
shows that more knowledge conflicts arise from the
increased number of input passages.
the-art systems for these datasets leverage readers
with much larger size (up to 340B) (Izacard et al.,
2022; Anil et al., 2023) or incorporate more in-
put retrieved passages (Ma et al., 2023) and ad-
ditional knowledge in different formats (e.g., Ta-
bles, KBs) (Oguz et al., 2022). Therefore, it is not
an apple-to-apple comparison between our models
and theirs. However, knowledge merging can in
principle benefit a wide range of open-domain QA
system so our contributions should be complemen-
tary to other state-of-the-art retrievers and reader
modules.
D.2 Comparison Questions from HotpotQA
are Less Sensitive to Hallucinations in
LLM-generated Passages
A comparison question is one of the two types
of question in HotpotQA, testing models‚Äô ability
to compare two entities on some shared proper-
ties (Yang et al., 2018). This type of question is less
sensitive to hallucinations in LLM-generated pas-
sages than the bridge question. For example, for the
comparison question ‚Äú who is younger, Keith Bostic
or Jerry Glanville? ‚Äù, the ChatGPT-generated pas-
sage chain is ‚Äú Document 1: Keith Bostic was born
on January 8, 1956 ... \n \n Document 2: Jerry
Glanville was born on October 14, 1941 ... ‚Äù. It con-
tains hallucination errors since Keith Bostic was
actually born on January 17, 1961. Nevertheless,
the reader model could still make the correct pre-
diction (‚ÄúKeith Bostic‚Äù) based on the fabricated
evidence.
(10,10)(10,20)(20,20)(20,50)
(M,N)6
5
4
3
2
Attention ScoreType
Non-evidential
Compatible
ConflictingFigure 11: The attention score distribution of differ-
ent types of pairs on the test set of NaturalQuestions
w.r.t. the number of LLM-generated passages ( M) and
retrieved passages ( N). Our model assigns higher atten-
tion scores to compatible pairs than incompatible ones.
D.3 Distribution of Pairwise Relationships
In Figure 10, we show the distribution of the rela-
tionships of passage pairs (compatible vs. conflict-
ing vs. non-evidential) determined by our eviden-
tiality and consistency discriminators. We observe
a trend that as we increase the number of input
LLM passages and retrieved passages, the percent-
age of compatible pairs decreases, which shows
that more knowledge conflicts arise. This could ac-
count for the larger improvements of our COMBO
framework over direct merging with more passages
as input, which is shown in Figure 5.
D.4 Analyzing Attention Distributions Over
Different Types of Passage Pairs
In Figure 11, we show the distribution of attention
scores for each type of passage pair across differ-
ent numbers of input LLM-generated and retrieved
passages. Following Izacard and Grave (2021a),
the attention score for a passage pair is obtained by
averaging the pre-normalized attention score of all
tokens in the passage pair, all layers and all heads
of the decoder. We find that COMBO model gen-
erally assigns higher attention scores to compatible
pairs than incompatible ones. This indicates that
it learns to prioritize compatible information when
making its predictions, which mitigates the harmful
impact of hallucination errors.