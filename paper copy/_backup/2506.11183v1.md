## **DiffPR: Diffusion-Based Phase Reconstruction via Frequency-Decoupled** **Learning**

**Yi Zhang** [1]


**Abstract** Oversmoothing remains a persistent problem
when applying deep learning to off-axis quantitative phase
imaging (QPI): end-to-end U-Nets favour low-frequency
content and under-represent fine, diagnostic detail. We trace
this issue to _spectral bias_ and show that the bias is reinforced
by the high-level skip connections that feed high-frequency
features directly into the decoder. Removing those deepest
skips—thus supervising the network only at a low resolution—significantly improves generalisation and fidelity.
Building on this insight, we introduce **DiffPR**, a two-stage
frequency-decoupled framework. _Stage 1_ : an _asymmet-_
_ric_ U-Net with cancelled high-frequency skips predicts a
1 _/_ 4 -scale phase map from the interferogram, capturing reliable low-frequency structure while avoiding spectral bias.
_Stage 2_ : the upsampled prediction, lightly perturbed with
Gaussian noise, is refined by an unconditional diffusion
model that iteratively recovers the missing high-frequency
residuals through reverse denoising. Experiments on four
QPI datasets ( _B-Cell_, _WBC_, _HeLa_, _3T3_ ) show that DiffPR
outperforms strong U-Net baselines, boosting PSNR by
up to 1 _._ 1 dB and reducing MAE by 11%, while delivering
markedly sharper membrane ridges and speckle patterns.
The results demonstrate that cancelling high-level skips and
delegating detail synthesis to a diffusion prior is an effective remedy for the spectral bias that limits conventional
phase-retrieval networks.

**1. Introduction**

**2. Introduction**

Off-axis quantitative phase imaging (QPI) provides highsensitivity, label-free measurement of optical phase delay
and has shown strong potential in applications such as
live cell imaging (Park et al., 2006; Pandey et al., 2019),
morphology analysis (Ryu et al., 2021; Popescu et al.,
2006), and cellular mechanism studies (Pandey et al., 2019;
Popescu et al., 2006). However, conventional phase reconstruction in off-axis QPI requires computationally expensive
post-processing and background calibration, limiting its realtime deployment (Bhaduri et al., 2014; Park et al., 2018;

1 Institude of Data Science, University of Hong Kong. Correspondence to: Yi Zhang _<_ yizhang101@connect.hku.hk _>_ .


_Figure 1._ **Network comparison.** (a) Vanilla U [¯] /Net fuses both
low- and high-resolution (HR) features via full skip connections;
(b) Reduced U [¯] /Net removes top-level skips, forcing the decoder
to rely on low-resolution (LR) information only; (c) Our DiffPR
replaces the HR skip path with a diffusion head that synthesises
high-frequency details from the predicted LR phase. Dashed blue
arrows indicate gradients flowing from HR supervision.

Niu et al., 2020). To address this, recent efforts have applied deep learning to directly map interferograms to phase
maps (Wang et al., 2019b; Chang et al., 2020; Lai et al.,
2021; Shi et al., 2019; Yao et al., 2020), enabling faster,
calibration-free reconstruction.

Despite these advances, deep neural networks often struggle to recover fine structural details. A well-documented
phenomenon in modern deep learning is the spectral bias:
neural networks tend to learn low-frequency components
significantly faster than high-frequency ones during training
(Rahaman et al., 2019). This mismatch becomes particularly
problematic for high-resolution phase reconstruction, where
high-frequency phase details are essential but difficult to
learn directly.

In this work, we investigate how network design impacts
frequency learning in deep learning-based phase reconstruction. Specifically, we revisit the common use of U-Net
architectures (Ronneberger et al., 2015; Rivenson et al.,
2018; Zhang et al., 2021), which fuse multi-level features
through skip connections. While lower-level skip connections primarily carry low-frequency content, higher-level
skip connections often reintroduce high-frequency information. Surprisingly, we find that removing these high-level
skip connections (see Fig. 1 b), which suppresses direct
high-frequency supervision, actually improves reconstruc

1

**DiffPR: Diffusion-Based Phase Reconstruction via Frequency-Decoupled Learning**


tion fidelity and numerical performance. This suggests that
simultaneously learning low- and high-frequency content,
via architectural design, can be detrimental in this task.

Motivated by this observation, we propose DiffPR, a novel
frequency-decoupled framework for phase reconstruction.
DiffPR first uses a feedforward neural network to predict a
low-resolution phase map from the interferogram. This lowresolution output is then upsampled to the target resolution
and perturbed with mild Gaussian noise. Finally, an unconditional diffusion model transforms this noisy input into a
high-resolution phase map through a reverse denoising process. Notably, diffusion models are inherently well-suited
for learning high-frequency details. During training, they
are explicitly tasked with recovering the original signal from
inputs corrupted by small amounts of noise—effectively enforcing a learning bias toward fine-grained structures. This
makes them particularly powerful for restoring the highfrequency components that standard networks struggle to
learn. By decoupling frequency learning and leveraging this
bias, our approach achieves sharper, more accurate reconstructions without the need for end-to-end high-frequency
supervision.

Our contributions are summarized as follows:

1. We empirically demonstrate that removing highfrequency skip connections in U-Net leads to improved
phase reconstruction, revealing that direct joint learning of low- and high-frequency features can hinder
performance.

2. We introduce DiffPR, a diffusion-based framework that
decouples frequency learning: a feedforward model
reconstructs low-frequency phase content, and a diffusion model generates the high-frequency residuals,
yielding high-fidelity phase maps with sharper struc
tures.

**3. Related Work**

**3.1. Phase Retrieval on Off-Axis Phase Retrieval**

Off-axis quantitative phase imaging (QPI) has matured from
its optical foundations into a versatile tool for label-free
bio-imaging. Early diffraction-phase microscopy demonstrated sub-nanometer path-length sensitivity for live cells
and laid the groundwork for subsequent biomedical applications (Park et al., 2006; Popescu et al., 2006; Bhaduri
et al., 2014). Follow-up studies broadened QPI’s reach to
morphology analysis, mechano-molecular phenotyping and
portable systems, enabling in-field metrology and point-ofcare diagnostics (Park et al., 2018; Niu et al., 2020; Pandey
et al., 2019; Ryu et al., 2021). Together, these efforts established the need for rapid, high-quality phase reconstruction
pipelines to unlock QPI’s real-time potential.


To overcome the computational burden of Fourier-based
or iterative solvers, the community has increasingly embraced deep learning. Rivenson _et al._ first showed that
a CNN could directly map interferograms to phase maps,
suppressing twin-image artefacts with millisecond inference
times (Rivenson et al., 2018). Subsequent U-Net variants
achieved real-time digital focusing and phase compensation in off-axis microscopy (Zhang et al., 2018; Wang et al.,
2018), while one-step networks tackled the notoriously difficult phase-unwrapping task under heavy noise (Wang et al.,
2019a;b). Extensions such as PhaseGAN introduced adversarial loss to mitigate the characteristic over-smoothing
of _ℓ_ 1 -trained models (Zhang et al., 2021), whereas datadriven aberration modelling enabled truly calibration-free
QPI (Chang et al., 2020). Despite these advances, conventional encoder–decoder designs still struggle to recover
high-frequency details, motivating our frequency-decoupled
DiffPR framework, which predicts reliable low-frequency
structure first and then synthesises high-frequency residuals
with a generative prior.

**3.2. Diffusion Models and High-Frequency Detail**
**Restoration**

Denoising Diffusion Probabilistic Models (DDPM) first
framed generation as a gradual denoising process, showing
that repeatedly predicting clean data from slightly noised
inputs can synthesize sharp images (Ho et al., 2020b). Subsequent work demonstrated that diffusion models not only
rival but surpass GANs in perceptual fidelity, especially on
edge-rich datasets (Dhariwal & Nichol, 2021). Nichol and
Dhariwal further improved the noise schedule and sampling
procedure, boosting detail preservation in generated outputs (Nichol & Dhariwal, 2021). Score-based generative
modeling reformulated DDPMs as stochastic differential
equations, providing theoretical insight into how successive denoising naturally reconstructs fine spatial frequencies (Song et al., 2020). Latent Diffusion Models compress
pixel space yet still reproduce high-frequency textures at
megapixel resolution, underscoring the framework’s efficiency in retaining details after heavy dimensionality reduction (Rombach et al., 2022).

Targeted restoration tasks highlight the bias toward highfrequency learning: SR3 recovers _×_ 8 super-resolution
facial details via iterative diffusion refinement (Saharia
et al., 2022b), while _Palette_ generalises the paradigm to
diverse image-to-image translations with texture-faithful
outputs (Saharia et al., 2022a). Variational Diffusion Models show that carefully chosen noise schedules and variational objectives yield state-of-the-art likelihoods without
sacrificing edge sharpness (Kingma et al., 2021), and EDM
systematically analyses how sampler preconditioning accentuates high-frequency convergence (Karras et al., 2022).


2

**DiffPR: Diffusion-Based Phase Reconstruction via Frequency-Decoupled Learning**


**Algorithm 1** Inference pipeline of DiffPR

**Require:** interferogram _I_ ; predictor _f_ _θ_ ; diffusion model
_ϵ_ _θ_ ; noise schedule _{α_ _t_ _}_ _[T]_ _t_ =1 [; corruption level] _[ t]_ [corrupt] [;]
Reverse Diffusion Solver _R_
1: **Low-frequency prediction:** ˜ _ϕ_ [ˆ] ˆ [LR] LR _←_ _f_ _θ_ ( _I_ )
2: **Initialisation:** _ϕ_ _T_ _←_ Up� _ϕ_ � + _σ_ _t_ corrupt _ϵ,_ _ϵ ∼_
_N_ (0 _,_ **I** )
3: **for** _t_ = _t_ corrupt _, . . .,_ 0 **do**
4: **Predictor step:** _ϕ_ [˜] _t−_ 1 _←R_ ( _ϕ_ [˜] _t_ _, t, ϵ_ _θ_ )
5: **end for**
6: **return** _ϕ_ [ˆ] [HR] _←_ _ϕ_ [˜] 0

**3.3. Spectral Bias of Deep Neural Networks**

A growing body of work shows that deep networks possess
a _spectral bias_ : during training they fit low-frequency components far earlier than high-frequency ones. Rahaman _et al._
first quantified this effect with Fourier analysis, demonstrating that ReLU networks converge in a frequency-dependent
manner and struggle to represent rapid oscillations without
extensive parameter tuning (Rahaman et al., 2019). Xu _et al._
verified the phenomenon on high-dimensional benchmarks
and provided a theoretical explanation based on activationfunction regularity (Xu et al., 2019). To mitigate the bias,
Tancik _et al._ introduced Fourier feature positional encodings
that pre-condition the neural tangent kernel and enable multilayer perceptrons to capture high-frequency signals (Tancik
et al., 2020).

Recent analyses interpret denoising diffusion probabilistic models (DDPMs) as _approximate autoregressive gen-_
_erators in the frequency domain_ : the reverse process first
reconstructs low-frequency coefficients and then sequentially refines higher-frequency bins (Dieleman, 2024; Russo,
2025). This spectral progression biases diffusion priors
toward faithful high-frequency restoration, offering a natural complement to our DiffPR framework, which delegates
high-frequency synthesis to an unconditional diffusion stage
while maintaining reliable low-frequency structure through
a feed-forward predictor.

**4. Method**


**4.1. Low-Resolution Phase Predictor**

**Network architecture.** We employ an _asymmetric_ U-Net
_f_ _θ_ whose encoder has four down-sampling blocks (stride 2
convolutions) and whose decoder has only two up-sampling
blocks. Consequently, the network output _ϕ_ [ˆ] [LR] = _f_ _θ_ ( _I_ ) has
spatial dimensions [1] _[H][ ×]_ [1] _[W]_ [.]



[1] [1]

4 _[H][ ×]_ 4


4 _[W]_ [.]


**Training loss.** The predictor is trained with a meansquared error (MSE) objective:


LR 2
_L_ LR ( _θ_ ) = E ( _I,ϕ_ HR ) ��� _f_ _θ_ ( _I_ ) _−_ _ϕ_ �� 2


_._ (1)
�


**4.2. Diffusion Prior for High-Frequency Restoration**

**Network architecture.** The diffusion prior is a _symmetric_
U-Net _ϵ_ _ω_ identical in depth on the encoder and decoder
sides, operating at the full resolution _H × W_ .

**Forward diffusion process.** Diffusion models first define
a forward diffusion process to perturb the data distribution
_p_ _data_ to a Gaussian distribution. Formally, the diffusion process follows an SDE d _**x**_ _t_ = _**f**_ ( _**x**_ _t_ ) + _g_ ( _t_ )d **w**, where d **w** is
the Brownian motion and _t_ flows forward from 0 to _T_ . The
calculated analytic solution of this diffusion process gives
a transition distribution _p_ _t_ ( _**x**_ _t_ _|_ _**x**_ 0 ) = _N_ ( _**x**_ _t_ _|α_ _t_ _**x**_ 0 _, σ_ _t_ [2] **[I]** [)] [,]
where _α_ _t_ = _e_ � 0 _t_ _[f]_ [(] _[s]_ [)] _[ds]_ and _σ_ _t_ [2] [= 1] _[ −]_ _[e]_ _[−]_ � 0 _t_ _[g]_ [(] _[s]_ [)] [2] _[ds]_ . In
the typical variance-preserving diffusion schedule, _**f**_ and
_g_ are designed such that lim _t→_ 0 _p_ _t_ ( _**x**_ ) = _p_ _data_ ( _**x**_ ) and
lim _t→T_ _p_ _t_ ( _**x**_ ) = _N_ ( _**x**_ _|_ **0** _,_ _**I**_ ).

**Denoising score matching loss.** Diffusion models sample data by reversing this diffusion process, where
_∇_ _**x**_ _t_ log _p_ _t_ ( _**x**_ _t_ ) is required. To learn this term, a neural network _s_ _θ_ is trained to minimize an empirical risk by marginalizing _∇_ _**x**_ _t_ log _p_ _t_ ( _**x**_ _t_ _|_ _**x**_ 0 ), leading to the following loss:


_L_ ( _θ_ ) = E _t∼U_ (0 _,_ 1) _,ϵ∼N_ ( **0** _,_ **I** )


_N_
� _∥s_ _θ_ ( _α_ _t_ _**x**_ _n_ + _σ_ _t_ _ϵ, t_ ) + _ϵ/σ_ _t_ _∥_ [2] _._

_n_ =1


To further balance the diffusion loss at different _t_ ’s, people
usually adopt loss reweighing (Karras et al., 2022) or an alternate objective using _ϵ_ -prediction (Ho et al., 2020a; Nichol
& Dhariwal, 2021), leading to the following well-known
denoising score matching (DSM) loss:


_N_
� _∥s_ _θ_ ( _α_ _t_ _**x**_ _n_ + _σ_ _t_ _ϵ, t_ ) _−_ _ϵ∥_ [2] _._

_n_ =1


Our DiffPR framework consists of two stages: **(i) Low-**
**resolution phase prediction**, where an asymmetric UNet maps the input interferogram to a [1] 4 [-scale phase map;]

**(ii) High-frequency refinement**, where a symmetric diffusion U-Net generates the final high-resolution phase by
reversing a stochastic denoising process. We denote an interferogram by _I ∈_ R _[H][×][W]_, the ground-truth phase by _ϕ_ [HR],
and the [1]

4 [-scale phase by] _[ ϕ]_ [LR] [ =][ Down][(] _[ϕ]_ [HR] [)][.]


where _s_ _θ_ ( _·, t_ ) can be viewed as the learned score function
at time _t_ .

**Reverse SDE sampling.** Given an estimated lowresolution phase map, we first corrupt it by the forward diffusion process to certain timestep _t_ . _ϕ_ [˜] _T_ = _α_ _t_ Up� _ϕ_ ˆ LR � +


_L_ ( _θ, t_ ) = E _ϵ∼N_ ( **0** _,_ **I** )


3

**DiffPR: Diffusion-Based Phase Reconstruction via Frequency-Decoupled Learning**

against the canonical **U-Net** and our **Reduced U-Net** [1] . Results demonstrate that (1) removing high-frequency skip
connections already improves fidelity, and (2) adding the
diffusion prior further boosts both numerical and visual
quality.

**5.1. Datasets and Metrics**

We construct four off-axis QPI datasets containing interferograms of _B Lymphocytes_ (385 samples), _white blood cells_
( 312 ), _HeLa_ ( 284 ), and _3T3_ cells ( 298 ). Each interferogram
is of size 1024 _×_ 1024 pixels and is normalised to zero mean
and unit variance. Target phase maps are linearly rescaled
to the [0 _,_ 1] range.


_Figure 2._ **Qualitative comparison.** (a) Ground-truth phase and
zoom-in regions. (b) U-Net results are overly smooth; (c) Reduced
U-Net restores better contrast but misses texture; (d) DiffPR reconstructs sharp, noise-free details.

_σ_ _t_ _ϵ, ϵ_ _∼N_ (0 _,_ **I** ) _,_ Starting from this noise-perturbed phase
map, we sample from the diffusion model by applying a
reverse-time SDE which reverses the diffusion process (Anderson, 1982):

d _**x**_ _t_ = [ _**f**_ ( _**x**_ _t_ ) _−_ _g_ ( _t_ ) [2] _∇_ _**x**_ _t_ log _p_ _t_ ( _**x**_ _t_ )]d _t_ + d ¯ **w** _,_

where d ¯ **w** is the Brownian motion and _t_ flows forward from
_T_ to 0.

**5. Experiments**

_Table 1._ **Numerical Criteria for the Networks on Different Sam-**

**ples. The best results are in bold;** _×_ **indicates that the model**
**failed to converge and predicted a blank background.**

Metric B Cell WBC HeLa 3t3

PSNR _×_ _×_ 28.59 34.41

U-Net SSIM _×_ _×_ 0.6119 0.7687

MAE _×_ _×_ 0.0317 0.0138


Redu
ced

U-Net

Diff
PRNet


PSNR 46.64 45.70 28.88 34.76

SSIM 0.9506 0.9145 0.7080 0.8278

MAE 0.0028 0.0035 0.0280 0.0119

PSNR **47.59** **46.81** **29.48** **36.96**

SSIM **0.9659** **0.9354** **0.7393** **0.8443**

MAE **0.0025** **0.0028** **0.0249** **0.0108**


We evaluate **DiffPR** on four representative off-axis QPI
datasets— _B-Cell_, _WBC_, _HeLa_, and _3T3_ —and compare it


Following common practice, we randomly split each dataset
into 80 % training, 10 % validation, and 10 % test sets. Performance is reported on the test split with **PSNR** ( dB ),
**SSIM**, and **MAE** (lower is better).

**5.2. Implementation Details**

**Network variants.** We train three models on all datasets:

(i) the canonical **U-Net**, (ii) the proposed **Reduced U-Net**,
and (iii) our full **DiffPR** (which uses the Reduced U-Net as
low-resolution predictor and a diffusion prior).

**Training protocol for U-Net variants.** Input–target pairs
are randomly cropped to 512 _×_ 512 to accelerate training
and reduce GPU memory. All models are optimised with
Adam ( _β_ 1 =0 _._ 9 _, β_ 2 =0 _._ 999 ) at a learning rate of 1 _×_ 10 _[−]_ [4]

and a batch size of 16 . For the vanilla U-Net we employ
early stopping on the validation PSNR with a patience of
100 epochs.

**Diffusion prior.** The diffusion model adopts a variancepreserving schedule (Ho et al., 2020a) with _T_ =1000
timesteps and is trained for 800 k updates. At inference
we integrate the reverse SDE with a 100 -step predictor–
corrector sampler (Alg. 1).

**6. Quantitative Results**

Table 1 presents PSNR, SSIM, and MAE across all four
datasets. On _B-Cell_ and _WBC_ the baseline U-Net col
lapses to an all-zero prediction—marked by “ _×_ ” in the
table—because both datasets contain large zero-phase backgrounds. The network minimises loss by staying in this local
minimum, and standard gradient descent fails to escape. The
experiments reveral serveral clear patterns:

**Removing high-frequency skips helps convergence and**
**fidelity.** Eliminating the deepest skip connection forces

1 U-Net without the deepest skip connections; see Fig. 1 (b).


4

**DiffPR: Diffusion-Based Phase Reconstruction via Frequency-Decoupled Learning**


the decoder to rely on low-frequency structure rather than a
spurious high-frequency shortcut. As a result, the _Reduced_
_U-Net_ converges on every dataset and consistently outperforms the vanilla model. For example, on _B-Cell_ PSNR
rises from failure to 46 _._ 6 dB, and MAE decreases by 13 %.

**A diffusion prior further closes the detail gap.** Adding
the diffusion stage boosts fidelity beyond the Reduced UNet, especially on texture-rich or noisy samples. On _WBC_
we observe a + 1 _._ 1 dB PSNR gain (from 45.7 dB to 46.8 dB)
and a corresponding SSIM improvement (0.914 → 0.935).
On _B-Cell_ MAE drops from 0.0028 to 0.0025. The iterative denoising process effectively reconstructs membrane
granularity that deterministic decoders miss.

Overall, DiffPR delivers the highest PSNR on every
dataset—up to + 1 _._ 1 dB beyond the Reduced U-Net—and reduces MAE by as much as 11 % . These results confirm that
(i) suppressing direct high-frequency supervision avoids
background-dominated minima, and (ii) coupling a lowfrequency predictor with a diffusion prior is superior to
conventional end-to-end optimisation for high-fidelity phase
reconstruction.

**6.1. Qualitative Results**

Figure 2 illustrates visual differences on representative
crops. Grey dashed boxes in the ground truth highlight three
challenging regions: fine ridges, a low-contrast cytoplasmic
boundary, and speckle-like noise.

**Vanilla U-Net (Fig. 2b).** Although edges are roughly
aligned, high-frequency texture is missing; ridge amplitude
is attenuated and intracellular speckles collapse into smooth
blobs—classic symptoms of spectral bias.

**Reduced U-Net (Fig. 2c).** Removing top-level skips sharpens global shape and attenuates ringing, but residual blur
remains around membrane folds and the faint cytoplasmic
boundary is still over-smoothed. This suggests that frequency decoupling helps preserve macroscopic structure yet
cannot fully regenerate lost fine features.

**DiffPR (Fig. 2d).** Our method faithfully reconstructs the
sinusoidal ridges, restores the weak boundary with correct
phase gradient, and reproduces speckle patterning without
hallucinated noise. Because the diffusion prior progressively
denoises from a low-frequency initialisation, it focuses its
capacity on residual high-frequency modes rather than relearning the full signal. The result is a phase map visually
indistinguishable from the ground truth while remaining
free of artefacts.

These qualitative observations mirror the quantitative improvements in Table 1, reinforcing that DiffPR achieves
superior high-frequency fidelity without sacrificing lowfrequency accuracy.


**7. Conclusion**

We have introduced **DiffPR**, a frequency-decoupled framework for off-axis quantitative phase imaging that couples a
low-resolution predictor with an unconditional diffusion
prior. Our analysis revealed that the ubiquitous U [¯] /Net
architecture, when endowed with deep skip connections,
can overfit large background regions and stall in a lowfrequency local minimum. Removing the deepest skips
( _Reduced U/Net_ _[¯]_ ) already alleviates this issue, confirming
that direct supervision of high-frequency features can be
harmful. Building on this observation, DiffPR synthesises
the missing high-frequency residuals through a reverse SDE,
explicitly exploiting the diffusion model’s bias toward detail

recovery.

Extensive experiments on four cell datasets demonstrate that
DiffPR surpasses both vanilla and Reduced U [¯] /Net baselines,
improving PSNR by up to 1 _._ 1 dB and lowering MAE by
11 % . Qualitative comparisons further show that DiffPR
reconstructs sub-cellular ridges and speckle patterns with
minimal artefacts.

**Limitations and future work.** DiffPR currently relies on
a 100 -step sampler, incurring longer inference time than a
single forward pass. Future work will explore consistency
distillation (Luhman & Luhman, 2021; Liu et al., 2023a;
Song et al., 2023; Yin et al., 2024; Zheng et al., 2023; Liu
et al., 2023b; Berthelot et al., 2023), and higher-order ODE
solvers (Song et al., 2021; Lu et al., 2022a;b) to accelerate
sampling. Moreover, extending the framework to volumetric
phase tomography and to other ill-posed inverse problems
(e.g. fluorescence lifetime imaging) could broaden its impact. Finally, incorporating physics-informed constraints
into the diffusion prior is a promising direction for further
improving accuracy and interpretability.

**References**

Anderson, B. D. Reverse-time diffusion equation models.
_Stochastic Processes and their Applications_, 12(3):313–
326, 1982.

Berthelot, D., Autef, A., Lin, J., Yap, D. A., Zhai, S., Hu,
S., Zheng, D., Talbott, W., and Gu, E. Tract: Denoising
diffusion models with transitive closure time-distillation.

_arXiv preprint arXiv:2303.04248_, 2023.

Bhaduri, B., Edwards, C., Pham, H., Zhou, R., Nguyen,
T. H., Goddard, L. L., and Popescu, G. Diffraction phase
microscopy: principles and applications in materials and
life sciences. _Advances in Optics and Photonics_, 6(1):
57–119, 2014.

Chang, T., Ryu, D., Jo, Y., Choi, G., Min, H.-S., and Park,
Y. Calibration-free quantitative phase imaging using


5

**DiffPR: Diffusion-Based Phase Reconstruction via Frequency-Decoupled Learning**


data-driven aberration modeling. _Optics Express_, 28(23):
34835–34847, 2020.

Dhariwal, P. and Nichol, A. Diffusion models beat gans
on image synthesis. _Advances in Neural Information_
_Processing Systems_, 2021. arXiv:2105.05233.

Dieleman, S. Diffusion is spectral autoregression. Blog
post, 2024. URL [https://sander.ai/2024/](https://sander.ai/2024/09/02/spectral-autoregression.html)
[09/02/spectral-autoregression.html](https://sander.ai/2024/09/02/spectral-autoregression.html) . Accessed: 2025-06-12.

Ho, J., Jain, A., and Abbeel, P. Denoising diffusion probabilistic models. _Advances in neural information process-_
_ing systems_, 33:6840–6851, 2020a.

Ho, J., Jain, A., and Abbeel, P. Denoising diffusion probabilistic models. _arXiv preprint arXiv:2006.11239_, 2020b.

Karras, T., Aittala, M., Aila, T., and Laine, S. Elucidating
the design space of diffusion-based generative models.
_Advances in neural information processing systems_, 35:
26565–26577, 2022.

Kingma, D. P., Salimans, T., Poole, B., and Ho, J.
Variational diffusion models. In _Advances in Neu-_

_ral Information Processing Systems (NeurIPS)_, 2021.
arXiv:2107.00630.

Lai, X., Xiao, S., Xu, C., Fan, S., and Wei, K.
Aberration-free digital holographic phase imaging using the derivative-based principal component analysis.
_Journal of Biomedical Optics_, 26(4):046501, 2021.

Liu, X., Gong, C., and qiang liu. Flow straight and
fast: Learning to generate and transfer data with rectified flow. In _The Eleventh International Conference_
_on Learning Representations_, 2023a. URL [https:](https://openreview.net/forum?id=XVjTT1nw5z)
[//openreview.net/forum?id=XVjTT1nw5z.](https://openreview.net/forum?id=XVjTT1nw5z)

Liu, X., Zhang, X., Ma, J., Peng, J., et al. Instaflow: One
step is enough for high-quality diffusion-based text-toimage generation. In _The Twelfth International Confer-_
_ence on Learning Representations_, 2023b.

Lu, C., Zhou, Y., Bao, F., Chen, J., Li, C., and Zhu, J.
Dpm-solver: A fast ode solver for diffusion probabilistic
model sampling in around 10 steps. _Advances in Neural_
_Information Processing Systems_, 35:5775–5787, 2022a.

Lu, C., Zhou, Y., Bao, F., Chen, J., Li, C., and Zhu, J. Dpmsolver++: Fast solver for guided sampling of diffusion
probabilistic models. _arXiv preprint arXiv:2211.01095_,
2022b.

Luhman, E. and Luhman, T. Knowledge distillation in
iterative generative models for improved sampling speed.
_arXiv preprint arXiv:2101.02388_, 2021.


Nichol, A. Q. and Dhariwal, P. Improved denoising diffusion probabilistic models. In _International conference on_
_machine learning_, pp. 8162–8171. PMLR, 2021.

Niu, M., Luo, G., Shu, X., Qu, F., Zhou, S., Ho, Y.-P., Zhao,
N., and Zhou, R. Portable quantitative phase microscope
for material metrology and biological imaging. _Photonics_
_Research_, 8(7):1253–1259, 2020.

Pandey, R., Zhou, R., Bordett, R., Hunter, C., Glunde,
K., Barman, I., Valdez, T., and Finck, C. Integration
of diffraction phase microscopy and raman imaging for
label-free morpho-molecular assessment of live cells.
_Journal of biophotonics_, 12(4):e201800291, 2019.

Park, Y., Popescu, G., Badizadegan, K., Dasari,
R. R., and Feld, M. S. Diffraction phase
and fluorescence microscopy. _Opt. Express_, 14
(18):8263–8268, Sep 2006. doi: 10.1364/OE.14.
008263. URL [https://opg.optica.org/oe/](https://opg.optica.org/oe/abstract.cfm?URI=oe-14-18-8263)

[abstract.cfm?URI=oe-14-18-8263.](https://opg.optica.org/oe/abstract.cfm?URI=oe-14-18-8263)

Park, Y., Depeursinge, C., and Popescu, G. Quantitative
phase imaging in biomedicine. _Nature photonics_, 12(10):
578–589, 2018.

Popescu, G., Ikeda, T., Dasari, R. R., and Feld, M. S. Diffraction phase microscopy for quantifying cell structure and
dynamics. _Optics letters_, 31(6):775–777, 2006.

Rahaman, N., Baratin, A., Arpit, D., Draxler, F., Lin, M.,
Hamprecht, F., Bengio, Y., and Courville, A. On the
spectral bias of neural networks. In _Proceedings of the_
_36th International Conference on Machine Learning_, Proceedings of Machine Learning Research, pp. 5301–5310.
PMLR, 2019. URL [https://proceedings.mlr.](https://proceedings.mlr.press/v97/rahaman19a.html)
[press/v97/rahaman19a.html.](https://proceedings.mlr.press/v97/rahaman19a.html)

Rivenson, Y., Zhang, Y., Gunaydın, H., Teng, D., and Ozcan, ¨
A. Phase recovery and holographic image reconstruction
using deep learning in neural networks. _Light: Science &_
_Applications_, 7(2):17141–17141, 2018.

Rombach, R., Blattmann, A., Lorenz, D., Esser, P., and
Ommer, B. High-resolution image synthesis with latent diffusion models. In _IEEE/CVF Conference on_
_Computer Vision and Pattern Recognition (CVPR)_, 2022.
arXiv:2112.10752.

Ronneberger, O., Fischer, P., and Brox, T. U-net: Convolutional networks for biomedical image segmentation. In _In-_
_ternational Conference on Medical image computing and_
_computer-assisted intervention_, pp. 234–241. Springer,
2015.

Russo, G. Diffusion is autoregression
in the frequency domain. Blog post,
2025. URL [https://gianluca.ai/](https://gianluca.ai/diffusion-is-frequency-autoregression/)


[6](https://gianluca.ai/diffusion-is-frequency-autoregression/)

**DiffPR: Diffusion-Based Phase Reconstruction via Frequency-Decoupled Learning**


[diffusion-is-frequency-autoregression/](https://gianluca.ai/diffusion-is-frequency-autoregression/) .
Accessed: 2025-06-12.

Ryu, D., Kim, J., Lim, D., Min, H.-S., Yoo, I. Y., Cho, D.,
and Park, Y. Label-free white blood cell classification using refractive index tomography and deep learning. _BME_
_Frontiers_, 2021, 2021.

Saharia, C., Chan, W., Chang, H., Lee, C., Ho, J., Salimans,
T., Fleet, D. J., and Norouzi, M. Palette: Image-to-image
diffusion models. In _ACM SIGGRAPH Conference Pro-_
_ceedings_, 2022a. arXiv:2111.05826.

Saharia, C., Ho, J., Chan, W., Salimans, T., Fleet, D. J., and
Norouzi, M. Image super-resolution via iterative refinement. In _IEEE/CVF Conference on Computer Vision and_
_Pattern Recognition (CVPR)_, 2022b. arXiv:2104.07636.

Shi, J., Zhu, X., Wang, H., Song, L., and Guo, Q. Label enhanced and patch based deep learning for phase
retrieval from single frame fringe pattern in fringe projection 3d measurement. _Optics express_, 27(20):28929–
28943, 2019.

Song, J., Meng, C., and Ermon, S. Denoising diffusion
implicit models. In _International Conference on Learning_
_Representations_, 2021. URL [https://openreview.](https://openreview.net/forum?id=St1giarCHLP)
[net/forum?id=St1giarCHLP.](https://openreview.net/forum?id=St1giarCHLP)

Song, Y., Sohl-Dickstein, J., Kingma, D. P., Kumar, A., Ermon, S., and Poole, B. Score-based generative modeling
through stochastic differential equations. In _International_
_Conference on Learning Representations_, 2020.

Song, Y., Dhariwal, P., Chen, M., and Sutskever, I. Consistency models, 2023. URL [https://arxiv.org/](https://arxiv.org/abs/2303.01469)
[abs/2303.01469.](https://arxiv.org/abs/2303.01469)

Tancik, M., Srinivasan, P. P., Mildenhall, B., Fridovich-Keil,
S., Raghavan, N., Singhal, U., Ramamoorthi, R., Barron,
J. T., and Ng, R. Fourier features let networks learn high
frequency functions in low dimensional domains. In _Ad-_
_vances in Neural Information Processing Systems_, 2020.
[URL https://arxiv.org/abs/2006.10739.](https://arxiv.org/abs/2006.10739)

Wang, H., Lyu, M., and Situ, G. eholonet: a
learning-based end-to-end approach for in-line digital holographic reconstruction. _Opt. Express_, 26
(18):22603–22614, Sep 2018. doi: 10.1364/OE.26.
022603. URL [https://opg.optica.org/oe/](https://opg.optica.org/oe/abstract.cfm?URI=oe-26-18-22603)

[abstract.cfm?URI=oe-26-18-22603.](https://opg.optica.org/oe/abstract.cfm?URI=oe-26-18-22603)

Wang, K., Li, Y., Kemao, Q., Di, J., and Zhao, J. Onestep robust deep learning phase unwrapping. _Opt. Ex-_
_press_, 27(10):15100–15115, May 2019a. doi: 10.1364/
OE.27.015100. URL [https://opg.optica.org/](https://opg.optica.org/oe/abstract.cfm?URI=oe-27-10-15100)
[oe/abstract.cfm?URI=oe-27-10-15100.](https://opg.optica.org/oe/abstract.cfm?URI=oe-27-10-15100)

7


Wang, K., Li, Y., Kemao, Q., Di, J., and Zhao, J. One-step
robust deep learning phase unwrapping. _Optics express_,
27(10):15100–15115, 2019b.

Xu, Z.-Q. J., Zhang, Y., Luo, T., Xiao, Y., and Ma, Z. Frequency principle: Fourier analysis sheds light on deep
neural networks. _arXiv preprint arXiv:1901.06523_, 2019.
[URL https://arxiv.org/abs/1901.06523.](https://arxiv.org/abs/1901.06523)

Yao, Y., Shu, X., and Zhou, R. Deep learning based phase
retrieval in quantitative phase microscopy. In _Uncon-_
_ventional Optical Imaging II_, volume 11351, pp. 76–80.
SPIE, 2020.

Yin, T., Gharbi, M., Zhang, R., Shechtman, E., Durand, F.,
Freeman, W. T., and Park, T. One-step diffusion with
distribution matching distillation. In _Proceedings of the_
_IEEE/CVF conference on computer vision and pattern_
_recognition_, pp. 6613–6623, 2024.

Zhang, G., Guan, T., Shen, Z., Wang, X., Hu, T., Wang, D.,
He, Y., and Xie, N. Fast phase retrieval in off-axis digital
holographic microscopy through deep learning. _Opt. Ex-_
_press_, 26(15):19388–19405, Jul 2018. doi: 10.1364/OE.
26.019388. URL [https://opg.optica.org/oe/](https://opg.optica.org/oe/abstract.cfm?URI=oe-26-15-19388)

[abstract.cfm?URI=oe-26-15-19388.](https://opg.optica.org/oe/abstract.cfm?URI=oe-26-15-19388)

Zhang, Y., Noack, M. A., Vagovic, P., Fezzaa, K.,
Garcia-Moreno, F., Ritschel, T., and Villanueva-Perez,
P. Phasegan: a deep-learning phase-retrieval approach for
unpaired datasets. _Optics express_, 29(13):19593–19604,
2021.

Zheng, H., Nie, W., Vahdat, A., Azizzadenesheli, K., and
Anandkumar, A. Fast sampling of diffusion models via
operator learning. In _International conference on machine_
_learning_, pp. 42390–42402. PMLR, 2023.

